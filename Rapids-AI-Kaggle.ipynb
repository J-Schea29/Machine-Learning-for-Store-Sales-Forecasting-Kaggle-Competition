{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "68fdbfd5-d749-441e-9291-48c9e26dfded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaggle\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "api = KaggleApi()\n",
    "api.authenticate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5e042b-275d-4a9b-85d8-77d00104f47c",
   "metadata": {},
   "source": [
    "## Imports Needed to run Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "95e2ccd0-6df8-4ca5-96b1-58a118dd875b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports for data wrangling \n",
    "import cudf\n",
    "import cupy as cp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "35ba9ed7-f231-4876-b860-c28fae1a2f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing given data\n",
    "train = cudf.read_csv(\"./input/train.csv\", parse_dates=['date'])\n",
    "\n",
    "test = cudf.read_csv(\"./input/test.csv\", parse_dates=['date'])\n",
    "\n",
    "oil = cudf.read_csv(\"./input/oil.csv\", parse_dates=['date'])\n",
    "\n",
    "holiday = cudf.read_csv(\"./input/holidays_events.csv\")\n",
    "\n",
    "store = cudf.read_csv(\"./input/stores.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db416fb9-d8e8-4b59-a7a9-9aae161d54fe",
   "metadata": {},
   "source": [
    "## Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f704e17-0daa-43ac-82b1-83c6b0c916e9",
   "metadata": {},
   "source": [
    "### Capturing Seasonal Holiday Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2a05e50e-ddda-4e59-9fa9-b2f39bf7d974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting dates to datetime\n",
    "holiday[\"date\"] = cudf.to_datetime(holiday[\"date\"], format='%Y-%m-%d')\n",
    "holiday = holiday.set_index(\"date\")\n",
    "\n",
    "# Keeping only celbrated holidays\n",
    "holiday = holiday.loc[(holiday[\"transferred\"]!=True)].drop(\"transferred\", axis=1)\n",
    "holiday.loc[holiday[\"type\"]==\"Transfer\", \"type\"] = \"Holiday\"\n",
    "\n",
    "# Bridged days are day where there is no work\n",
    "bridge = holiday.loc[holiday[\"type\"]==\"Bridge\"]\n",
    "bridge[\"bridge\"] = True\n",
    "bridge = bridge[[\"bridge\"]]\n",
    "\n",
    "# Special events\n",
    "event = holiday.loc[holiday[\"type\"]==\"Event\"][[\"description\"]]\n",
    "\n",
    "# Keeping only holidays\n",
    "holiday = holiday.loc[holiday[\"type\"]==\"Holiday\"]\n",
    "\n",
    "# Holidays celerbated localy \n",
    "loc_hol = holiday.loc[holiday[\"locale\"]==\"Local\"][[\"locale_name\", \"description\"]]\n",
    "\n",
    "# Holidays celerbrated regionally\n",
    "reg_hol = holiday.loc[holiday[\"locale\"]==\"Regional\"][[\"locale_name\", \"description\"]]\n",
    "\n",
    "#Holidays celberbrated nationally\n",
    "nat_hol = holiday.loc[holiday[\"locale\"]==\"National\"][[\"description\"]]\n",
    "\n",
    "# Recording days Earthquake\n",
    "quake = event.loc[event[\"description\"].str.find(\"Terremoto Manabi\")!=-1]\n",
    "quake[\"time_since_quake\"] = cp.arange(1,len(quake.index)+1)\n",
    "quake.drop(\"description\", axis=1, inplace=True)\n",
    "\n",
    "# Removing Earthquake and adding Sporting Events\n",
    "event = event.loc[event[\"description\"].str.find(\"Terremoto Manabi\")==-1]\n",
    "event.loc[event[\"description\"].str.find(\"futbol\")!=-1, \"description\"]= \"Sports\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8714e35a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bridge</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-12-24</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-31</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-26</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-02</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-04</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            bridge\n",
       "date              \n",
       "2012-12-24    True\n",
       "2012-12-31    True\n",
       "2014-12-26    True\n",
       "2015-01-02    True\n",
       "2016-11-04    True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bridge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8f7c2d-63a5-4f01-bfcb-553480b34fd3",
   "metadata": {},
   "source": [
    "### Location Specific Demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e484d5b1-1842-465e-ae7c-51474ccc5c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure proper format\n",
    "train[\"store_nbr\"] = train[\"store_nbr\"].astype(int)\n",
    "\n",
    "# Merging\n",
    "X = train.merge(store, on=\"store_nbr\", how=\"left\")\n",
    "X.drop(\"cluster\", axis=1, inplace=True)\n",
    "\n",
    "# Converting dates to datetime\n",
    "X[\"date\"] = cudf.to_datetime(X[\"date\"], format='%Y-%m-%d')\n",
    "\n",
    "# Creating feature measuring the total in store promotions.\n",
    "total_other_promo_store = X[[\"date\", \"store_nbr\", \"onpromotion\"]].groupby(['date', 'store_nbr']).sum()[\"onpromotion\"].reset_index()\n",
    "total_other_promo_store = total_other_promo_store.rename(columns={'onpromotion': 'total_other_promo_store',})\n",
    "\n",
    "# Creating feature measuring the total promotions in each town for similar products.\n",
    "total_other_city_promo = X[[\"date\", \"onpromotion\", \"family\", \"city\"]].groupby(['date', 'city', 'family']).sum()[\"onpromotion\"].reset_index()\n",
    "total_other_city_promo = total_other_city_promo.rename(columns={'onpromotion': 'total_other_city_promo',})\n",
    "\n",
    "# Adding new features\n",
    "X = X.merge(total_other_promo_store, on=['date', 'store_nbr'], how=\"left\")\n",
    "X = X.merge(total_other_city_promo, on=['date', 'city', 'family'], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4df2e7df-a73d-4a5d-88bb-04e2b33052b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure proper format\n",
    "store[\"store_nbr\"] = store[\"store_nbr\"].astype(int)\n",
    "test[\"store_nbr\"] = test[\"store_nbr\"].astype(int)\n",
    "\n",
    "# Merging\n",
    "X_test = test.merge(store, on=\"store_nbr\", how=\"left\")\n",
    "X_test.drop(\"cluster\", axis=1, inplace=True)\n",
    "\n",
    "# Converting dates to datetime\n",
    "X_test[\"date\"] = cudf.to_datetime(X_test[\"date\"], format='%Y-%m-%d')\n",
    "\n",
    "# Creating feature measuring the total in store promotions.\n",
    "total_other_promo_store = X_test[[\"date\", \"store_nbr\", \"onpromotion\"]].groupby(['date', 'store_nbr']).sum()[\"onpromotion\"].reset_index()\n",
    "total_other_promo_store = total_other_promo_store.rename(columns={'onpromotion': 'total_other_promo_store',})\n",
    "\n",
    "# Creating feature measuring the total promotions in each town for similar products.\n",
    "total_other_city_promo = X_test[[\"date\", \"onpromotion\", \"family\", \"city\"]].groupby(['date', 'city', 'family']).sum()[\"onpromotion\"].reset_index()\n",
    "total_other_city_promo = total_other_city_promo.rename(columns={'onpromotion': 'total_other_city_promo',})\n",
    "\n",
    "# Adding new features\n",
    "X_test = X_test.merge(total_other_promo_store, on=['date', 'store_nbr'], how=\"left\")\n",
    "X_test = X_test.merge(total_other_city_promo, on=['date', 'city', 'family'], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4d76ff04",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.set_index(\"date\")\n",
    "X_test = X_test.set_index(\"date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a203c43-19df-48ba-9c9c-f6b423a2dd40",
   "metadata": {},
   "source": [
    "### Merging with Holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e576cca1-b3eb-455f-aed1-65a679476c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding national holidays\n",
    "X = X.merge(nat_hol, on=\"date\", how=\"left\")\n",
    "\n",
    "# Bridge days\n",
    "X = X.merge(bridge, on=\"date\", how=\"left\")\n",
    "\n",
    "# Adding local holdays\n",
    "X = X.merge(loc_hol, left_on=[\"date\", \"city\"],\n",
    "            right_on=[\"date\", \"locale_name\"],\n",
    "            suffixes=(None, '_l'), how=\"left\"\n",
    "           )\n",
    "X.drop(\"locale_name\", axis=1, inplace=True)\n",
    "\n",
    "# Adding regional holidays\n",
    "X = X.merge(reg_hol, left_on=[\"date\", \"state\"],\n",
    "            right_on=[\"date\", \"locale_name\"], \n",
    "            suffixes=(None, '_r'),how=\"left\"\n",
    "           )\n",
    "X.drop(\"locale_name\", axis=1, inplace=True)\n",
    "\n",
    "# True if holiday that Day\n",
    "X[\"holiday\"] = (((X[\"descriptionNone\"].isnull()==False) | (X[\"description_l\"].isnull()==False)) | (X[\"description\"].isnull()==False))\n",
    "\n",
    "X[\"holiday_description\"] = X['descriptionNone'].fillna('') + X['description_l'].fillna('') + X['description'].fillna('')\n",
    "\n",
    "# Combine Holiday descriptions\n",
    "X.drop(\"descriptionNone\", axis=1, inplace=True)\n",
    "X.drop(\"description_l\", axis=1, inplace=True)\n",
    "X.drop(\"description\", axis=1, inplace=True)\n",
    "\n",
    "#Events\n",
    "X = X.merge(event, on=\"date\", how=\"left\")\n",
    "X = X.rename(columns={'description': 'event',})\n",
    "X[\"event\"] = X[\"event\"].fillna(\"none\")\n",
    "\n",
    "# Adding Quake data\n",
    "X = X.merge(quake, on=\"date\", how=\"left\")\n",
    "X[\"time_since_quake\"] = X[\"time_since_quake\"].fillna(0)\n",
    "\n",
    "#To model a diminishing marginal effect on the economy by the earthquake\n",
    "X[\"time_since_quake_sq\"] = X[\"time_since_quake\"]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e60cf2ae-a8ab-49ee-9b2c-354f2c34131f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding national holidays\n",
    "X_test = X_test.merge(nat_hol, on=\"date\", how=\"left\")\n",
    "del nat_hol\n",
    "\n",
    "# Bridge days\n",
    "X_test = X_test.merge(bridge, on=\"date\", how=\"left\")\n",
    "del bridge\n",
    "\n",
    "# Adding local holdays\n",
    "X_test = X_test.merge(loc_hol, left_on=[\"date\", \"city\"],\n",
    "            right_on=[\"date\", \"locale_name\"],\n",
    "            suffixes=(None, '_l'), how=\"left\"\n",
    "           )\n",
    "X_test.drop(\"locale_name\", axis=1, inplace=True)\n",
    "del loc_hol\n",
    "\n",
    "# Adding regional holidays\n",
    "X_test = X_test.merge(reg_hol, left_on=[\"date\", \"state\"],\n",
    "            right_on=[\"date\", \"locale_name\"], \n",
    "            suffixes=(None, '_r'),how=\"left\"\n",
    "           )\n",
    "X_test.drop(\"locale_name\", axis=1, inplace=True)\n",
    "del reg_hol\n",
    "\n",
    "# True if holiday that Day\n",
    "X_test[\"holiday\"] = (((X_test[\"descriptionNone\"].isnull()==False) | (X_test[\"description_l\"].isnull()==False)) | (X_test[\"description\"].isnull()==False))\n",
    "\n",
    "X_test[\"holiday_description\"] = X_test['descriptionNone'].fillna('') + X_test['description_l'].fillna('') + X_test['description'].fillna('')\n",
    "\n",
    "# Combine Holiday descriptions\n",
    "X_test.drop(\"descriptionNone\", axis=1, inplace=True)\n",
    "X_test.drop(\"description_l\", axis=1, inplace=True)\n",
    "X_test.drop(\"description\", axis=1, inplace=True)\n",
    "\n",
    "#Events\n",
    "X_test = X_test.merge(event, on=\"date\", how=\"left\")\n",
    "X_test = X_test.rename(columns={'description': 'event',})\n",
    "X_test[\"event\"] = X_test[\"event\"].fillna(\"none\")\n",
    "del event\n",
    "\n",
    "# Adding Quake data\n",
    "X_test = X_test.merge(quake, on=\"date\", how=\"left\")\n",
    "X_test[\"time_since_quake\"] = X_test[\"time_since_quake\"].fillna(0)\n",
    "del quake\n",
    "\n",
    "#To model a diminishing marginal effect on the economy by the earthquake\n",
    "X_test[\"time_since_quake_sq\"] = X_test[\"time_since_quake\"]**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2059c7b0-ce19-4011-929d-cd39e25682df",
   "metadata": {},
   "source": [
    "### Merging with Oil Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c9d6f820-485e-4f44-a3ef-821638b194ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "oil[\"date\"] = cudf.to_datetime(oil[\"date\"], format='%Y-%m-%d')\n",
    "oil = oil.set_index(\"date\")\n",
    "X = X.merge(oil, on=\"date\", how=\"left\")\n",
    "X_test = X_test.merge(oil, on=\"date\", how=\"left\")\n",
    "\n",
    "del oil\n",
    "\n",
    "# There is no price of oil on days that the market is closed so we interpolate to get next value.\n",
    "X[\"dcoilwtico\"]= X[\"dcoilwtico\"].interpolate(method=\"linear\", limit_direction=\"both\")\n",
    "X_test[\"dcoilwtico\"]= X_test[\"dcoilwtico\"].interpolate(method=\"linear\", limit_direction=\"both\")\n",
    "\n",
    "# I just to do a rolling average to smooth out any problems with the empty values,\n",
    "# and to capture any effect of changes. \n",
    "X[\"dcoilwtico\"] = X[\"dcoilwtico\"].rolling(\n",
    "    window=30,       \n",
    "    min_periods=1,  \n",
    ").mean()\n",
    "\n",
    "X_test[\"dcoilwtico\"] = X_test[\"dcoilwtico\"].rolling(\n",
    "    window=30,       \n",
    "    min_periods=1,  \n",
    ").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5cddac-bc83-4fce-903a-ce35d9675dcc",
   "metadata": {},
   "source": [
    "### Time Based Varriables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4ef2ed5c-e767-476d-b9cc-50d06717e194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time variables\n",
    "X[\"day\"] = X.index.dayofweek\n",
    "X[\"dayofyear\"] = X.index.dayofyear\n",
    "X[\"month\"] = X.index.month\n",
    "X[\"year\"] = X.index.year\n",
    "\n",
    "# This varible says whether it is a workday.\n",
    "X[\"workday\"] = (((X.bridge.isnull()) & (X.holiday==False)) & ((X[\"day\"]!=5) & (X[\"day\"]!=6)))\n",
    "X.drop(\"bridge\", axis=1, inplace=True)\n",
    "\n",
    "# In Ecudor, people get paid on the 15 and the last day of the month\n",
    "X[\"payday\"] = ((X.index.day==15) | (X.index.day==X.index.to_series().dt.days_in_month)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2a7d9e6e-6b89-4dfd-b375-aa0a56cd1270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time variables\n",
    "X_test[\"day\"] = X_test.index.dayofweek\n",
    "X_test[\"dayofyear\"] =X_test.index.dayofyear\n",
    "X_test[\"month\"] = X_test.index.month\n",
    "X_test[\"year\"] = X_test.index.year\n",
    "\n",
    "# This varible says whether it is a workday.\n",
    "X_test[\"workday\"] = (((X_test.bridge.isnull()) & (X_test.holiday==False)) & ((X_test[\"day\"]!=5) & (X_test[\"day\"]!=6)))\n",
    "X_test.drop(\"bridge\", axis=1, inplace=True)\n",
    "\n",
    "# In Ecudor, people get paid on the 15 and the last day of the month\n",
    "X_test[\"payday\"] = ((X_test.index.day==15) | (X_test.index.day==X_test.index.to_series().dt.days_in_month)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad9d618-c5d0-4c41-8d31-e255fdba0d75",
   "metadata": {},
   "source": [
    "### Data Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b2deef0a-75d4-4134-9c4e-1f0fb03537c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing data type\n",
    "X_test = X_test.reset_index()\n",
    "X_test = X_test.set_index(\"date\")\n",
    "\n",
    "X_test[\"onpromotion\"] = X_test[\"onpromotion\"].astype('float')\n",
    "X_test[\"total_other_promo_store\"] = X_test[\"total_other_promo_store\"].astype('float')\n",
    "X_test[\"total_other_city_promo\"] = X_test[\"total_other_city_promo\"].astype('float')\n",
    "X_test[\"holiday\"] = X_test[\"holiday\"].astype('float')\n",
    "\n",
    "X_test[\"family\"] = X_test[\"family\"].astype('category')\n",
    "X_test[\"store_nbr\"] = X_test[\"store_nbr\"].astype('category')\n",
    "X_test[\"holiday\"] = X_test[\"holiday\"].astype('category')\n",
    "X_test[\"event\"] = X_test[\"event\"].astype('category')\n",
    "X_test[\"city\"] = X_test[\"city\"].astype('category')\n",
    "X_test[\"state\"] = X_test[\"state\"].astype('category')\n",
    "X_test[\"type\"] = X_test[\"type\"].astype('category')\n",
    "X_test[\"workday\"] = X_test[\"workday\"].astype('category')\n",
    "X_test[\"payday\"] = X_test[\"payday\"].astype('category')\n",
    "X_test[\"holiday_description\"] = X_test[\"holiday_description\"].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "968334b4-6d18-4dd3-b646-d25286f5cccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reset_index()\n",
    "X = X.set_index(\"date\")\n",
    "\n",
    "X[\"onpromotion\"] = X[\"onpromotion\"].astype('float')\n",
    "X[\"total_other_promo_store\"] = X[\"total_other_promo_store\"].astype('float')\n",
    "X[\"total_other_city_promo\"] = X[\"total_other_city_promo\"].astype('float')\n",
    "X[\"holiday\"] = X[\"holiday\"].astype('float')\n",
    "\n",
    "X[\"family\"] = X[\"family\"].astype('category')\n",
    "X[\"store_nbr\"] = X[\"store_nbr\"].astype('category')\n",
    "X[\"holiday\"] = X[\"holiday\"].astype('category')\n",
    "X[\"event\"] = X[\"event\"].astype('category')\n",
    "X[\"city\"] = X[\"city\"].astype('category')\n",
    "X[\"state\"] = X[\"state\"].astype('category')\n",
    "X[\"type\"] = X[\"type\"].astype('category')\n",
    "X[\"workday\"] = X[\"workday\"].astype('category')\n",
    "X[\"payday\"] = X[\"payday\"].astype('category')\n",
    "X[\"holiday_description\"] = X[\"holiday_description\"].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daee883d",
   "metadata": {},
   "source": [
    "### Lagged Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fc941ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lags(data, column, lags):\n",
    "    '''Takes Data and creates lagged features for every catergory'''\n",
    "    for k in range(1, lags+1):\n",
    "        data[f\"{column}_lag_{k}\"] = data.groupby([\"store_nbr\", \"family\"])[column].shift(k)\n",
    "\n",
    "def make_one_year_lag(data, column):\n",
    "    '''Takes Data and retrieves the values from the previous year'''\n",
    "    data[f\"{column}_one_year_lag\"] = data.groupby([\"store_nbr\", \"family\", \"dayofyear\"])[column].shift(1)\n",
    "    \n",
    "    # Any after a year is just the result of the store being closed\n",
    "    data[f\"{column}_one_year_lag\"] = data[f\"{column}_one_year_lag\"].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0ddb3e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lag = cudf.concat([X[[\"store_nbr\", \"family\", \"dayofyear\", \"onpromotion\", \"dcoilwtico\", \"sales\"]], X_test[[\"store_nbr\", \"family\", \"onpromotion\", \"dcoilwtico\"]]], axis=0)\n",
    "X_lag = X_lag.reset_index().sort_values([\"store_nbr\", \"family\", \"date\"]).set_index([\"date\"])\n",
    "\n",
    "X_lag[\"dayofyear\"] = X_lag.index.dayofyear\n",
    "        \n",
    "make_lags(X_lag, \"onpromotion\", 7)\n",
    "make_lags(X_lag, \"dcoilwtico\", 7)\n",
    "\n",
    "make_one_year_lag(X_lag, \"sales\")\n",
    "\n",
    "X_lag = X_lag.drop([\"dayofyear\", \"onpromotion\", \"dcoilwtico\", \"sales\"], axis=1)\n",
    "\n",
    "X = X.merge(X_lag, on=[\"date\", \"store_nbr\", \"family\"], how=\"left\")\n",
    "X_test = X_test.merge(X_lag, on=[\"date\", \"store_nbr\", \"family\"], how=\"left\")\n",
    "\n",
    "del X_lag\n",
    "\n",
    "X[\"Change_in_oil_prices\"] = X[\"dcoilwtico\"]-X[\"dcoilwtico_lag_1\"]\n",
    "X_test[\"Change_in_oil_prices\"] = X_test[\"dcoilwtico\"]-X_test[\"dcoilwtico_lag_1\"]\n",
    "X[\"Change_in_oil_prices\"] = X[\"Change_in_oil_prices\"].astype('float')\n",
    "X_test[\"Change_in_oil_prices\"] = X_test[\"Change_in_oil_prices\"].astype('float')\n",
    "\n",
    "X[\"promo_last_7_days\"] = X[X.columns[X.columns.str.find(\"onpromotion_lag\")==0]].sum(axis=1)\n",
    "X_test[\"promo_last_7_days\"] = X_test[X_test.columns[X_test.columns.str.find(\"onpromotion_lag\")==0]].sum(axis=1)\n",
    "X[\"promo_last_7_days\"] = X[\"promo_last_7_days\"].astype('float')\n",
    "X_test[\"promo_last_7_days\"] = X_test[\"promo_last_7_days\"].astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836e7aad",
   "metadata": {},
   "source": [
    "### Final Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ecc8b2f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>type</th>\n",
       "      <th>total_other_promo_store</th>\n",
       "      <th>total_other_city_promo</th>\n",
       "      <th>holiday</th>\n",
       "      <th>...</th>\n",
       "      <th>dcoilwtico_lag_1</th>\n",
       "      <th>dcoilwtico_lag_2</th>\n",
       "      <th>dcoilwtico_lag_3</th>\n",
       "      <th>dcoilwtico_lag_4</th>\n",
       "      <th>dcoilwtico_lag_5</th>\n",
       "      <th>dcoilwtico_lag_6</th>\n",
       "      <th>dcoilwtico_lag_7</th>\n",
       "      <th>sales_one_year_lag</th>\n",
       "      <th>Change_in_oil_prices</th>\n",
       "      <th>promo_last_7_days</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-10</th>\n",
       "      <td>17490</td>\n",
       "      <td>5</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Santo Domingo</td>\n",
       "      <td>Santo Domingo de los Tsachilas</td>\n",
       "      <td>D</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>93.493667</td>\n",
       "      <td>93.21</td>\n",
       "      <td>93.165333</td>\n",
       "      <td>93.167809</td>\n",
       "      <td>93.130446</td>\n",
       "      <td>93.465000</td>\n",
       "      <td>93.243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.357333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-10</th>\n",
       "      <td>17491</td>\n",
       "      <td>5</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Santo Domingo</td>\n",
       "      <td>Santo Domingo de los Tsachilas</td>\n",
       "      <td>D</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>93.469333</td>\n",
       "      <td>93.21</td>\n",
       "      <td>93.168000</td>\n",
       "      <td>93.167832</td>\n",
       "      <td>93.082210</td>\n",
       "      <td>93.442000</td>\n",
       "      <td>93.222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.308667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-10</th>\n",
       "      <td>17492</td>\n",
       "      <td>5</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Santo Domingo</td>\n",
       "      <td>Santo Domingo de los Tsachilas</td>\n",
       "      <td>D</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>93.445000</td>\n",
       "      <td>93.21</td>\n",
       "      <td>93.170667</td>\n",
       "      <td>93.167854</td>\n",
       "      <td>93.087562</td>\n",
       "      <td>93.470667</td>\n",
       "      <td>93.201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.260000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-10</th>\n",
       "      <td>17493</td>\n",
       "      <td>5</td>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Santo Domingo</td>\n",
       "      <td>Santo Domingo de los Tsachilas</td>\n",
       "      <td>D</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>93.420667</td>\n",
       "      <td>93.21</td>\n",
       "      <td>93.173333</td>\n",
       "      <td>93.167877</td>\n",
       "      <td>93.092914</td>\n",
       "      <td>93.472000</td>\n",
       "      <td>93.180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.211333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-10</th>\n",
       "      <td>17494</td>\n",
       "      <td>5</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Santo Domingo</td>\n",
       "      <td>Santo Domingo de los Tsachilas</td>\n",
       "      <td>D</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>93.469333</td>\n",
       "      <td>93.21</td>\n",
       "      <td>93.176000</td>\n",
       "      <td>93.167899</td>\n",
       "      <td>93.098267</td>\n",
       "      <td>93.473333</td>\n",
       "      <td>93.159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.235667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id store_nbr      family  onpromotion           city  \\\n",
       "date                                                                  \n",
       "2013-01-10  17490         5  AUTOMOTIVE          0.0  Santo Domingo   \n",
       "2013-01-10  17491         5   BABY CARE          0.0  Santo Domingo   \n",
       "2013-01-10  17492         5      BEAUTY          0.0  Santo Domingo   \n",
       "2013-01-10  17493         5   BEVERAGES          0.0  Santo Domingo   \n",
       "2013-01-10  17494         5       BOOKS          0.0  Santo Domingo   \n",
       "\n",
       "                                     state type  total_other_promo_store  \\\n",
       "date                                                                       \n",
       "2013-01-10  Santo Domingo de los Tsachilas    D                      0.0   \n",
       "2013-01-10  Santo Domingo de los Tsachilas    D                      0.0   \n",
       "2013-01-10  Santo Domingo de los Tsachilas    D                      0.0   \n",
       "2013-01-10  Santo Domingo de los Tsachilas    D                      0.0   \n",
       "2013-01-10  Santo Domingo de los Tsachilas    D                      0.0   \n",
       "\n",
       "            total_other_city_promo holiday  ... dcoilwtico_lag_1  \\\n",
       "date                                        ...                    \n",
       "2013-01-10                     0.0     0.0  ...        93.493667   \n",
       "2013-01-10                     0.0     0.0  ...        93.469333   \n",
       "2013-01-10                     0.0     0.0  ...        93.445000   \n",
       "2013-01-10                     0.0     0.0  ...        93.420667   \n",
       "2013-01-10                     0.0     0.0  ...        93.469333   \n",
       "\n",
       "            dcoilwtico_lag_2  dcoilwtico_lag_3  dcoilwtico_lag_4  \\\n",
       "date                                                               \n",
       "2013-01-10             93.21         93.165333         93.167809   \n",
       "2013-01-10             93.21         93.168000         93.167832   \n",
       "2013-01-10             93.21         93.170667         93.167854   \n",
       "2013-01-10             93.21         93.173333         93.167877   \n",
       "2013-01-10             93.21         93.176000         93.167899   \n",
       "\n",
       "            dcoilwtico_lag_5  dcoilwtico_lag_6  dcoilwtico_lag_7  \\\n",
       "date                                                               \n",
       "2013-01-10         93.130446         93.465000            93.243   \n",
       "2013-01-10         93.082210         93.442000            93.222   \n",
       "2013-01-10         93.087562         93.470667            93.201   \n",
       "2013-01-10         93.092914         93.472000            93.180   \n",
       "2013-01-10         93.098267         93.473333            93.159   \n",
       "\n",
       "            sales_one_year_lag  Change_in_oil_prices  promo_last_7_days  \n",
       "date                                                                     \n",
       "2013-01-10                 0.0             -0.357333                0.0  \n",
       "2013-01-10                 0.0             -0.308667                0.0  \n",
       "2013-01-10                 0.0             -0.260000                0.0  \n",
       "2013-01-10                 0.0             -0.211333                0.0  \n",
       "2013-01-10                 0.0             -0.235667                0.0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = X[[\"store_nbr\", \"family\", \"sales\"]]\n",
    "X.drop(\"sales\", axis=1, inplace=True)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a037ac91-c2d5-4aa7-af0e-875f1a941da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Removing early time with NaNs\n",
    "X = X.loc[X.index >= \"2015-07-01\"]\n",
    "y = y.loc[y.index >= \"2015-07-01\"]\n",
    "\n",
    "# X = X.loc[X.index >= \"2016-01-01\"]\n",
    "# y = y.loc[y.index >= \"2016-01-01\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705516e1-83e3-42c1-a5be-f4de5165a39f",
   "metadata": {},
   "source": [
    "## Trainning Model\n",
    "###  Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "50754687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing \n",
    "from cuml.dask.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from cuml.preprocessing import MinMaxScaler, StandardScaler, SimpleImputer, LabelEncoder, OneHotEncoder\n",
    "from cuml.compose import make_column_transformer\n",
    "from statsmodels.tsa.deterministic import CalendarFourier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Cross-Validation\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# Models\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from cuml.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from cuml.neighbors import KNeighborsRegressor\n",
    "from cuml.ensemble import RandomForestRegressor\n",
    "from cuml.metrics import mean_squared_error, mean_squared_log_error\n",
    "from bayes_opt import BayesianOptimization\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from jons_time_series_functions import Prepare_data, Hybrid_Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874f29f4",
   "metadata": {},
   "source": [
    "### Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ef4cf620-0ef7-4ab0-b3df-f3df15b17564",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total GPUs detected: 1\n",
      "\n",
      "Device 0: NVIDIA GeForce RTX 4070\n",
      "  Total memory: 12.878086144 GB\n",
      "  CUDA Capability: 8.9\n",
      "  MultiProcessor Count: 46\n",
      "  Performing computation on Device 0...\n",
      "\n",
      "Summary of Results:\n",
      "Result from GPU 0: 249728400.00\n",
      "\n",
      "Average result from all GPUs: 249728400.00\n"
     ]
    }
   ],
   "source": [
    "# Function to perform a basic operation on the GPU and return the result\n",
    "def basic_gpu_operation(device):\n",
    "    # Create a random tensor of size (1000, 1000) on the specified device\n",
    "    x = torch.rand((1000, 1000), device=device)\n",
    "    # Perform a basic arithmetic operation (e.g., matrix multiplication with its transpose)\n",
    "    result = torch.matmul(x, x.t())\n",
    "    # Return the sum of the result to ensure a scalar value is returned\n",
    "    return result.sum()\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    # Print the total number of GPUs detected\n",
    "    gpu_count = torch.cuda.device_count()\n",
    "    print(f'Total GPUs detected: {gpu_count}\\n')\n",
    "    # Initialize a list to hold the results from each GPU\n",
    "    results = []\n",
    "    # Loop through all available GPUs, print their properties, perform computations, and gather results\n",
    "    for i in range(gpu_count):\n",
    "        device = torch.device(f'cuda:{i}')\n",
    "        gpu_properties = torch.cuda.get_device_properties(i)\n",
    "        print(f\"Device {i}: {gpu_properties.name}\")\n",
    "        print(f\"  Total memory: {gpu_properties.total_memory / 1e9} GB\")\n",
    "        print(f\"  CUDA Capability: {gpu_properties.major}.{gpu_properties.minor}\")\n",
    "        print(f\"  MultiProcessor Count: {gpu_properties.multi_processor_count}\")\n",
    "        print(f'  Performing computation on Device {i}...\\n')\n",
    "        # Perform the basic operation on the GPU and append the result to the results list\n",
    "        result = basic_gpu_operation(device)\n",
    "        results.append(result.item())  # Convert to Python number and append\n",
    "    # Summarize and print the results from each GPU\n",
    "    print('Summary of Results:')\n",
    "    for i, result in enumerate(results):\n",
    "        print(f'Result from GPU {i}: {result:.2f}')\n",
    "    # Perform some aggregation on the CPU (e.g., compute the average of all results)\n",
    "    results = cp.array(results)\n",
    "    average_result = cp.mean(results)\n",
    "    print(f'\\nAverage result from all GPUs: {average_result:.2f}')\n",
    "    # Optionally, provide a summary of overall GPU utilization or performance here\n",
    "    # This could involve more detailed metrics based on your specific use case or application\n",
    "else:\n",
    "    print(\"CUDA is not available. Please check your installation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "465ff6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSLELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse=nn.MSELoss().to(device)\n",
    "        \n",
    "    def forward(self, pred, actual):\n",
    "        return self.mse(torch.log(pred+1), torch.log(actual + 1))\n",
    "    \n",
    "    \n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_layer, n_hidden_1, n_hidden_2, drop):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        \n",
    "        self.input_layer = input_layer\n",
    "        self.n_hidden_1 = n_hidden_1\n",
    "        self.n_hidden_2 = n_hidden_2\n",
    "        \n",
    "        # Layers: Linear, LSTM, Linear\n",
    "        self.linear1 = nn.Linear(input_layer, n_hidden_1)\n",
    "        self.dropout = nn.Dropout(drop)\n",
    "        self.lstm = nn.LSTM(n_hidden_1, n_hidden_2, batch_first=True)\n",
    "        self.linear2 = nn.Linear(n_hidden_2, 1)\n",
    "        self.ReLU = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.linear1(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        output, (h_t, c_t) = self.lstm(x)\n",
    "        output = self.dropout(output)\n",
    "        output = self.linear2(output)\n",
    "        output = self.ReLU(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "class LSTMRegressor():\n",
    "    def __init__(self, n_hidden=50, n_hidden_2=20, drop=0.2, epochs=100, early_stop=5, lr=0.01, Boosted=False):\n",
    "        \n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_hidden_2 = n_hidden_2\n",
    "        self.drop = drop\n",
    "        if Boosted:\n",
    "            self.criterion = nn.MSELoss().to(device)\n",
    "        else: \n",
    "            self.criterion = MSLELoss()\n",
    "            \n",
    "        self.early_stop = early_stop \n",
    "        self.epochs = epochs \n",
    "        self.lr = lr\n",
    "        self.min_val_loss = float('inf')\n",
    "        self.min_val_loss_2 = float('inf')\n",
    "        \n",
    "    def train(self, train_loader):\n",
    "        \n",
    "        self.model.train()\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            x_batch, y_batch = x_batch, y_batch\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(x_batch)\n",
    "            loss = self.criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "\n",
    "    def pred(self, test_loader, valid=False, epoch=0):\n",
    "        \n",
    "        self.model.eval()\n",
    "        if valid:\n",
    "             \n",
    "            val_losses = 0\n",
    "            num = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for x_batch, y_batch in test_loader:\n",
    "                    x_batch = x_batch\n",
    "                    outputs = self.model(x_batch)\n",
    "\n",
    "                    loss = self.criterion(outputs, y_batch)\n",
    "                    val_losses=+loss.item()\n",
    "\n",
    "                    num=+1\n",
    "\n",
    "            val_loss = val_losses/num\n",
    "\n",
    "            if val_loss<self.min_val_loss:\n",
    "            \n",
    "                self.min_val_loss = val_loss\n",
    "                self.early_stop_count = 0\n",
    "            else:\n",
    "                self.early_stop_count+=1\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}/{self.epochs}, Validation score of {np.sqrt(val_loss):.4f}\")\n",
    "            if self.early_stop_count>=self.early_stop:\n",
    "                print(f\"early stopping at Validation Score of {np.sqrt(self.min_val_loss):.4f}\")\n",
    "                print()\n",
    "                self.stop = True\n",
    "\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                predictions = []\n",
    "                for x_batch in test_loader:\n",
    "                    x_batch = x_batch.to(device)\n",
    "                    outputs = self.model(x_batch)\n",
    "                    predictions.append(outputs.cpu().numpy())\n",
    "\n",
    "                return np.concatenate(predictions)\n",
    "                \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        \n",
    "        if isinstance(X, list):\n",
    "            X_train, y_train = X[0], y[0]\n",
    "            self.model = LSTMModel(X_train.shape[1], n_hidden_1=self.n_hidden, n_hidden_2= self.n_hidden_2, drop=self.drop).to(device)\n",
    "            \n",
    "            self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "            train_loader = DataLoader(TensorDataset(X_train.to(device), y_train.to(device)), batch_size=31, shuffle=False)\n",
    "            \n",
    "            X_valid, y_valid = X[1], y[1]\n",
    "            test_loader = DataLoader(TensorDataset(X_valid.to(device), y_valid.to(device)), batch_size=31, shuffle=False)\n",
    "            \n",
    "            self.stop=False\n",
    "            self.early_stop_count =0 \n",
    "            \n",
    "            for epoch in range(self.epochs):\n",
    "                self.train(train_loader)\n",
    "                \n",
    "                self.pred(test_loader, valid=True, epoch=epoch)\n",
    "                if self.stop:\n",
    "                    break\n",
    "\n",
    "        else:\n",
    "                X_train, y_train = X, y\n",
    "                self.model = LSTMModel(X_train.shape[1], n_hidden_1=self.n_hidden, n_hidden_2= self.n_hidden_2, drop=self.drop).to(device)\n",
    "                \n",
    "                self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "                train_loader = DataLoader(TensorDataset(X_train.to(device), y_train.to(device)), batch_size=31, shuffle=False)\n",
    "                \n",
    "                for epoch in range(self.epochs):\n",
    "                    self.train(train_loader)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \n",
    "        test_loader = DataLoader(X.to(device), batch_size=31, shuffle=False)\n",
    "        \n",
    "        outputs = self.pred(test_loader)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bd09e7",
   "metadata": {},
   "source": [
    "### Trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "002a6c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the preprocessing steps\n",
    "numeric_transformer = [\"float\", StandardScaler()]\n",
    "categorical_transformer = [\"category\", OneHotEncoder(sparse=False, handle_unknown='ignore')]\n",
    "\n",
    "column_list = [\"time_since_quake\", \"time_since_quake_sq\"]\n",
    "\n",
    "#data_preprocessor = Prepare_data(column_list, [numeric_transformer, categorical_transformer])\n",
    "data_preprocessor = Prepare_data(column_list, [numeric_transformer])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39912e5",
   "metadata": {},
   "source": [
    "## Linear Regression, XGBoost, Boosted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b5a6e7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_C = X.copy()\n",
    "\n",
    "\n",
    "# X_C[\"family\"] = X_C[\"family\"].cat.codes\n",
    "# X_C[\"store_nbr\"] = X_C[\"store_nbr\"].cat.codes\n",
    "# X[\"holiday\"] = X_C[\"holiday\"].cat.codes\n",
    "# X_C[\"event\"] = X[\"event\"].cat.codes\n",
    "# X_C[\"city\"] = X_C[\"city\"].cat.codes\n",
    "# X_C[\"state\"] = X_C[\"state\"].cat.codes\n",
    "# X_C[\"type\"] = X_C[\"type\"].cat.codes\n",
    "\n",
    "X_C = X_C[[\"id\", \"store_nbr\", \"family\"] + sorted(set(X_C.columns)-set([\"id\", \"store_nbr\", \"family\"]))]\n",
    "\n",
    "X_C = X_C.reset_index().sort_values([\"store_nbr\", \"family\", \"date\"]).set_index([\"date\"])\n",
    "y = y.reset_index().sort_values([\"store_nbr\", \"family\", \"date\"]).set_index([\"date\"])\n",
    "# X_C = X_C.set_index([\"date\"])\n",
    "# y = y.set_index([\"date\"])\n",
    "\n",
    "X_test_C = X_test.copy()\n",
    "X_test_C = X_test_C[[\"id\", \"store_nbr\", \"family\"] + sorted(set(X_test_C.columns)-set([\"id\", \"store_nbr\", \"family\"]))]\n",
    "#.drop([\"state\", \"city\", \"type\", \"dayofyear\", \"year\"], axis=1)\n",
    "X_test_C = X_test_C.reset_index().sort_values([\"store_nbr\", \"family\", \"date\"])\n",
    "X_test_C = X_test_C.set_index([\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "be920998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def feature_importance(X, y, model):\n",
    "    \n",
    "#     dates = X.index.drop_duplicates()\n",
    "    \n",
    "#     X_train = X.loc[dates[int(len(dates)*2/3):]]\n",
    "#     X_valid = X.loc[dates[:int(len(dates)*2/3)]]\n",
    "    \n",
    "#     y_train = y.loc[dates[int(len(dates)*2/3):]]\n",
    "#     y_valid = y.loc[dates[:int(len(dates)*2/3)]]\n",
    "    \n",
    "#     model.fit(X_train, y_train)\n",
    "    \n",
    "#     del X_train\n",
    "#     del y_train\n",
    "    \n",
    "#     pred = model.predict(X_valid)\n",
    "#     baseline = float(np.sqrt(mean_squared_log_error(y_valid.sales, pred.sales)))\n",
    "#     importance_dict = {}\n",
    "    \n",
    "#     for i in range(1, len(X_valid.columns)):\n",
    "        \n",
    "#         name = X_valid.columns[i]\n",
    "#         X_shuffle = X_valid.copy()\n",
    "#         X_shuffle = X_shuffle.to_pandas()\n",
    "#         X_shuffle[name] = X_shuffle[name].values[np.random.permutation(len(X_shuffle))]\n",
    "        \n",
    "#         X_shuffle = cudf.from_pandas(X_shuffle)\n",
    "#         pred = model.predict(X_shuffle)\n",
    "        \n",
    "#         del X_shuffle\n",
    "        \n",
    "#         importance_dict[name] = float(np.sqrt(mean_squared_log_error(y_valid.sales, pred.sales))) - baseline\n",
    "        \n",
    "        \n",
    "#     return importance_dict\n",
    "        \n",
    "    \n",
    "# xgb_params = {\n",
    "#     'tree_method': 'gpu_hist',  # Specify GPU usage\n",
    "#     'predictor': 'gpu_predictor',\n",
    "#     'enable_categorical': True,\n",
    "# }\n",
    "\n",
    "# xgb = XGBRegressor(**xgb_params)\n",
    "\n",
    "\n",
    "# lr = LinearRegression(fit_intercept=False, algorithm=\"svd\", copy_X=True)\n",
    "\n",
    "# model = Hybrid_Pipeline(data_preprocessor, lr, xgb, Boosted=True, to_tensor=False)\n",
    "\n",
    "# feature_df = pd.DataFrame.from_dict(feature_importance(X_C, y, model), orient='index', columns=['Change in MSE']).reset_index().sort_values(\"Change in MSE\")\n",
    "# feature_df = feature_df.rename({\"index\": \"Columns\"}, axis=1)\n",
    "# feature_df.plot.barh(x='Columns', y='Change in MSE', title='Feature Importance', color='blue')\n",
    "\n",
    "#X_C = X_C[feature_df.loc[feature_df[\"Change in MSE\"]>=0][\"Columns\"].append(pd.Series([\"store_nbr\", \"family\", \"id\"]), ignore_index=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "07850848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | Change... |   city    |    day    | dayofyear | dcoilw... | dcoilw... | dcoilw... | dcoilw... | dcoilw... | dcoilw... | dcoilw... | dcoilw... |   event   |  holiday  | holida... |   month   | onprom... | onprom... | onprom... | onprom... | onprom... | onprom... | onprom... | onprom... |  payday   | promo_... | sales_... |   state   | time_s... | time_s... | total_... | total_... |   type    |  workday  |   year    |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m-1.189   \u001b[0m | \u001b[0m0.417    \u001b[0m | \u001b[0m0.7203   \u001b[0m | \u001b[0m0.0001144\u001b[0m | \u001b[0m0.3023   \u001b[0m | \u001b[0m0.1468   \u001b[0m | \u001b[0m0.09234  \u001b[0m | \u001b[0m0.1863   \u001b[0m | \u001b[0m0.3456   \u001b[0m | \u001b[0m0.3968   \u001b[0m | \u001b[0m0.5388   \u001b[0m | \u001b[0m0.4192   \u001b[0m | \u001b[0m0.6852   \u001b[0m | \u001b[0m0.2045   \u001b[0m | \u001b[0m0.8781   \u001b[0m | \u001b[0m0.02739  \u001b[0m | \u001b[0m0.6705   \u001b[0m | \u001b[0m0.4173   \u001b[0m | \u001b[0m0.5587   \u001b[0m | \u001b[0m0.1404   \u001b[0m | \u001b[0m0.1981   \u001b[0m | \u001b[0m0.8007   \u001b[0m | \u001b[0m0.9683   \u001b[0m | \u001b[0m0.3134   \u001b[0m | \u001b[0m0.6923   \u001b[0m | \u001b[0m0.8764   \u001b[0m | \u001b[0m0.8946   \u001b[0m | \u001b[0m0.08504  \u001b[0m | \u001b[0m0.03905  \u001b[0m | \u001b[0m0.1698   \u001b[0m | \u001b[0m0.8781   \u001b[0m | \u001b[0m0.09835  \u001b[0m | \u001b[0m0.4211   \u001b[0m | \u001b[0m0.9579   \u001b[0m | \u001b[0m0.5332   \u001b[0m | \u001b[0m0.6919   \u001b[0m |\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m-0.9842  \u001b[0m | \u001b[95m0.3155   \u001b[0m | \u001b[95m0.6865   \u001b[0m | \u001b[95m0.8346   \u001b[0m | \u001b[95m0.01829  \u001b[0m | \u001b[95m0.7501   \u001b[0m | \u001b[95m0.9889   \u001b[0m | \u001b[95m0.7482   \u001b[0m | \u001b[95m0.2804   \u001b[0m | \u001b[95m0.7893   \u001b[0m | \u001b[95m0.1032   \u001b[0m | \u001b[95m0.4479   \u001b[0m | \u001b[95m0.9086   \u001b[0m | \u001b[95m0.2936   \u001b[0m | \u001b[95m0.2878   \u001b[0m | \u001b[95m0.13     \u001b[0m | \u001b[95m0.01937  \u001b[0m | \u001b[95m0.6788   \u001b[0m | \u001b[95m0.2116   \u001b[0m | \u001b[95m0.2655   \u001b[0m | \u001b[95m0.4916   \u001b[0m | \u001b[95m0.05336  \u001b[0m | \u001b[95m0.5741   \u001b[0m | \u001b[95m0.1467   \u001b[0m | \u001b[95m0.5893   \u001b[0m | \u001b[95m0.6998   \u001b[0m | \u001b[95m0.1023   \u001b[0m | \u001b[95m0.4141   \u001b[0m | \u001b[95m0.6944   \u001b[0m | \u001b[95m0.4142   \u001b[0m | \u001b[95m0.04995  \u001b[0m | \u001b[95m0.5359   \u001b[0m | \u001b[95m0.6638   \u001b[0m | \u001b[95m0.5149   \u001b[0m | \u001b[95m0.9446   \u001b[0m | \u001b[95m0.5866   \u001b[0m |\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m-1.373   \u001b[0m | \u001b[0m0.9034   \u001b[0m | \u001b[0m0.1375   \u001b[0m | \u001b[0m0.1393   \u001b[0m | \u001b[0m0.8074   \u001b[0m | \u001b[0m0.3977   \u001b[0m | \u001b[0m0.1654   \u001b[0m | \u001b[0m0.9275   \u001b[0m | \u001b[0m0.3478   \u001b[0m | \u001b[0m0.7508   \u001b[0m | \u001b[0m0.726    \u001b[0m | \u001b[0m0.8833   \u001b[0m | \u001b[0m0.6237   \u001b[0m | \u001b[0m0.7509   \u001b[0m | \u001b[0m0.3489   \u001b[0m | \u001b[0m0.2699   \u001b[0m | \u001b[0m0.8959   \u001b[0m | \u001b[0m0.4281   \u001b[0m | \u001b[0m0.9648   \u001b[0m | \u001b[0m0.6634   \u001b[0m | \u001b[0m0.6217   \u001b[0m | \u001b[0m0.1147   \u001b[0m | \u001b[0m0.9495   \u001b[0m | \u001b[0m0.4499   \u001b[0m | \u001b[0m0.5784   \u001b[0m | \u001b[0m0.4081   \u001b[0m | \u001b[0m0.237    \u001b[0m | \u001b[0m0.9034   \u001b[0m | \u001b[0m0.5737   \u001b[0m | \u001b[0m0.00287  \u001b[0m | \u001b[0m0.6171   \u001b[0m | \u001b[0m0.3266   \u001b[0m | \u001b[0m0.5271   \u001b[0m | \u001b[0m0.8859   \u001b[0m | \u001b[0m0.3573   \u001b[0m | \u001b[0m0.9085   \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m-1.226   \u001b[0m | \u001b[0m0.6234   \u001b[0m | \u001b[0m0.01582  \u001b[0m | \u001b[0m0.9294   \u001b[0m | \u001b[0m0.6909   \u001b[0m | \u001b[0m0.9973   \u001b[0m | \u001b[0m0.1723   \u001b[0m | \u001b[0m0.1371   \u001b[0m | \u001b[0m0.9326   \u001b[0m | \u001b[0m0.6968   \u001b[0m | \u001b[0m0.066    \u001b[0m | \u001b[0m0.7555   \u001b[0m | \u001b[0m0.7539   \u001b[0m | \u001b[0m0.923    \u001b[0m | \u001b[0m0.7115   \u001b[0m | \u001b[0m0.1243   \u001b[0m | \u001b[0m0.01988  \u001b[0m | \u001b[0m0.02621  \u001b[0m | \u001b[0m0.02831  \u001b[0m | \u001b[0m0.2462   \u001b[0m | \u001b[0m0.86     \u001b[0m | \u001b[0m0.5388   \u001b[0m | \u001b[0m0.5528   \u001b[0m | \u001b[0m0.842    \u001b[0m | \u001b[0m0.1242   \u001b[0m | \u001b[0m0.2792   \u001b[0m | \u001b[0m0.5858   \u001b[0m | \u001b[0m0.9696   \u001b[0m | \u001b[0m0.561    \u001b[0m | \u001b[0m0.01865  \u001b[0m | \u001b[0m0.8006   \u001b[0m | \u001b[0m0.233    \u001b[0m | \u001b[0m0.8071   \u001b[0m | \u001b[0m0.3879   \u001b[0m | \u001b[0m0.8635   \u001b[0m | \u001b[0m0.7471   \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m-1.326   \u001b[0m | \u001b[0m0.5562   \u001b[0m | \u001b[0m0.1365   \u001b[0m | \u001b[0m0.05992  \u001b[0m | \u001b[0m0.1213   \u001b[0m | \u001b[0m0.04455  \u001b[0m | \u001b[0m0.1075   \u001b[0m | \u001b[0m0.2257   \u001b[0m | \u001b[0m0.713    \u001b[0m | \u001b[0m0.5597   \u001b[0m | \u001b[0m0.01256  \u001b[0m | \u001b[0m0.07197  \u001b[0m | \u001b[0m0.9673   \u001b[0m | \u001b[0m0.5681   \u001b[0m | \u001b[0m0.2033   \u001b[0m | \u001b[0m0.2523   \u001b[0m | \u001b[0m0.7438   \u001b[0m | \u001b[0m0.1954   \u001b[0m | \u001b[0m0.5814   \u001b[0m | \u001b[0m0.97     \u001b[0m | \u001b[0m0.8468   \u001b[0m | \u001b[0m0.2398   \u001b[0m | \u001b[0m0.4938   \u001b[0m | \u001b[0m0.62     \u001b[0m | \u001b[0m0.829    \u001b[0m | \u001b[0m0.1568   \u001b[0m | \u001b[0m0.01858  \u001b[0m | \u001b[0m0.07002  \u001b[0m | \u001b[0m0.4863   \u001b[0m | \u001b[0m0.6063   \u001b[0m | \u001b[0m0.5689   \u001b[0m | \u001b[0m0.3174   \u001b[0m | \u001b[0m0.9886   \u001b[0m | \u001b[0m0.5797   \u001b[0m | \u001b[0m0.3801   \u001b[0m | \u001b[0m0.5509   \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m-1.013   \u001b[0m | \u001b[0m0.7453   \u001b[0m | \u001b[0m0.6692   \u001b[0m | \u001b[0m0.2649   \u001b[0m | \u001b[0m0.06633  \u001b[0m | \u001b[0m0.3701   \u001b[0m | \u001b[0m0.6297   \u001b[0m | \u001b[0m0.2102   \u001b[0m | \u001b[0m0.7528   \u001b[0m | \u001b[0m0.06654  \u001b[0m | \u001b[0m0.2603   \u001b[0m | \u001b[0m0.8048   \u001b[0m | \u001b[0m0.1934   \u001b[0m | \u001b[0m0.6395   \u001b[0m | \u001b[0m0.5247   \u001b[0m | \u001b[0m0.9248   \u001b[0m | \u001b[0m0.2633   \u001b[0m | \u001b[0m0.06596  \u001b[0m | \u001b[0m0.7351   \u001b[0m | \u001b[0m0.7722   \u001b[0m | \u001b[0m0.9078   \u001b[0m | \u001b[0m0.932    \u001b[0m | \u001b[0m0.01395  \u001b[0m | \u001b[0m0.2344   \u001b[0m | \u001b[0m0.6168   \u001b[0m | \u001b[0m0.949    \u001b[0m | \u001b[0m0.9502   \u001b[0m | \u001b[0m0.5567   \u001b[0m | \u001b[0m0.9156   \u001b[0m | \u001b[0m0.6416   \u001b[0m | \u001b[0m0.39     \u001b[0m | \u001b[0m0.486    \u001b[0m | \u001b[0m0.6043   \u001b[0m | \u001b[0m0.5495   \u001b[0m | \u001b[0m0.9262   \u001b[0m | \u001b[0m0.9187   \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m-1.161   \u001b[0m | \u001b[0m0.3949   \u001b[0m | \u001b[0m0.9633   \u001b[0m | \u001b[0m0.174    \u001b[0m | \u001b[0m0.1263   \u001b[0m | \u001b[0m0.1351   \u001b[0m | \u001b[0m0.5057   \u001b[0m | \u001b[0m0.02152  \u001b[0m | \u001b[0m0.948    \u001b[0m | \u001b[0m0.8271   \u001b[0m | \u001b[0m0.01502  \u001b[0m | \u001b[0m0.1762   \u001b[0m | \u001b[0m0.3321   \u001b[0m | \u001b[0m0.131    \u001b[0m | \u001b[0m0.8095   \u001b[0m | \u001b[0m0.3447   \u001b[0m | \u001b[0m0.9401   \u001b[0m | \u001b[0m0.582    \u001b[0m | \u001b[0m0.8788   \u001b[0m | \u001b[0m0.8447   \u001b[0m | \u001b[0m0.9054   \u001b[0m | \u001b[0m0.4599   \u001b[0m | \u001b[0m0.5463   \u001b[0m | \u001b[0m0.7986   \u001b[0m | \u001b[0m0.2857   \u001b[0m | \u001b[0m0.4903   \u001b[0m | \u001b[0m0.5991   \u001b[0m | \u001b[0m0.01553  \u001b[0m | \u001b[0m0.5935   \u001b[0m | \u001b[0m0.4337   \u001b[0m | \u001b[0m0.8074   \u001b[0m | \u001b[0m0.3152   \u001b[0m | \u001b[0m0.8929   \u001b[0m | \u001b[0m0.5779   \u001b[0m | \u001b[0m0.184    \u001b[0m | \u001b[0m0.7879   \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m-1.654   \u001b[0m | \u001b[0m0.612    \u001b[0m | \u001b[0m0.05391  \u001b[0m | \u001b[0m0.4202   \u001b[0m | \u001b[0m0.6791   \u001b[0m | \u001b[0m0.9186   \u001b[0m | \u001b[0m0.000402 \u001b[0m | \u001b[0m0.9768   \u001b[0m | \u001b[0m0.3766   \u001b[0m | \u001b[0m0.9738   \u001b[0m | \u001b[0m0.6047   \u001b[0m | \u001b[0m0.8288   \u001b[0m | \u001b[0m0.5747   \u001b[0m | \u001b[0m0.6281   \u001b[0m | \u001b[0m0.2856   \u001b[0m | \u001b[0m0.5868   \u001b[0m | \u001b[0m0.75     \u001b[0m | \u001b[0m0.8583   \u001b[0m | \u001b[0m0.7551   \u001b[0m | \u001b[0m0.6981   \u001b[0m | \u001b[0m0.8645   \u001b[0m | \u001b[0m0.3227   \u001b[0m | \u001b[0m0.6708   \u001b[0m | \u001b[0m0.4509   \u001b[0m | \u001b[0m0.3821   \u001b[0m | \u001b[0m0.4108   \u001b[0m | \u001b[0m0.4015   \u001b[0m | \u001b[0m0.3174   \u001b[0m | \u001b[0m0.6219   \u001b[0m | \u001b[0m0.4302   \u001b[0m | \u001b[0m0.9738   \u001b[0m | \u001b[0m0.6778   \u001b[0m | \u001b[0m0.1986   \u001b[0m | \u001b[0m0.4267   \u001b[0m | \u001b[0m0.3433   \u001b[0m | \u001b[0m0.7976   \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m-1.046   \u001b[0m | \u001b[0m0.88     \u001b[0m | \u001b[0m0.9038   \u001b[0m | \u001b[0m0.6627   \u001b[0m | \u001b[0m0.2702   \u001b[0m | \u001b[0m0.2524   \u001b[0m | \u001b[0m0.8549   \u001b[0m | \u001b[0m0.5277   \u001b[0m | \u001b[0m0.8022   \u001b[0m | \u001b[0m0.5725   \u001b[0m | \u001b[0m0.7331   \u001b[0m | \u001b[0m0.519    \u001b[0m | \u001b[0m0.7709   \u001b[0m | \u001b[0m0.5689   \u001b[0m | \u001b[0m0.4657   \u001b[0m | \u001b[0m0.3427   \u001b[0m | \u001b[0m0.06821  \u001b[0m | \u001b[0m0.3779   \u001b[0m | \u001b[0m0.07963  \u001b[0m | \u001b[0m0.9828   \u001b[0m | \u001b[0m0.1816   \u001b[0m | \u001b[0m0.8119   \u001b[0m | \u001b[0m0.875    \u001b[0m | \u001b[0m0.6884   \u001b[0m | \u001b[0m0.5695   \u001b[0m | \u001b[0m0.161    \u001b[0m | \u001b[0m0.4669   \u001b[0m | \u001b[0m0.3452   \u001b[0m | \u001b[0m0.225    \u001b[0m | \u001b[0m0.5925   \u001b[0m | \u001b[0m0.3123   \u001b[0m | \u001b[0m0.9163   \u001b[0m | \u001b[0m0.9096   \u001b[0m | \u001b[0m0.2571   \u001b[0m | \u001b[0m0.1109   \u001b[0m | \u001b[0m0.193    \u001b[0m |\n",
      "| \u001b[95m10       \u001b[0m | \u001b[95m-0.9531  \u001b[0m | \u001b[95m0.4996   \u001b[0m | \u001b[95m0.7286   \u001b[0m | \u001b[95m0.2082   \u001b[0m | \u001b[95m0.248    \u001b[0m | \u001b[95m0.8517   \u001b[0m | \u001b[95m0.4158   \u001b[0m | \u001b[95m0.6167   \u001b[0m | \u001b[95m0.2337   \u001b[0m | \u001b[95m0.102    \u001b[0m | \u001b[95m0.5159   \u001b[0m | \u001b[95m0.4771   \u001b[0m | \u001b[95m0.1527   \u001b[0m | \u001b[95m0.6218   \u001b[0m | \u001b[95m0.544    \u001b[0m | \u001b[95m0.6541   \u001b[0m | \u001b[95m0.1445   \u001b[0m | \u001b[95m0.7515   \u001b[0m | \u001b[95m0.222    \u001b[0m | \u001b[95m0.5194   \u001b[0m | \u001b[95m0.7853   \u001b[0m | \u001b[95m0.02233  \u001b[0m | \u001b[95m0.3244   \u001b[0m | \u001b[95m0.8729   \u001b[0m | \u001b[95m0.8447   \u001b[0m | \u001b[95m0.5384   \u001b[0m | \u001b[95m0.8666   \u001b[0m | \u001b[95m0.9498   \u001b[0m | \u001b[95m0.8264   \u001b[0m | \u001b[95m0.8541   \u001b[0m | \u001b[95m0.09874  \u001b[0m | \u001b[95m0.6513   \u001b[0m | \u001b[95m0.7035   \u001b[0m | \u001b[95m0.6102   \u001b[0m | \u001b[95m0.7996   \u001b[0m | \u001b[95m0.03457  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m11       \u001b[0m | \u001b[0m-1.091   \u001b[0m | \u001b[0m0.7702   \u001b[0m | \u001b[0m0.7317   \u001b[0m | \u001b[0m0.2597   \u001b[0m | \u001b[0m0.2571   \u001b[0m | \u001b[0m0.6323   \u001b[0m | \u001b[0m0.3453   \u001b[0m | \u001b[0m0.7966   \u001b[0m | \u001b[0m0.4461   \u001b[0m | \u001b[0m0.7827   \u001b[0m | \u001b[0m0.9905   \u001b[0m | \u001b[0m0.3002   \u001b[0m | \u001b[0m0.143    \u001b[0m | \u001b[0m0.9013   \u001b[0m | \u001b[0m0.5416   \u001b[0m | \u001b[0m0.9747   \u001b[0m | \u001b[0m0.6366   \u001b[0m | \u001b[0m0.9939   \u001b[0m | \u001b[0m0.5461   \u001b[0m | \u001b[0m0.5264   \u001b[0m | \u001b[0m0.1354   \u001b[0m | \u001b[0m0.3557   \u001b[0m | \u001b[0m0.02622  \u001b[0m | \u001b[0m0.1604   \u001b[0m | \u001b[0m0.7456   \u001b[0m | \u001b[0m0.0304   \u001b[0m | \u001b[0m0.3665   \u001b[0m | \u001b[0m0.8623   \u001b[0m | \u001b[0m0.6927   \u001b[0m | \u001b[0m0.6909   \u001b[0m | \u001b[0m0.1886   \u001b[0m | \u001b[0m0.4419   \u001b[0m | \u001b[0m0.5816   \u001b[0m | \u001b[0m0.9898   \u001b[0m | \u001b[0m0.2039   \u001b[0m | \u001b[0m0.2477   \u001b[0m |\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m-1.292   \u001b[0m | \u001b[0m0.2622   \u001b[0m | \u001b[0m0.7502   \u001b[0m | \u001b[0m0.457    \u001b[0m | \u001b[0m0.05693  \u001b[0m | \u001b[0m0.5085   \u001b[0m | \u001b[0m0.212    \u001b[0m | \u001b[0m0.7986   \u001b[0m | \u001b[0m0.2973   \u001b[0m | \u001b[0m0.02761  \u001b[0m | \u001b[0m0.5934   \u001b[0m | \u001b[0m0.8438   \u001b[0m | \u001b[0m0.381    \u001b[0m | \u001b[0m0.7499   \u001b[0m | \u001b[0m0.5111   \u001b[0m | \u001b[0m0.541    \u001b[0m | \u001b[0m0.9594   \u001b[0m | \u001b[0m0.804    \u001b[0m | \u001b[0m0.03232  \u001b[0m | \u001b[0m0.7094   \u001b[0m | \u001b[0m0.465    \u001b[0m | \u001b[0m0.9475   \u001b[0m | \u001b[0m0.2214   \u001b[0m | \u001b[0m0.2671   \u001b[0m | \u001b[0m0.08147  \u001b[0m | \u001b[0m0.4286   \u001b[0m | \u001b[0m0.109    \u001b[0m | \u001b[0m0.6338   \u001b[0m | \u001b[0m0.803    \u001b[0m | \u001b[0m0.6968   \u001b[0m | \u001b[0m0.7662   \u001b[0m | \u001b[0m0.3425   \u001b[0m | \u001b[0m0.8459   \u001b[0m | \u001b[0m0.4288   \u001b[0m | \u001b[0m0.824    \u001b[0m | \u001b[0m0.6265   \u001b[0m |\n",
      "| \u001b[95m13       \u001b[0m | \u001b[95m-0.8743  \u001b[0m | \u001b[95m0.1434   \u001b[0m | \u001b[95m0.07839  \u001b[0m | \u001b[95m0.01833  \u001b[0m | \u001b[95m0.06672  \u001b[0m | \u001b[95m0.4586   \u001b[0m | \u001b[95m0.1133   \u001b[0m | \u001b[95m0.02778  \u001b[0m | \u001b[95m0.7549   \u001b[0m | \u001b[95m0.3949   \u001b[0m | \u001b[95m0.7469   \u001b[0m | \u001b[95m0.4524   \u001b[0m | \u001b[95m0.4501   \u001b[0m | \u001b[95m0.4781   \u001b[0m | \u001b[95m0.474    \u001b[0m | \u001b[95m0.8032   \u001b[0m | \u001b[95m0.4024   \u001b[0m | \u001b[95m0.9047   \u001b[0m | \u001b[95m0.03706  \u001b[0m | \u001b[95m0.7739   \u001b[0m | \u001b[95m0.1256   \u001b[0m | \u001b[95m0.6185   \u001b[0m | \u001b[95m0.01036  \u001b[0m | \u001b[95m0.5386   \u001b[0m | \u001b[95m0.003018 \u001b[0m | \u001b[95m0.9512   \u001b[0m | \u001b[95m0.9054   \u001b[0m | \u001b[95m0.796    \u001b[0m | \u001b[95m0.9153   \u001b[0m | \u001b[95m0.1456   \u001b[0m | \u001b[95m0.1577   \u001b[0m | \u001b[95m0.1876   \u001b[0m | \u001b[95m0.6225   \u001b[0m | \u001b[95m0.9058   \u001b[0m | \u001b[95m0.99     \u001b[0m | \u001b[95m0.7111   \u001b[0m |\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m-1.091   \u001b[0m | \u001b[0m0.7318   \u001b[0m | \u001b[0m0.9093   \u001b[0m | \u001b[0m0.4009   \u001b[0m | \u001b[0m0.2499   \u001b[0m | \u001b[0m0.1734   \u001b[0m | \u001b[0m0.1195   \u001b[0m | \u001b[0m0.8126   \u001b[0m | \u001b[0m0.1468   \u001b[0m | \u001b[0m0.2643   \u001b[0m | \u001b[0m0.8191   \u001b[0m | \u001b[0m0.3106   \u001b[0m | \u001b[0m0.9824   \u001b[0m | \u001b[0m0.2666   \u001b[0m | \u001b[0m0.5337   \u001b[0m | \u001b[0m0.3145   \u001b[0m | \u001b[0m0.9108   \u001b[0m | \u001b[0m0.3666   \u001b[0m | \u001b[0m0.4336   \u001b[0m | \u001b[0m0.5123   \u001b[0m | \u001b[0m0.9389   \u001b[0m | \u001b[0m0.03095  \u001b[0m | \u001b[0m0.7169   \u001b[0m | \u001b[0m0.891    \u001b[0m | \u001b[0m0.02729  \u001b[0m | \u001b[0m0.5221   \u001b[0m | \u001b[0m0.326    \u001b[0m | \u001b[0m0.8595   \u001b[0m | \u001b[0m0.5585   \u001b[0m | \u001b[0m0.6902   \u001b[0m | \u001b[0m0.4529   \u001b[0m | \u001b[0m0.6283   \u001b[0m | \u001b[0m0.2901   \u001b[0m | \u001b[0m0.009349 \u001b[0m | \u001b[0m0.5768   \u001b[0m | \u001b[0m0.3114   \u001b[0m |\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m-1.223   \u001b[0m | \u001b[0m0.5173   \u001b[0m | \u001b[0m0.9164   \u001b[0m | \u001b[0m0.4265   \u001b[0m | \u001b[0m0.2474   \u001b[0m | \u001b[0m0.3713   \u001b[0m | \u001b[0m0.9319   \u001b[0m | \u001b[0m0.9369   \u001b[0m | \u001b[0m0.8443   \u001b[0m | \u001b[0m0.9202   \u001b[0m | \u001b[0m0.2279   \u001b[0m | \u001b[0m0.08748  \u001b[0m | \u001b[0m0.2273   \u001b[0m | \u001b[0m0.3144   \u001b[0m | \u001b[0m0.1748   \u001b[0m | \u001b[0m0.6071   \u001b[0m | \u001b[0m0.4136   \u001b[0m | \u001b[0m0.8164   \u001b[0m | \u001b[0m0.1851   \u001b[0m | \u001b[0m0.7019   \u001b[0m | \u001b[0m0.2404   \u001b[0m | \u001b[0m0.5742   \u001b[0m | \u001b[0m0.349    \u001b[0m | \u001b[0m0.05696  \u001b[0m | \u001b[0m0.2288   \u001b[0m | \u001b[0m0.6641   \u001b[0m | \u001b[0m0.4973   \u001b[0m | \u001b[0m0.519    \u001b[0m | \u001b[0m0.1747   \u001b[0m | \u001b[0m0.5707   \u001b[0m | \u001b[0m0.9968   \u001b[0m | \u001b[0m0.8168   \u001b[0m | \u001b[0m0.5944   \u001b[0m | \u001b[0m0.976    \u001b[0m | \u001b[0m0.9016   \u001b[0m | \u001b[0m0.5956   \u001b[0m |\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m-0.9347  \u001b[0m | \u001b[0m0.03243  \u001b[0m | \u001b[0m0.09358  \u001b[0m | \u001b[0m0.06537  \u001b[0m | \u001b[0m0.4517   \u001b[0m | \u001b[0m0.3754   \u001b[0m | \u001b[0m0.9754   \u001b[0m | \u001b[0m0.168    \u001b[0m | \u001b[0m0.9728   \u001b[0m | \u001b[0m0.7675   \u001b[0m | \u001b[0m0.8242   \u001b[0m | \u001b[0m0.6326   \u001b[0m | \u001b[0m0.6687   \u001b[0m | \u001b[0m0.4769   \u001b[0m | \u001b[0m0.01314  \u001b[0m | \u001b[0m0.353    \u001b[0m | \u001b[0m0.4921   \u001b[0m | \u001b[0m0.7301   \u001b[0m | \u001b[0m0.4686   \u001b[0m | \u001b[0m0.4574   \u001b[0m | \u001b[0m0.1377   \u001b[0m | \u001b[0m0.01089  \u001b[0m | \u001b[0m0.7583   \u001b[0m | \u001b[0m0.32     \u001b[0m | \u001b[0m0.9844   \u001b[0m | \u001b[0m0.2202   \u001b[0m | \u001b[0m0.3387   \u001b[0m | \u001b[0m0.5239   \u001b[0m | \u001b[0m0.7549   \u001b[0m | \u001b[0m0.4639   \u001b[0m | \u001b[0m0.1248   \u001b[0m | \u001b[0m0.3125   \u001b[0m | \u001b[0m0.5045   \u001b[0m | \u001b[0m0.6738   \u001b[0m | \u001b[0m0.7701   \u001b[0m | \u001b[0m0.1303   \u001b[0m |\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m-1.552   \u001b[0m | \u001b[0m0.02292  \u001b[0m | \u001b[0m0.5191   \u001b[0m | \u001b[0m0.81     \u001b[0m | \u001b[0m0.0126   \u001b[0m | \u001b[0m0.6725   \u001b[0m | \u001b[0m0.6868   \u001b[0m | \u001b[0m0.4492   \u001b[0m | \u001b[0m0.9148   \u001b[0m | \u001b[0m0.6444   \u001b[0m | \u001b[0m0.00524  \u001b[0m | \u001b[0m0.4844   \u001b[0m | \u001b[0m0.8593   \u001b[0m | \u001b[0m0.8304   \u001b[0m | \u001b[0m0.6492   \u001b[0m | \u001b[0m0.6737   \u001b[0m | \u001b[0m0.5785   \u001b[0m | \u001b[0m0.2741   \u001b[0m | \u001b[0m0.5605   \u001b[0m | \u001b[0m0.6717   \u001b[0m | \u001b[0m0.3524   \u001b[0m | \u001b[0m0.8558   \u001b[0m | \u001b[0m0.195    \u001b[0m | \u001b[0m0.7473   \u001b[0m | \u001b[0m0.2896   \u001b[0m | \u001b[0m0.7738   \u001b[0m | \u001b[0m0.4277   \u001b[0m | \u001b[0m0.8077   \u001b[0m | \u001b[0m0.3535   \u001b[0m | \u001b[0m0.2137   \u001b[0m | \u001b[0m0.7673   \u001b[0m | \u001b[0m0.3086   \u001b[0m | \u001b[0m0.7332   \u001b[0m | \u001b[0m0.7445   \u001b[0m | \u001b[0m0.2214   \u001b[0m | \u001b[0m0.2141   \u001b[0m |\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m-1.223   \u001b[0m | \u001b[0m0.1989   \u001b[0m | \u001b[0m0.1425   \u001b[0m | \u001b[0m0.3771   \u001b[0m | \u001b[0m0.02663  \u001b[0m | \u001b[0m0.1109   \u001b[0m | \u001b[0m0.6746   \u001b[0m | \u001b[0m0.7998   \u001b[0m | \u001b[0m0.08053  \u001b[0m | \u001b[0m0.2317   \u001b[0m | \u001b[0m0.2076   \u001b[0m | \u001b[0m0.9173   \u001b[0m | \u001b[0m0.7113   \u001b[0m | \u001b[0m0.5539   \u001b[0m | \u001b[0m0.3045   \u001b[0m | \u001b[0m0.8349   \u001b[0m | \u001b[0m0.4353   \u001b[0m | \u001b[0m0.9235   \u001b[0m | \u001b[0m0.7061   \u001b[0m | \u001b[0m0.478    \u001b[0m | \u001b[0m0.1262   \u001b[0m | \u001b[0m0.976    \u001b[0m | \u001b[0m0.1598   \u001b[0m | \u001b[0m0.2026   \u001b[0m | \u001b[0m0.4312   \u001b[0m | \u001b[0m0.4042   \u001b[0m | \u001b[0m0.1468   \u001b[0m | \u001b[0m0.7293   \u001b[0m | \u001b[0m0.1887   \u001b[0m | \u001b[0m0.6439   \u001b[0m | \u001b[0m0.7543   \u001b[0m | \u001b[0m0.2107   \u001b[0m | \u001b[0m0.601    \u001b[0m | \u001b[0m0.7489   \u001b[0m | \u001b[0m0.6382   \u001b[0m | \u001b[0m0.5971   \u001b[0m |\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m-0.9882  \u001b[0m | \u001b[0m0.2955   \u001b[0m | \u001b[0m0.7316   \u001b[0m | \u001b[0m0.9453   \u001b[0m | \u001b[0m0.4256   \u001b[0m | \u001b[0m0.7822   \u001b[0m | \u001b[0m0.05614  \u001b[0m | \u001b[0m0.8353   \u001b[0m | \u001b[0m0.1923   \u001b[0m | \u001b[0m0.3951   \u001b[0m | \u001b[0m0.3001   \u001b[0m | \u001b[0m0.0801   \u001b[0m | \u001b[0m0.9046   \u001b[0m | \u001b[0m0.3702   \u001b[0m | \u001b[0m0.5307   \u001b[0m | \u001b[0m0.4941   \u001b[0m | \u001b[0m0.1322   \u001b[0m | \u001b[0m0.2065   \u001b[0m | \u001b[0m0.07619  \u001b[0m | \u001b[0m0.5079   \u001b[0m | \u001b[0m0.2615   \u001b[0m | \u001b[0m0.3571   \u001b[0m | \u001b[0m0.1081   \u001b[0m | \u001b[0m0.7876   \u001b[0m | \u001b[0m0.1066   \u001b[0m | \u001b[0m0.9857   \u001b[0m | \u001b[0m0.1772   \u001b[0m | \u001b[0m0.5724   \u001b[0m | \u001b[0m0.04485  \u001b[0m | \u001b[0m0.7871   \u001b[0m | \u001b[0m0.1896   \u001b[0m | \u001b[0m0.5279   \u001b[0m | \u001b[0m0.7401   \u001b[0m | \u001b[0m0.1499   \u001b[0m | \u001b[0m0.5511   \u001b[0m | \u001b[0m0.2166   \u001b[0m |\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m-2.221   \u001b[0m | \u001b[0m0.7592   \u001b[0m | \u001b[0m0.7229   \u001b[0m | \u001b[0m0.1765   \u001b[0m | \u001b[0m0.862    \u001b[0m | \u001b[0m0.01978  \u001b[0m | \u001b[0m0.8602   \u001b[0m | \u001b[0m0.5589   \u001b[0m | \u001b[0m0.4032   \u001b[0m | \u001b[0m0.7587   \u001b[0m | \u001b[0m0.7169   \u001b[0m | \u001b[0m0.9873   \u001b[0m | \u001b[0m0.2781   \u001b[0m | \u001b[0m0.003794 \u001b[0m | \u001b[0m0.9339   \u001b[0m | \u001b[0m0.8579   \u001b[0m | \u001b[0m0.7289   \u001b[0m | \u001b[0m0.5167   \u001b[0m | \u001b[0m0.707    \u001b[0m | \u001b[0m0.7805   \u001b[0m | \u001b[0m0.3749   \u001b[0m | \u001b[0m0.7703   \u001b[0m | \u001b[0m0.7506   \u001b[0m | \u001b[0m0.6132   \u001b[0m | \u001b[0m0.4019   \u001b[0m | \u001b[0m0.6973   \u001b[0m | \u001b[0m0.003113 \u001b[0m | \u001b[0m0.7749   \u001b[0m | \u001b[0m0.8964   \u001b[0m | \u001b[0m0.2393   \u001b[0m | \u001b[0m0.1208   \u001b[0m | \u001b[0m0.2203   \u001b[0m | \u001b[0m0.3021   \u001b[0m | \u001b[0m0.883    \u001b[0m | \u001b[0m0.5432   \u001b[0m | \u001b[0m0.2867   \u001b[0m |\n",
      "| \u001b[0m21       \u001b[0m | \u001b[0m-1.188   \u001b[0m | \u001b[0m0.1384   \u001b[0m | \u001b[0m0.2901   \u001b[0m | \u001b[0m0.6139   \u001b[0m | \u001b[0m0.3241   \u001b[0m | \u001b[0m0.4574   \u001b[0m | \u001b[0m0.4441   \u001b[0m | \u001b[0m0.8281   \u001b[0m | \u001b[0m0.4263   \u001b[0m | \u001b[0m0.3457   \u001b[0m | \u001b[0m0.675    \u001b[0m | \u001b[0m0.2215   \u001b[0m | \u001b[0m0.4672   \u001b[0m | \u001b[0m0.3148   \u001b[0m | \u001b[0m0.6269   \u001b[0m | \u001b[0m0.8774   \u001b[0m | \u001b[0m0.4477   \u001b[0m | \u001b[0m0.7845   \u001b[0m | \u001b[0m0.457    \u001b[0m | \u001b[0m0.6562   \u001b[0m | \u001b[0m0.1318   \u001b[0m | \u001b[0m0.433    \u001b[0m | \u001b[0m0.9093   \u001b[0m | \u001b[0m0.6055   \u001b[0m | \u001b[0m0.7668   \u001b[0m | \u001b[0m0.5047   \u001b[0m | \u001b[0m0.4981   \u001b[0m | \u001b[0m0.8429   \u001b[0m | \u001b[0m0.06781  \u001b[0m | \u001b[0m0.5733   \u001b[0m | \u001b[0m0.9428   \u001b[0m | \u001b[0m0.5179   \u001b[0m | \u001b[0m0.1945   \u001b[0m | \u001b[0m0.8479   \u001b[0m | \u001b[0m0.2516   \u001b[0m | \u001b[0m0.7007   \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m22       \u001b[0m | \u001b[0m-1.656   \u001b[0m | \u001b[0m0.5403   \u001b[0m | \u001b[0m0.9488   \u001b[0m | \u001b[0m0.6243   \u001b[0m | \u001b[0m0.838    \u001b[0m | \u001b[0m0.007933 \u001b[0m | \u001b[0m0.9893   \u001b[0m | \u001b[0m0.07771  \u001b[0m | \u001b[0m0.3221   \u001b[0m | \u001b[0m0.9462   \u001b[0m | \u001b[0m0.008939 \u001b[0m | \u001b[0m0.8227   \u001b[0m | \u001b[0m0.8612   \u001b[0m | \u001b[0m0.4398   \u001b[0m | \u001b[0m0.2557   \u001b[0m | \u001b[0m0.8027   \u001b[0m | \u001b[0m0.4779   \u001b[0m | \u001b[0m0.1343   \u001b[0m | \u001b[0m0.9278   \u001b[0m | \u001b[0m0.896    \u001b[0m | \u001b[0m0.4915   \u001b[0m | \u001b[0m0.8567   \u001b[0m | \u001b[0m0.4186   \u001b[0m | \u001b[0m0.6835   \u001b[0m | \u001b[0m0.398    \u001b[0m | \u001b[0m0.5057   \u001b[0m | \u001b[0m0.1896   \u001b[0m | \u001b[0m0.965    \u001b[0m | \u001b[0m0.2942   \u001b[0m | \u001b[0m0.1035   \u001b[0m | \u001b[0m0.1443   \u001b[0m | \u001b[0m0.01409  \u001b[0m | \u001b[0m0.7159   \u001b[0m | \u001b[0m0.5645   \u001b[0m | \u001b[0m0.7946   \u001b[0m | \u001b[0m0.5071   \u001b[0m |\n",
      "| \u001b[0m23       \u001b[0m | \u001b[0m-1.073   \u001b[0m | \u001b[0m0.7918   \u001b[0m | \u001b[0m0.6958   \u001b[0m | \u001b[0m0.7778   \u001b[0m | \u001b[0m0.4065   \u001b[0m | \u001b[0m0.6478   \u001b[0m | \u001b[0m0.1798   \u001b[0m | \u001b[0m0.3218   \u001b[0m | \u001b[0m0.1726   \u001b[0m | \u001b[0m0.4086   \u001b[0m | \u001b[0m0.2414   \u001b[0m | \u001b[0m0.4069   \u001b[0m | \u001b[0m0.9752   \u001b[0m | \u001b[0m0.3203   \u001b[0m | \u001b[0m0.9825   \u001b[0m | \u001b[0m0.6363   \u001b[0m | \u001b[0m0.3751   \u001b[0m | \u001b[0m0.8575   \u001b[0m | \u001b[0m0.6196   \u001b[0m | \u001b[0m0.252    \u001b[0m | \u001b[0m0.7929   \u001b[0m | \u001b[0m0.4329   \u001b[0m | \u001b[0m0.3575   \u001b[0m | \u001b[0m0.3303   \u001b[0m | \u001b[0m0.6974   \u001b[0m | \u001b[0m0.2687   \u001b[0m | \u001b[0m0.8083   \u001b[0m | \u001b[0m0.2953   \u001b[0m | \u001b[0m0.5441   \u001b[0m | \u001b[0m0.4879   \u001b[0m | \u001b[0m0.8554   \u001b[0m | \u001b[0m0.8884   \u001b[0m | \u001b[0m0.1844   \u001b[0m | \u001b[0m0.5853   \u001b[0m | \u001b[0m0.8982   \u001b[0m | \u001b[0m0.4461   \u001b[0m |\n",
      "| \u001b[0m24       \u001b[0m | \u001b[0m-1.233   \u001b[0m | \u001b[0m0.9219   \u001b[0m | \u001b[0m0.279    \u001b[0m | \u001b[0m0.6088   \u001b[0m | \u001b[0m0.6825   \u001b[0m | \u001b[0m0.2282   \u001b[0m | \u001b[0m0.01377  \u001b[0m | \u001b[0m0.4167   \u001b[0m | \u001b[0m0.9385   \u001b[0m | \u001b[0m0.343    \u001b[0m | \u001b[0m0.7797   \u001b[0m | \u001b[0m0.1747   \u001b[0m | \u001b[0m0.342    \u001b[0m | \u001b[0m0.1446   \u001b[0m | \u001b[0m0.7168   \u001b[0m | \u001b[0m0.6993   \u001b[0m | \u001b[0m0.6885   \u001b[0m | \u001b[0m0.2534   \u001b[0m | \u001b[0m0.6924   \u001b[0m | \u001b[0m0.2273   \u001b[0m | \u001b[0m0.4246   \u001b[0m | \u001b[0m0.3719   \u001b[0m | \u001b[0m0.3553   \u001b[0m | \u001b[0m0.05765  \u001b[0m | \u001b[0m0.6316   \u001b[0m | \u001b[0m0.7073   \u001b[0m | \u001b[0m0.6136   \u001b[0m | \u001b[0m0.6483   \u001b[0m | \u001b[0m0.1699   \u001b[0m | \u001b[0m0.1494   \u001b[0m | \u001b[0m0.5142   \u001b[0m | \u001b[0m0.8753   \u001b[0m | \u001b[0m0.184    \u001b[0m | \u001b[0m0.4628   \u001b[0m | \u001b[0m0.4289   \u001b[0m | \u001b[0m0.4973   \u001b[0m |\n",
      "| \u001b[0m25       \u001b[0m | \u001b[0m-1.781   \u001b[0m | \u001b[0m0.1615   \u001b[0m | \u001b[0m0.3424   \u001b[0m | \u001b[0m0.2619   \u001b[0m | \u001b[0m0.8445   \u001b[0m | \u001b[0m0.8003   \u001b[0m | \u001b[0m0.4266   \u001b[0m | \u001b[0m0.607    \u001b[0m | \u001b[0m0.1455   \u001b[0m | \u001b[0m0.5096   \u001b[0m | \u001b[0m0.2969   \u001b[0m | \u001b[0m0.8597   \u001b[0m | \u001b[0m0.6716   \u001b[0m | \u001b[0m0.6335   \u001b[0m | \u001b[0m0.1248   \u001b[0m | \u001b[0m0.4706   \u001b[0m | \u001b[0m0.9866   \u001b[0m | \u001b[0m0.9483   \u001b[0m | \u001b[0m0.6451   \u001b[0m | \u001b[0m0.1517   \u001b[0m | \u001b[0m0.6391   \u001b[0m | \u001b[0m0.5657   \u001b[0m | \u001b[0m0.4687   \u001b[0m | \u001b[0m0.428    \u001b[0m | \u001b[0m0.5993   \u001b[0m | \u001b[0m0.85     \u001b[0m | \u001b[0m0.7511   \u001b[0m | \u001b[0m0.5794   \u001b[0m | \u001b[0m0.9247   \u001b[0m | \u001b[0m0.06474  \u001b[0m | \u001b[0m0.9913   \u001b[0m | \u001b[0m0.05299  \u001b[0m | \u001b[0m0.1995   \u001b[0m | \u001b[0m0.4228   \u001b[0m | \u001b[0m0.1075   \u001b[0m | \u001b[0m0.6237   \u001b[0m |\n",
      "| \u001b[0m26       \u001b[0m | \u001b[0m-1.352   \u001b[0m | \u001b[0m0.04799  \u001b[0m | \u001b[0m0.2846   \u001b[0m | \u001b[0m0.06104  \u001b[0m | \u001b[0m0.7035   \u001b[0m | \u001b[0m0.6685   \u001b[0m | \u001b[0m0.3786   \u001b[0m | \u001b[0m0.1882   \u001b[0m | \u001b[0m0.747    \u001b[0m | \u001b[0m0.3404   \u001b[0m | \u001b[0m0.7953   \u001b[0m | \u001b[0m0.4879   \u001b[0m | \u001b[0m0.5257   \u001b[0m | \u001b[0m0.02849  \u001b[0m | \u001b[0m0.6442   \u001b[0m | \u001b[0m0.3507   \u001b[0m | \u001b[0m0.2292   \u001b[0m | \u001b[0m0.4339   \u001b[0m | \u001b[0m0.3825   \u001b[0m | \u001b[0m0.4698   \u001b[0m | \u001b[0m0.9795   \u001b[0m | \u001b[0m0.3644   \u001b[0m | \u001b[0m0.7744   \u001b[0m | \u001b[0m0.5528   \u001b[0m | \u001b[0m0.8891   \u001b[0m | \u001b[0m0.355    \u001b[0m | \u001b[0m0.2455   \u001b[0m | \u001b[0m0.911    \u001b[0m | \u001b[0m0.04353  \u001b[0m | \u001b[0m0.9508   \u001b[0m | \u001b[0m0.5564   \u001b[0m | \u001b[0m0.3764   \u001b[0m | \u001b[0m0.9951   \u001b[0m | \u001b[0m0.05836  \u001b[0m | \u001b[0m0.5167   \u001b[0m | \u001b[0m0.0311   \u001b[0m |\n",
      "| \u001b[0m27       \u001b[0m | \u001b[0m-1.624   \u001b[0m | \u001b[0m0.5712   \u001b[0m | \u001b[0m0.1805   \u001b[0m | \u001b[0m0.631    \u001b[0m | \u001b[0m0.9809   \u001b[0m | \u001b[0m0.8749   \u001b[0m | \u001b[0m0.4518   \u001b[0m | \u001b[0m0.7085   \u001b[0m | \u001b[0m0.7775   \u001b[0m | \u001b[0m0.4948   \u001b[0m | \u001b[0m0.5285   \u001b[0m | \u001b[0m0.1508   \u001b[0m | \u001b[0m0.3694   \u001b[0m | \u001b[0m0.1422   \u001b[0m | \u001b[0m0.7269   \u001b[0m | \u001b[0m0.477    \u001b[0m | \u001b[0m0.4489   \u001b[0m | \u001b[0m0.886    \u001b[0m | \u001b[0m0.5276   \u001b[0m | \u001b[0m0.4091   \u001b[0m | \u001b[0m0.2689   \u001b[0m | \u001b[0m0.07201  \u001b[0m | \u001b[0m0.4181   \u001b[0m | \u001b[0m0.02575  \u001b[0m | \u001b[0m0.2912   \u001b[0m | \u001b[0m0.5035   \u001b[0m | \u001b[0m0.9659   \u001b[0m | \u001b[0m0.1094   \u001b[0m | \u001b[0m0.673    \u001b[0m | \u001b[0m0.4999   \u001b[0m | \u001b[0m0.7771   \u001b[0m | \u001b[0m0.1436   \u001b[0m | \u001b[0m0.0832   \u001b[0m | \u001b[0m0.3992   \u001b[0m | \u001b[0m0.797    \u001b[0m | \u001b[0m0.1917   \u001b[0m |\n",
      "| \u001b[0m28       \u001b[0m | \u001b[0m-1.036   \u001b[0m | \u001b[0m0.7678   \u001b[0m | \u001b[0m0.2903   \u001b[0m | \u001b[0m0.2169   \u001b[0m | \u001b[0m0.01672  \u001b[0m | \u001b[0m0.3987   \u001b[0m | \u001b[0m0.3811   \u001b[0m | \u001b[0m0.6593   \u001b[0m | \u001b[0m0.07092  \u001b[0m | \u001b[0m0.1526   \u001b[0m | \u001b[0m0.01658  \u001b[0m | \u001b[0m0.1138   \u001b[0m | \u001b[0m0.6518   \u001b[0m | \u001b[0m0.4027   \u001b[0m | \u001b[0m0.321    \u001b[0m | \u001b[0m0.5579   \u001b[0m | \u001b[0m0.9935   \u001b[0m | \u001b[0m0.8345   \u001b[0m | \u001b[0m0.6996   \u001b[0m | \u001b[0m0.9183   \u001b[0m | \u001b[0m0.03973  \u001b[0m | \u001b[0m0.07033  \u001b[0m | \u001b[0m0.474    \u001b[0m | \u001b[0m0.3492   \u001b[0m | \u001b[0m0.9373   \u001b[0m | \u001b[0m0.4896   \u001b[0m | \u001b[0m0.5396   \u001b[0m | \u001b[0m0.8953   \u001b[0m | \u001b[0m0.4466   \u001b[0m | \u001b[0m0.877    \u001b[0m | \u001b[0m0.2536   \u001b[0m | \u001b[0m0.2738   \u001b[0m | \u001b[0m0.3284   \u001b[0m | \u001b[0m0.5476   \u001b[0m | \u001b[0m0.2201   \u001b[0m | \u001b[0m0.6714   \u001b[0m |\n",
      "| \u001b[0m29       \u001b[0m | \u001b[0m-1.209   \u001b[0m | \u001b[0m0.1428   \u001b[0m | \u001b[0m0.0941   \u001b[0m | \u001b[0m0.8702   \u001b[0m | \u001b[0m0.2369   \u001b[0m | \u001b[0m0.386    \u001b[0m | \u001b[0m0.5715   \u001b[0m | \u001b[0m0.5258   \u001b[0m | \u001b[0m0.07602  \u001b[0m | \u001b[0m0.8741   \u001b[0m | \u001b[0m0.9511   \u001b[0m | \u001b[0m0.8125   \u001b[0m | \u001b[0m0.2838   \u001b[0m | \u001b[0m0.5278   \u001b[0m | \u001b[0m0.3394   \u001b[0m | \u001b[0m0.5547   \u001b[0m | \u001b[0m0.9744   \u001b[0m | \u001b[0m0.3117   \u001b[0m | \u001b[0m0.6688   \u001b[0m | \u001b[0m0.326    \u001b[0m | \u001b[0m0.7745   \u001b[0m | \u001b[0m0.3258   \u001b[0m | \u001b[0m0.8898   \u001b[0m | \u001b[0m0.7517   \u001b[0m | \u001b[0m0.7626   \u001b[0m | \u001b[0m0.4695   \u001b[0m | \u001b[0m0.2108   \u001b[0m | \u001b[0m0.04148  \u001b[0m | \u001b[0m0.3218   \u001b[0m | \u001b[0m0.03711  \u001b[0m | \u001b[0m0.6939   \u001b[0m | \u001b[0m0.6704   \u001b[0m | \u001b[0m0.4305   \u001b[0m | \u001b[0m0.7678   \u001b[0m | \u001b[0m0.536    \u001b[0m | \u001b[0m0.03986  \u001b[0m |\n",
      "| \u001b[0m30       \u001b[0m | \u001b[0m-1.246   \u001b[0m | \u001b[0m0.1348   \u001b[0m | \u001b[0m0.1934   \u001b[0m | \u001b[0m0.3357   \u001b[0m | \u001b[0m0.05231  \u001b[0m | \u001b[0m0.6051   \u001b[0m | \u001b[0m0.5121   \u001b[0m | \u001b[0m0.6175   \u001b[0m | \u001b[0m0.4324   \u001b[0m | \u001b[0m0.8477   \u001b[0m | \u001b[0m0.4541   \u001b[0m | \u001b[0m0.0154   \u001b[0m | \u001b[0m0.8731   \u001b[0m | \u001b[0m0.6562   \u001b[0m | \u001b[0m0.823    \u001b[0m | \u001b[0m0.9518   \u001b[0m | \u001b[0m0.05091  \u001b[0m | \u001b[0m0.2351   \u001b[0m | \u001b[0m0.06334  \u001b[0m | \u001b[0m0.4217   \u001b[0m | \u001b[0m0.8638   \u001b[0m | \u001b[0m0.08162  \u001b[0m | \u001b[0m0.4731   \u001b[0m | \u001b[0m0.1255   \u001b[0m | \u001b[0m0.7729   \u001b[0m | \u001b[0m0.8414   \u001b[0m | \u001b[0m0.04329  \u001b[0m | \u001b[0m0.4864   \u001b[0m | \u001b[0m0.2394   \u001b[0m | \u001b[0m0.9525   \u001b[0m | \u001b[0m0.9439   \u001b[0m | \u001b[0m0.6139   \u001b[0m | \u001b[0m0.9735   \u001b[0m | \u001b[0m0.3449   \u001b[0m | \u001b[0m0.8979   \u001b[0m | \u001b[0m0.4346   \u001b[0m |\n",
      "| \u001b[0m31       \u001b[0m | \u001b[0m-0.9717  \u001b[0m | \u001b[0m0.4039   \u001b[0m | \u001b[0m0.4942   \u001b[0m | \u001b[0m0.3297   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.392    \u001b[0m | \u001b[0m0.3631   \u001b[0m | \u001b[0m0.1593   \u001b[0m | \u001b[0m0.496    \u001b[0m | \u001b[0m0.1921   \u001b[0m | \u001b[0m0.7485   \u001b[0m | \u001b[0m0.2194   \u001b[0m | \u001b[0m0.6796   \u001b[0m | \u001b[0m0.6204   \u001b[0m | \u001b[0m0.184    \u001b[0m | \u001b[0m0.4417   \u001b[0m | \u001b[0m0.08893  \u001b[0m | \u001b[0m0.7452   \u001b[0m | \u001b[0m0.06136  \u001b[0m | \u001b[0m0.5096   \u001b[0m | \u001b[0m0.07992  \u001b[0m | \u001b[0m0.1033   \u001b[0m | \u001b[0m0.2483   \u001b[0m | \u001b[0m0.4758   \u001b[0m | \u001b[0m0.7017   \u001b[0m | \u001b[0m0.4913   \u001b[0m | \u001b[0m0.858    \u001b[0m | \u001b[0m0.6713   \u001b[0m | \u001b[0m0.5783   \u001b[0m | \u001b[0m0.6512   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.806    \u001b[0m | \u001b[0m0.6926   \u001b[0m | \u001b[0m0.7213   \u001b[0m | \u001b[0m0.9677   \u001b[0m | \u001b[0m0.6458   \u001b[0m |\n",
      "| \u001b[0m32       \u001b[0m | \u001b[0m-1.005   \u001b[0m | \u001b[0m0.8721   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.8884   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.5809   \u001b[0m | \u001b[0m0.3696   \u001b[0m | \u001b[0m0.8393   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.07968  \u001b[0m | \u001b[0m0.3332   \u001b[0m | \u001b[0m0.04317  \u001b[0m | \u001b[0m0.7577   \u001b[0m | \u001b[0m0.5099   \u001b[0m | \u001b[0m0.5098   \u001b[0m | \u001b[0m0.3134   \u001b[0m | \u001b[0m0.1034   \u001b[0m | \u001b[0m0.5676   \u001b[0m | \u001b[0m0.1855   \u001b[0m | \u001b[0m0.3702   \u001b[0m | \u001b[0m0.4622   \u001b[0m | \u001b[0m0.024    \u001b[0m | \u001b[0m0.4418   \u001b[0m | \u001b[0m0.6119   \u001b[0m | \u001b[0m0.8208   \u001b[0m | \u001b[0m0.3631   \u001b[0m | \u001b[0m0.6056   \u001b[0m | \u001b[0m0.619    \u001b[0m | \u001b[0m0.2289   \u001b[0m | \u001b[0m0.9649   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.628    \u001b[0m | \u001b[0m0.3817   \u001b[0m | \u001b[0m0.596    \u001b[0m | \u001b[0m0.3726   \u001b[0m |\n",
      "| \u001b[0m33       \u001b[0m | \u001b[0m-0.9676  \u001b[0m | \u001b[0m0.572    \u001b[0m | \u001b[0m0.488    \u001b[0m | \u001b[0m0.02155  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.6791   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.04334  \u001b[0m | \u001b[0m0.5016   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.366    \u001b[0m | \u001b[0m0.01033  \u001b[0m | \u001b[0m0.1504   \u001b[0m | \u001b[0m0.6047   \u001b[0m | \u001b[0m0.6394   \u001b[0m | \u001b[0m0.9369   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.7509   \u001b[0m | \u001b[0m0.00977  \u001b[0m | \u001b[0m0.773    \u001b[0m | \u001b[0m0.6132   \u001b[0m | \u001b[0m0.4575   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.626    \u001b[0m | \u001b[0m0.2004   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.8895   \u001b[0m | \u001b[0m0.8175   \u001b[0m | \u001b[0m0.6996   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.5713   \u001b[0m | \u001b[0m0.8121   \u001b[0m | \u001b[0m0.7708   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.9492   \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m34       \u001b[0m | \u001b[0m-0.9153  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.5237   \u001b[0m | \u001b[0m0.5384   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.3675   \u001b[0m | \u001b[0m0.9382   \u001b[0m | \u001b[0m0.4711   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.842    \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.8112   \u001b[0m | \u001b[0m0.2347   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.05765  \u001b[0m | \u001b[0m0.7829   \u001b[0m | \u001b[0m0.174    \u001b[0m | \u001b[0m0.03531  \u001b[0m | \u001b[0m0.09341  \u001b[0m | \u001b[0m0.3689   \u001b[0m | \u001b[0m0.8441   \u001b[0m | \u001b[0m0.5037   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.9408   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.4956   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.1988   \u001b[0m | \u001b[0m0.8916   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.4258   \u001b[0m |\n",
      "| \u001b[0m35       \u001b[0m | \u001b[0m-1.01    \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.2114   \u001b[0m | \u001b[0m0.2877   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.6296   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.4357   \u001b[0m | \u001b[0m0.6861   \u001b[0m | \u001b[0m0.7355   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.4      \u001b[0m | \u001b[0m0.3923   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.02034  \u001b[0m | \u001b[0m0.01407  \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.2823   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.9696   \u001b[0m | \u001b[0m0.4268   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.458    \u001b[0m | \u001b[0m0.5814   \u001b[0m | \u001b[0m0.7114   \u001b[0m | \u001b[0m0.558    \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.8108   \u001b[0m | \u001b[0m0.928    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.917    \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[0m36       \u001b[0m | \u001b[0m-1.024   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.1901   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.5472   \u001b[0m | \u001b[0m0.008633 \u001b[0m | \u001b[0m0.7333   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.783    \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.3257   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.6148   \u001b[0m | \u001b[0m0.0212   \u001b[0m | \u001b[0m0.6961   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.1456   \u001b[0m | \u001b[0m0.2228   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.4323   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.1851   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.6143   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "| \u001b[0m37       \u001b[0m | \u001b[0m-0.9472  \u001b[0m | \u001b[0m0.3463   \u001b[0m | \u001b[0m0.4852   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.4578   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0225   \u001b[0m | \u001b[0m0.5108   \u001b[0m | \u001b[0m0.4841   \u001b[0m | \u001b[0m0.3953   \u001b[0m | \u001b[0m0.8502   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.695    \u001b[0m | \u001b[0m0.3205   \u001b[0m | \u001b[0m0.8599   \u001b[0m | \u001b[0m0.8005   \u001b[0m | \u001b[0m0.3817   \u001b[0m | \u001b[0m0.6734   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.3102   \u001b[0m | \u001b[0m0.06702  \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.7601   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.9931   \u001b[0m | \u001b[0m0.5085   \u001b[0m | \u001b[0m0.9121   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.3556   \u001b[0m |\n",
      "| \u001b[0m38       \u001b[0m | \u001b[0m-1.039   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.2901   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.934    \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.6292   \u001b[0m | \u001b[0m0.5955   \u001b[0m | \u001b[0m0.05047  \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.7186   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.667    \u001b[0m | \u001b[0m0.09507  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.5728   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.8088   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.6001   \u001b[0m | \u001b[0m0.4092   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.155    \u001b[0m |\n",
      "| \u001b[0m39       \u001b[0m | \u001b[0m-1.027   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.216    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.7606   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.314    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.3096   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.1025   \u001b[0m | \u001b[0m0.4551   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.3265   \u001b[0m | \u001b[0m0.4283   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.3523   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.9767   \u001b[0m | \u001b[0m0.5043   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.2595   \u001b[0m | \u001b[0m0.6746   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "| \u001b[0m40       \u001b[0m | \u001b[0m-0.9056  \u001b[0m | \u001b[0m0.2078   \u001b[0m | \u001b[0m0.04443  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.5533   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.1503   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.4385   \u001b[0m | \u001b[0m0.4886   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.8109   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.2923   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.6097   \u001b[0m | \u001b[0m0.7161   \u001b[0m | \u001b[0m0.09175  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.2216   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.01717  \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.4066   \u001b[0m | \u001b[0m0.4474   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.836    \u001b[0m | \u001b[0m0.5153   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.586    \u001b[0m |\n",
      "| \u001b[0m41       \u001b[0m | \u001b[0m-0.9324  \u001b[0m | \u001b[0m0.7256   \u001b[0m | \u001b[0m0.5196   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.9004   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.8133   \u001b[0m | \u001b[0m0.8335   \u001b[0m | \u001b[0m0.6902   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.7635   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.7434   \u001b[0m | \u001b[0m0.6089   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.1684   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.2689   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.8951   \u001b[0m | \u001b[0m0.6927   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.4326   \u001b[0m |\n",
      "| \u001b[0m42       \u001b[0m | \u001b[0m-1.07    \u001b[0m | \u001b[0m0.7092   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.5649   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.5094   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.5572   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.5889   \u001b[0m | \u001b[0m0.5916   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.9589   \u001b[0m | \u001b[0m0.7992   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.8943   \u001b[0m | \u001b[0m0.8732   \u001b[0m | \u001b[0m0.1457   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.5669   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.09722  \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.3196   \u001b[0m | \u001b[0m0.6035   \u001b[0m | \u001b[0m0.6059   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.9868   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.8753   \u001b[0m |\n",
      "| \u001b[0m43       \u001b[0m | \u001b[0m-0.9564  \u001b[0m | \u001b[0m0.9157   \u001b[0m | \u001b[0m0.1064   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.4948   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.139    \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.2165   \u001b[0m | \u001b[0m0.9418   \u001b[0m | \u001b[0m0.4736   \u001b[0m | \u001b[0m0.9344   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.4157   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.6349   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.6685   \u001b[0m | \u001b[0m0.592    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[0m44       \u001b[0m | \u001b[0m-0.9652  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.2755   \u001b[0m | \u001b[0m0.7515   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.9876   \u001b[0m | \u001b[0m0.05331  \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.8834   \u001b[0m | \u001b[0m0.6891   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.848    \u001b[0m | \u001b[0m0.2098   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.1712   \u001b[0m | \u001b[0m0.9247   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.5334   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.8815   \u001b[0m | \u001b[0m0.6584   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.07616  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.7806   \u001b[0m | \u001b[0m0.07801  \u001b[0m | \u001b[0m0.7269   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.02502  \u001b[0m |\n",
      "| \u001b[0m45       \u001b[0m | \u001b[0m-0.9098  \u001b[0m | \u001b[0m0.3137   \u001b[0m | \u001b[0m0.8506   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.3244   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.02766  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.9006   \u001b[0m | \u001b[0m0.068    \u001b[0m | \u001b[0m0.04064  \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.07804  \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.28     \u001b[0m | \u001b[0m0.1637   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.4748   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.1146   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.9261   \u001b[0m | \u001b[0m0.2603   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.1317   \u001b[0m | \u001b[0m0.4831   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m46       \u001b[0m | \u001b[0m-0.8788  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.3996   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.3611   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.5969   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.4726   \u001b[0m | \u001b[0m0.1716   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.047    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.4838   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.6039   \u001b[0m | \u001b[0m0.4959   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.4378   \u001b[0m |\n",
      "| \u001b[0m47       \u001b[0m | \u001b[0m-0.8863  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.9308   \u001b[0m | \u001b[0m0.04263  \u001b[0m | \u001b[0m0.6347   \u001b[0m | \u001b[0m0.1147   \u001b[0m | \u001b[0m0.426    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.2743   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.05785  \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.8073   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.774    \u001b[0m | \u001b[0m0.5987   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.1363   \u001b[0m |\n",
      "| \u001b[0m48       \u001b[0m | \u001b[0m-0.8936  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.1339   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.09561  \u001b[0m | \u001b[0m0.5601   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.3834   \u001b[0m | \u001b[0m0.4252   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.01608  \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.3916   \u001b[0m | \u001b[0m0.4243   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[0m49       \u001b[0m | \u001b[0m-0.9169  \u001b[0m | \u001b[0m0.1113   \u001b[0m | \u001b[0m0.9233   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.8038   \u001b[0m | \u001b[0m0.2013   \u001b[0m | \u001b[0m0.4299   \u001b[0m | \u001b[0m0.3167   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.06873  \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.7258   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.9556   \u001b[0m | \u001b[0m0.8839   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[0m50       \u001b[0m | \u001b[0m-0.9462  \u001b[0m | \u001b[0m0.2288   \u001b[0m | \u001b[0m0.8963   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.4491   \u001b[0m | \u001b[0m0.1081   \u001b[0m | \u001b[0m0.747    \u001b[0m | \u001b[0m0.5492   \u001b[0m | \u001b[0m0.8436   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.8231   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.005781 \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.3892   \u001b[0m |\n",
      "| \u001b[95m51       \u001b[0m | \u001b[95m-0.8623  \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.7815   \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.221    \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.01709  \u001b[0m | \u001b[95m0.4529   \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.4263   \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.5125   \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.9794   \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.4485   \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.376    \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.0      \u001b[0m |\n",
      "| \u001b[0m52       \u001b[0m | \u001b[0m-0.8893  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.4752   \u001b[0m | \u001b[0m0.6802   \u001b[0m | \u001b[0m0.1838   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.171    \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.5082   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.8065   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.2335   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.2149   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[95m53       \u001b[0m | \u001b[95m-0.8531  \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.4429   \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.3784   \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.2281   \u001b[0m | \u001b[95m0.04771  \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.3719   \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.1542   \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.4059   \u001b[0m |\n",
      "| \u001b[0m54       \u001b[0m | \u001b[0m-0.9685  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.9139   \u001b[0m | \u001b[0m0.6881   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.07443  \u001b[0m | \u001b[0m0.6225   \u001b[0m | \u001b[0m0.02617  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.09513  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.8704   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.5604   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "| \u001b[0m55       \u001b[0m | \u001b[0m-0.9399  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.9256   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.6617   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.662    \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.09083  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.1712   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.8907   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.009132 \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[0m56       \u001b[0m | \u001b[0m-0.8614  \u001b[0m | \u001b[0m0.9569   \u001b[0m | \u001b[0m0.4614   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.1788   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.2222   \u001b[0m | \u001b[0m0.2107   \u001b[0m | \u001b[0m0.2379   \u001b[0m | \u001b[0m0.009953 \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.5835   \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m57       \u001b[0m | \u001b[0m-1.005   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.2068   \u001b[0m | \u001b[0m0.002312 \u001b[0m | \u001b[0m0.6919   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.3521   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.2126   \u001b[0m | \u001b[0m0.5735   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[95m58       \u001b[0m | \u001b[95m-0.7755  \u001b[0m | \u001b[95m0.3711   \u001b[0m | \u001b[95m0.1622   \u001b[0m | \u001b[95m0.08843  \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.324    \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.006586 \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.6243   \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m |\n",
      "| \u001b[0m59       \u001b[0m | \u001b[0m-0.792   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.8652   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.4871   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.7321   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.1809   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.1726   \u001b[0m | \u001b[0m0.03844  \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[0m60       \u001b[0m | \u001b[0m-0.8019  \u001b[0m | \u001b[0m0.9722   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.7976   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.1556   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.9835   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.543    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[0m61       \u001b[0m | \u001b[0m-0.7993  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.64     \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.2484   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[0m62       \u001b[0m | \u001b[0m-0.9056  \u001b[0m | \u001b[0m0.6934   \u001b[0m | \u001b[0m0.3672   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.1045   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.3949   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0001226\u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.1426   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[0m63       \u001b[0m | \u001b[0m-0.9066  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.2489   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.03781  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.7117   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.7427   \u001b[0m |\n",
      "| \u001b[0m64       \u001b[0m | \u001b[0m-0.8595  \u001b[0m | \u001b[0m0.08101  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.2807   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.4848   \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[0m65       \u001b[0m | \u001b[0m-0.8595  \u001b[0m | \u001b[0m0.9262   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.6182   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.5308   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.7306   \u001b[0m | \u001b[0m0.1203   \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[0m66       \u001b[0m | \u001b[0m-0.9394  \u001b[0m | \u001b[0m0.8992   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.9165   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.1873   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[0m67       \u001b[0m | \u001b[0m-0.9872  \u001b[0m | \u001b[0m0.2148   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.8433   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.4187   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m68       \u001b[0m | \u001b[0m-0.8104  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.5031   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.3827   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.6497   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[0m69       \u001b[0m | \u001b[0m-0.898   \u001b[0m | \u001b[0m0.2147   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0888   \u001b[0m | \u001b[0m0.06689  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.5497   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[0m70       \u001b[0m | \u001b[0m-0.8689  \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0764   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[0m71       \u001b[0m | \u001b[0m-0.8702  \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.5959   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.04665  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.08181  \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[0m72       \u001b[0m | \u001b[0m-0.8675  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.2271   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.4516   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[0m73       \u001b[0m | \u001b[0m-0.7936  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.5093   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.7777   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "| \u001b[0m74       \u001b[0m | \u001b[0m-0.8315  \u001b[0m | \u001b[0m0.9012   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.1851   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "| \u001b[0m75       \u001b[0m | \u001b[0m-0.826   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.6439   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.9723   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.6488   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.9555   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "| \u001b[0m76       \u001b[0m | \u001b[0m-0.8841  \u001b[0m | \u001b[0m0.2406   \u001b[0m | \u001b[0m0.5623   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.5294   \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "| \u001b[0m77       \u001b[0m | \u001b[0m-0.823   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.9822   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.8559   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.9318   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "| \u001b[95m78       \u001b[0m | \u001b[95m-0.7539  \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.8981   \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.6641   \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.3318   \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m79       \u001b[0m | \u001b[0m-0.8444  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.181    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.6487   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "| \u001b[0m80       \u001b[0m | \u001b[0m-0.8673  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.7825   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.9854   \u001b[0m |\n",
      "=============================================================================================================================================================================================================================================================================================================================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "def objective_function(onpromotion, total_other_promo_store, total_other_city_promo, holiday,\n",
    "                       holiday_description, event, time_since_quake, time_since_quake_sq, state, city, \n",
    "                       dcoilwtico, day, month, workday, payday, onpromotion_lag_1, type, dayofyear, year,\n",
    "                       onpromotion_lag_2, onpromotion_lag_3, onpromotion_lag_4, onpromotion_lag_5,\n",
    "                       onpromotion_lag_6, onpromotion_lag_7, dcoilwtico_lag_1, dcoilwtico_lag_2, \n",
    "                       dcoilwtico_lag_3, dcoilwtico_lag_4, dcoilwtico_lag_5, dcoilwtico_lag_6, \n",
    "                       dcoilwtico_lag_7, sales_one_year_lag, Change_in_oil_prices, promo_last_7_days, X_C=X_C, y=y):\n",
    "    \n",
    "    # Convert non-integer arguments to integers\n",
    "    variable_list = [int(round(Change_in_oil_prices)), int(round(city)),int(round(day)), int(round(dayofyear)), int(round(dcoilwtico)),\n",
    "                        int(round(dcoilwtico_lag_1)), int(round(dcoilwtico_lag_2)), int(round(dcoilwtico_lag_3)), int(round(dcoilwtico_lag_4)),\n",
    "                        int(round(dcoilwtico_lag_5)), int(round(dcoilwtico_lag_6)), int(round(dcoilwtico_lag_7)), int(round(event)),\n",
    "                        int(round(holiday)), int(round(holiday_description)), int(round(month)), int(round(onpromotion)),int(round(onpromotion_lag_1)),\n",
    "                        int(round(onpromotion_lag_2)), int(round(onpromotion_lag_3)), int(round(onpromotion_lag_4)), int(round(onpromotion_lag_5)),\n",
    "                        int(round(onpromotion_lag_6)), int(round(onpromotion_lag_7)), int(round(payday)), int(round(promo_last_7_days)),\n",
    "                        int(round(sales_one_year_lag)), int(round(state)), int(round(time_since_quake)), int(round(time_since_quake_sq)),\n",
    "                        int(round(total_other_city_promo)), int(round(total_other_promo_store)), int(round(type)), int(round(workday)), int(round(year))]\n",
    "    \n",
    "    X_C = X_C.copy()\n",
    "    column_to_remove = []\n",
    "    for i in range(3, X_C.shape[1]):\n",
    "        if variable_list[i-3]==0:\n",
    "            column_to_remove.append(X_C.columns[i])\n",
    "    \n",
    "    X_C.drop(column_to_remove, axis=1, inplace=True)\n",
    "            \n",
    "    xgb_params = {\n",
    "        'tree_method': 'gpu_hist',  # Specify GPU usage\n",
    "        'predictor': 'gpu_predictor',\n",
    "        'enable_categorical': True,}\n",
    "\n",
    "    model_2 = XGBRegressor(**xgb_params)\n",
    "\n",
    "    model_1 = LinearRegression(fit_intercept=False, algorithm=\"svd\", copy_X=True)\n",
    "    # Use time series split for cross validation. \n",
    "    cv_split = TimeSeriesSplit(n_splits = 4)\n",
    "    \n",
    "    # Create lists to append MSLE scores.\n",
    "    valid_msle = []\n",
    "    \n",
    "    # Dates to index through. \n",
    "    dates = X_C.index.drop_duplicates()\n",
    "    \n",
    "    \n",
    "    list1 = [\"time_since_quake\", \"time_since_quake_sq\"]\n",
    "    list2 = X_C.columns\n",
    "\n",
    "    # Convert lists to sets\n",
    "    set1 = set(list1)\n",
    "    set2 = set(list2)\n",
    "\n",
    "    # Find the values in set1 that are not in set2\n",
    "    uncommon_values = set1 - set2\n",
    "\n",
    "    # Remove the uncommon values from list1\n",
    "    list1 = [value for value in list1 if value not in uncommon_values]\n",
    "    \n",
    "    numeric_transformer = [\"float\", StandardScaler()]\n",
    "    data_preprocessor = Prepare_data(list1, [numeric_transformer])\n",
    "    \n",
    "    # Perform Cross-Validation to determine how model will do on unseen data.\n",
    "    for train_index, valid_index in cv_split.split(dates):\n",
    "\n",
    "        model = Hybrid_Pipeline(data_preprocessor, model_1, model_2, Boosted=True, to_tensor=False)\n",
    "\n",
    "        # Index dates.\n",
    "        date_train, date_valid = dates[train_index], dates[valid_index]\n",
    "\n",
    "        # Selecting data for y_train and y_valid.\n",
    "        y_train = y.loc[date_train]\n",
    "        y_valid = y.loc[date_valid]\n",
    "\n",
    "        # Selecting data for X_train and X_valid.\n",
    "        X_train = X_C.loc[date_train]\n",
    "        X_valid = X_C.loc[date_valid]\n",
    "\n",
    "        X_train = X_train.reset_index().sort_values([\"store_nbr\", \"family\", \"date\"])\n",
    "        X_valid = X_valid.reset_index().sort_values([\"store_nbr\", \"family\", \"date\"])\n",
    "        X_train = X_train.set_index([\"date\"])\n",
    "        X_valid = X_valid.set_index([\"date\"])\n",
    "\n",
    "        y_train = y_train.reset_index().sort_values([\"store_nbr\", \"family\", \"date\"])\n",
    "        y_valid = y_valid.reset_index().sort_values([\"store_nbr\", \"family\", \"date\"])\n",
    "        y_train = y_train.set_index([\"date\"])\n",
    "        y_valid = y_valid.set_index([\"date\"])\n",
    "\n",
    "\n",
    "        # Fitting model.\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Create predictions for Trainning and Validation.\n",
    "        pred = model.predict(X_valid)\n",
    "\n",
    "        # MSE for trainning and validation. \n",
    "        valid_msle.append(float(mean_squared_log_error(y_valid[\"sales\"], pred[\"sales\"])))\n",
    "\n",
    "\n",
    "    return -float(np.sqrt(np.mean(valid_msle)))\n",
    "\n",
    "# Define the parameter space for Bayesian optimization (each feature is a parameter)\n",
    "params = {X_C.columns[i]: (0, 1) for i in range(3, X_C.shape[1])}\n",
    "\n",
    "# Initialize the Bayesian optimizer\n",
    "optimizer = BayesianOptimization(\n",
    "    f=objective_function,\n",
    "    pbounds=params,\n",
    "    random_state=1,  # For reproducibility\n",
    ")\n",
    "\n",
    "# Perform the optimization\n",
    "optimizer.maximize(init_points=30, n_iter=100)\n",
    "\n",
    "variables = list(optimizer.max[\"params\"].values())\n",
    "variables = [True, True, True] + [x>0.5 for x in variables]\n",
    "X_C = X_C[X_C.columns[variables]]\n",
    "\n",
    "list1 = [\"time_since_quake\", \"time_since_quake_sq\"]\n",
    "list2 = X_C.columns\n",
    "\n",
    "# Convert lists to sets\n",
    "set1 = set(list1)\n",
    "set2 = set(list2)\n",
    "\n",
    "# Find the values in set1 that are not in set2\n",
    "uncommon_values = set1 - set2\n",
    "\n",
    "# Remove the uncommon values from list1\n",
    "list1 = [value for value in list1 if value not in uncommon_values]\n",
    "\n",
    "numeric_transformer = [\"float\", StandardScaler()]\n",
    "data_preprocessor = Prepare_data(list1, [numeric_transformer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8ab7d30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_optimization(n_estimators, gamma, subsample, max_depth, learning_rate):\n",
    "    \n",
    "    \n",
    "    model_1 = LinearRegression(fit_intercept=False, algorithm=\"svd\", copy_X=True)\n",
    "    \n",
    "    \n",
    "    n_estimators = int(n_estimators)\n",
    "    max_depth = int(max_depth)\n",
    "    \n",
    "    params = {\n",
    "    'tree_method': 'gpu_hist',  # Specify GPU usage\n",
    "    'predictor': 'gpu_predictor',\n",
    "    'enable_categorical': True,\n",
    "    'max_depth': max_depth,\n",
    "    'learning_rate': learning_rate,\n",
    "    'n_estimators': n_estimators,\n",
    "    'gamma': gamma,\n",
    "    'subsample': subsample}\n",
    "\n",
    "    model_2 = XGBRegressor(**params)\n",
    "    # Use time series split for cross validation. \n",
    "    cv_split = TimeSeriesSplit(n_splits = 4)\n",
    "    \n",
    "    # Create lists to append MSLE scores.\n",
    "    valid_msle = []\n",
    "\n",
    "    # Dates to index through. \n",
    "    dates = X_C.index.drop_duplicates()\n",
    "\n",
    "    \n",
    "    # Perform Cross-Validation to determine how model will do on unseen data.\n",
    "    for train_index, valid_index in cv_split.split(dates):\n",
    "\n",
    "        model = Hybrid_Pipeline(data_preprocessor, model_1, model_2, Boosted=True, to_tensor=False)\n",
    "\n",
    "        # Index dates.\n",
    "        date_train, date_valid = dates[train_index], dates[valid_index]\n",
    "\n",
    "        # Selecting data for y_train and y_valid.\n",
    "        y_train = y.loc[date_train]\n",
    "        y_valid = y.loc[date_valid]\n",
    "\n",
    "        # Selecting data for X_train and X_valid.\n",
    "        X_train = X_C.loc[date_train]\n",
    "        X_valid = X_C.loc[date_valid]\n",
    "\n",
    "        X_train = X_train.reset_index().sort_values([\"store_nbr\", \"family\", \"date\"])\n",
    "        X_valid = X_valid.reset_index().sort_values([\"store_nbr\", \"family\", \"date\"])\n",
    "        X_train = X_train.set_index([\"date\"])\n",
    "        X_valid = X_valid.set_index([\"date\"])\n",
    "\n",
    "        y_train = y_train.reset_index().sort_values([\"store_nbr\", \"family\", \"date\"])\n",
    "        y_valid = y_valid.reset_index().sort_values([\"store_nbr\", \"family\", \"date\"])\n",
    "        y_train = y_train.set_index([\"date\"])\n",
    "        y_valid = y_valid.set_index([\"date\"])\n",
    "\n",
    "\n",
    "        # Fitting model.\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Create predictions for Trainning and Validation.\n",
    "        pred = model.predict(X_valid)\n",
    "\n",
    "        # MSE for trainning and validation. \n",
    "        valid_msle.append(float(mean_squared_log_error(y_valid[\"sales\"], pred[\"sales\"])))\n",
    "\n",
    "\n",
    "    return -float(np.sqrt(np.mean(valid_msle)))\n",
    "\n",
    "parambounds = {\n",
    "    'learning_rate': (0.00001, 1),\n",
    "    'n_estimators': (0, 1000),\n",
    "    'max_depth': (3,12),\n",
    "    'subsample': (0, 1.0),  \n",
    "    'gamma': (1, 10),\n",
    "    \n",
    "}\n",
    "\n",
    "optimizer = BayesianOptimization(\n",
    "    f=hyperparameter_optimization,\n",
    "    pbounds=parambounds,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "optimizer.maximize(init_points=30, n_iter=100)\n",
    "print(optimizer.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cf280501-8dc3-4496-a7c7-a29767594c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "Training RMSLE: 0.660, Validation RMSLE: 0.760\n",
      "Fold 2:\n",
      "Training RMSLE: 0.650, Validation RMSLE: 0.717\n",
      "Fold 3:\n",
      "Training RMSLE: 0.786, Validation RMSLE: 0.777\n",
      "Fold 4:\n",
      "Training RMSLE: 0.725, Validation RMSLE: 0.718\n",
      "Average Across Folds\n",
      "Training RMSLE:0.707, Validation RMSLE: 0.744\n"
     ]
    }
   ],
   "source": [
    "params = optimizer.max[\"params\"]\n",
    "\n",
    "xgb_params = {\n",
    "    'tree_method': 'gpu_hist',  # Specify GPU usage\n",
    "    'predictor': 'gpu_predictor',\n",
    "    'enable_categorical': True,\n",
    "    'max_depth': int(params[\"max_depth\"]),\n",
    "    'learning_rate': params[\"learning_rate\"],\n",
    "    'n_estimators': int(params[\"n_estimators\"]),\n",
    "    'gamma': params[\"gamma\"],\n",
    "    'subsample': params[\"subsample\"]\n",
    "}\n",
    "\n",
    "xgb = XGBRegressor(**xgb_params)\n",
    "\n",
    "\n",
    "lr = LinearRegression(fit_intercept=False, algorithm=\"svd\", copy_X=True)\n",
    "\n",
    "# Use time series split for cross validation. \n",
    "cv_split = TimeSeriesSplit(n_splits = 4)\n",
    "\n",
    "# Create lists to append MSE scores. \n",
    "train_msle = []\n",
    "valid_msle = []\n",
    "\n",
    "# Dates to index through. \n",
    "dates = X_C.index.drop_duplicates()\n",
    "a = 0\n",
    "# Perform Cross-Validation to determine how model will do on unseen data.\n",
    "for train_index, valid_index in cv_split.split(dates):\n",
    "    a = a+1\n",
    "    print(f\"Fold {a}:\") \n",
    "    model = Hybrid_Pipeline(data_preprocessor, lr, xgb, Boosted=True, to_tensor=False)\n",
    "    \n",
    "    # Index dates.\n",
    "    date_train, date_valid = dates[train_index], dates[valid_index]\n",
    "\n",
    "    # Selecting data for y_train and y_valid.\n",
    "    y_train = y.loc[date_train]\n",
    "    y_valid = y.loc[date_valid]\n",
    "    \n",
    "    # Selecting data for X_train and X_valid.\n",
    "    X_train = X_C.loc[date_train]\n",
    "    X_valid = X_C.loc[date_valid]\n",
    "    \n",
    "    X_train = X_train.reset_index().sort_values([\"store_nbr\", \"family\", \"date\"])\n",
    "    X_valid = X_valid.reset_index().sort_values([\"store_nbr\", \"family\", \"date\"])\n",
    "    X_train = X_train.set_index([\"date\"])\n",
    "    X_valid = X_valid.set_index([\"date\"])\n",
    "\n",
    "    y_train = y_train.reset_index().sort_values([\"store_nbr\", \"family\", \"date\"])\n",
    "    y_valid = y_valid.reset_index().sort_values([\"store_nbr\", \"family\", \"date\"])\n",
    "    y_train = y_train.set_index([\"date\"])\n",
    "    y_valid = y_valid.set_index([\"date\"])\n",
    "\n",
    "\n",
    "    # Fitting model.\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Create predictions for Trainning and Validation.\n",
    "    fit = model.predict(X_train)\n",
    "    pred = model.predict(X_valid)\n",
    "    \n",
    "    # MSE for trainning and validation. \n",
    "    train_msle.append(float(mean_squared_log_error(y_train[\"sales\"], fit[\"sales\"])))\n",
    "    valid_msle.append(float(mean_squared_log_error(y_valid[\"sales\"], pred[\"sales\"])))\n",
    "    \n",
    "    print(f\"Training RMSLE: {cp.sqrt(mean_squared_log_error(y_train.sales, fit.sales)):.3f}, Validation RMSLE: {cp.sqrt(mean_squared_log_error(y_valid.sales, pred.sales)):.3f}\")\n",
    "\n",
    "# Returns the square root of the average of the MSE.\n",
    "print(\"Average Across Folds\")\n",
    "print(f\"Training RMSLE:{np.sqrt(np.mean(train_msle)):.3f}, Validation RMSLE: {np.sqrt(np.mean(valid_msle)):.3f}\")\n",
    "\n",
    "e_1 = 1/np.sqrt(np.mean(valid_msle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7826d387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Model\n",
    "model = Hybrid_Pipeline(data_preprocessor, lr, xgb, Boosted=True, to_tensor=False)\n",
    "model.fit(X_C, y)\n",
    "\n",
    "X_test_C = X_test_C[X_test_C.columns[variables]]\n",
    "pred_1 = model.predict(X_test_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67ffd25",
   "metadata": {},
   "source": [
    "## Linear Regression, XGBoost, Stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b07b42f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_C = X.copy()\n",
    "\n",
    "\n",
    "# X_C[\"family\"] = X_C[\"family\"].cat.codes\n",
    "# X_C[\"store_nbr\"] = X_C[\"store_nbr\"].cat.codes\n",
    "# X[\"holiday\"] = X_C[\"holiday\"].cat.codes\n",
    "# X_C[\"event\"] = X[\"event\"].cat.codes\n",
    "# X_C[\"city\"] = X_C[\"city\"].cat.codes\n",
    "# X_C[\"state\"] = X_C[\"state\"].cat.codes\n",
    "# X_C[\"type\"] = X_C[\"type\"].cat.codes\n",
    "\n",
    "X_C = X_C[[\"id\", \"store_nbr\", \"family\"] + sorted(set(X_C.columns)-set([\"id\", \"store_nbr\", \"family\"]))]\n",
    "\n",
    "X_C = X_C.reset_index().sort_values([\"store_nbr\", \"family\", \"date\"]).set_index([\"date\"])\n",
    "y = y.reset_index().sort_values([\"store_nbr\", \"family\", \"date\"]).set_index([\"date\"])\n",
    "# X_C = X_C.set_index([\"date\"])\n",
    "# y = y.set_index([\"date\"])\n",
    "\n",
    "X_test_C = X_test.copy()\n",
    "X_test_C = X_test_C[[\"id\", \"store_nbr\", \"family\"] + sorted(set(X_test_C.columns)-set([\"id\", \"store_nbr\", \"family\"]))]\n",
    "#.drop([\"state\", \"city\", \"type\", \"dayofyear\", \"year\"], axis=1)\n",
    "X_test_C = X_test_C.reset_index().sort_values([\"store_nbr\", \"family\", \"date\"])\n",
    "X_test_C = X_test_C.set_index([\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "894f42db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | Change... |   city    |    day    | dayofyear | dcoilw... | dcoilw... | dcoilw... | dcoilw... | dcoilw... | dcoilw... | dcoilw... | dcoilw... |   event   |  holiday  | holida... |   month   | onprom... | onprom... | onprom... | onprom... | onprom... | onprom... | onprom... | onprom... |  payday   | promo_... | sales_... |   state   | time_s... | time_s... | total_... | total_... |   type    |  workday  |   year    |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m-1.008   \u001b[0m | \u001b[0m0.417    \u001b[0m | \u001b[0m0.7203   \u001b[0m | \u001b[0m0.0001144\u001b[0m | \u001b[0m0.3023   \u001b[0m | \u001b[0m0.1468   \u001b[0m | \u001b[0m0.09234  \u001b[0m | \u001b[0m0.1863   \u001b[0m | \u001b[0m0.3456   \u001b[0m | \u001b[0m0.3968   \u001b[0m | \u001b[0m0.5388   \u001b[0m | \u001b[0m0.4192   \u001b[0m | \u001b[0m0.6852   \u001b[0m | \u001b[0m0.2045   \u001b[0m | \u001b[0m0.8781   \u001b[0m | \u001b[0m0.02739  \u001b[0m | \u001b[0m0.6705   \u001b[0m | \u001b[0m0.4173   \u001b[0m | \u001b[0m0.5587   \u001b[0m | \u001b[0m0.1404   \u001b[0m | \u001b[0m0.1981   \u001b[0m | \u001b[0m0.8007   \u001b[0m | \u001b[0m0.9683   \u001b[0m | \u001b[0m0.3134   \u001b[0m | \u001b[0m0.6923   \u001b[0m | \u001b[0m0.8764   \u001b[0m | \u001b[0m0.8946   \u001b[0m | \u001b[0m0.08504  \u001b[0m | \u001b[0m0.03905  \u001b[0m | \u001b[0m0.1698   \u001b[0m | \u001b[0m0.8781   \u001b[0m | \u001b[0m0.09835  \u001b[0m | \u001b[0m0.4211   \u001b[0m | \u001b[0m0.9579   \u001b[0m | \u001b[0m0.5332   \u001b[0m | \u001b[0m0.6919   \u001b[0m |\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m-0.9771  \u001b[0m | \u001b[95m0.3155   \u001b[0m | \u001b[95m0.6865   \u001b[0m | \u001b[95m0.8346   \u001b[0m | \u001b[95m0.01829  \u001b[0m | \u001b[95m0.7501   \u001b[0m | \u001b[95m0.9889   \u001b[0m | \u001b[95m0.7482   \u001b[0m | \u001b[95m0.2804   \u001b[0m | \u001b[95m0.7893   \u001b[0m | \u001b[95m0.1032   \u001b[0m | \u001b[95m0.4479   \u001b[0m | \u001b[95m0.9086   \u001b[0m | \u001b[95m0.2936   \u001b[0m | \u001b[95m0.2878   \u001b[0m | \u001b[95m0.13     \u001b[0m | \u001b[95m0.01937  \u001b[0m | \u001b[95m0.6788   \u001b[0m | \u001b[95m0.2116   \u001b[0m | \u001b[95m0.2655   \u001b[0m | \u001b[95m0.4916   \u001b[0m | \u001b[95m0.05336  \u001b[0m | \u001b[95m0.5741   \u001b[0m | \u001b[95m0.1467   \u001b[0m | \u001b[95m0.5893   \u001b[0m | \u001b[95m0.6998   \u001b[0m | \u001b[95m0.1023   \u001b[0m | \u001b[95m0.4141   \u001b[0m | \u001b[95m0.6944   \u001b[0m | \u001b[95m0.4142   \u001b[0m | \u001b[95m0.04995  \u001b[0m | \u001b[95m0.5359   \u001b[0m | \u001b[95m0.6638   \u001b[0m | \u001b[95m0.5149   \u001b[0m | \u001b[95m0.9446   \u001b[0m | \u001b[95m0.5866   \u001b[0m |\n",
      "| \u001b[95m3        \u001b[0m | \u001b[95m-0.9731  \u001b[0m | \u001b[95m0.9034   \u001b[0m | \u001b[95m0.1375   \u001b[0m | \u001b[95m0.1393   \u001b[0m | \u001b[95m0.8074   \u001b[0m | \u001b[95m0.3977   \u001b[0m | \u001b[95m0.1654   \u001b[0m | \u001b[95m0.9275   \u001b[0m | \u001b[95m0.3478   \u001b[0m | \u001b[95m0.7508   \u001b[0m | \u001b[95m0.726    \u001b[0m | \u001b[95m0.8833   \u001b[0m | \u001b[95m0.6237   \u001b[0m | \u001b[95m0.7509   \u001b[0m | \u001b[95m0.3489   \u001b[0m | \u001b[95m0.2699   \u001b[0m | \u001b[95m0.8959   \u001b[0m | \u001b[95m0.4281   \u001b[0m | \u001b[95m0.9648   \u001b[0m | \u001b[95m0.6634   \u001b[0m | \u001b[95m0.6217   \u001b[0m | \u001b[95m0.1147   \u001b[0m | \u001b[95m0.9495   \u001b[0m | \u001b[95m0.4499   \u001b[0m | \u001b[95m0.5784   \u001b[0m | \u001b[95m0.4081   \u001b[0m | \u001b[95m0.237    \u001b[0m | \u001b[95m0.9034   \u001b[0m | \u001b[95m0.5737   \u001b[0m | \u001b[95m0.00287  \u001b[0m | \u001b[95m0.6171   \u001b[0m | \u001b[95m0.3266   \u001b[0m | \u001b[95m0.5271   \u001b[0m | \u001b[95m0.8859   \u001b[0m | \u001b[95m0.3573   \u001b[0m | \u001b[95m0.9085   \u001b[0m |\n",
      "| \u001b[95m4        \u001b[0m | \u001b[95m-0.9277  \u001b[0m | \u001b[95m0.6234   \u001b[0m | \u001b[95m0.01582  \u001b[0m | \u001b[95m0.9294   \u001b[0m | \u001b[95m0.6909   \u001b[0m | \u001b[95m0.9973   \u001b[0m | \u001b[95m0.1723   \u001b[0m | \u001b[95m0.1371   \u001b[0m | \u001b[95m0.9326   \u001b[0m | \u001b[95m0.6968   \u001b[0m | \u001b[95m0.066    \u001b[0m | \u001b[95m0.7555   \u001b[0m | \u001b[95m0.7539   \u001b[0m | \u001b[95m0.923    \u001b[0m | \u001b[95m0.7115   \u001b[0m | \u001b[95m0.1243   \u001b[0m | \u001b[95m0.01988  \u001b[0m | \u001b[95m0.02621  \u001b[0m | \u001b[95m0.02831  \u001b[0m | \u001b[95m0.2462   \u001b[0m | \u001b[95m0.86     \u001b[0m | \u001b[95m0.5388   \u001b[0m | \u001b[95m0.5528   \u001b[0m | \u001b[95m0.842    \u001b[0m | \u001b[95m0.1242   \u001b[0m | \u001b[95m0.2792   \u001b[0m | \u001b[95m0.5858   \u001b[0m | \u001b[95m0.9696   \u001b[0m | \u001b[95m0.561    \u001b[0m | \u001b[95m0.01865  \u001b[0m | \u001b[95m0.8006   \u001b[0m | \u001b[95m0.233    \u001b[0m | \u001b[95m0.8071   \u001b[0m | \u001b[95m0.3879   \u001b[0m | \u001b[95m0.8635   \u001b[0m | \u001b[95m0.7471   \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m-1.15    \u001b[0m | \u001b[0m0.5562   \u001b[0m | \u001b[0m0.1365   \u001b[0m | \u001b[0m0.05992  \u001b[0m | \u001b[0m0.1213   \u001b[0m | \u001b[0m0.04455  \u001b[0m | \u001b[0m0.1075   \u001b[0m | \u001b[0m0.2257   \u001b[0m | \u001b[0m0.713    \u001b[0m | \u001b[0m0.5597   \u001b[0m | \u001b[0m0.01256  \u001b[0m | \u001b[0m0.07197  \u001b[0m | \u001b[0m0.9673   \u001b[0m | \u001b[0m0.5681   \u001b[0m | \u001b[0m0.2033   \u001b[0m | \u001b[0m0.2523   \u001b[0m | \u001b[0m0.7438   \u001b[0m | \u001b[0m0.1954   \u001b[0m | \u001b[0m0.5814   \u001b[0m | \u001b[0m0.97     \u001b[0m | \u001b[0m0.8468   \u001b[0m | \u001b[0m0.2398   \u001b[0m | \u001b[0m0.4938   \u001b[0m | \u001b[0m0.62     \u001b[0m | \u001b[0m0.829    \u001b[0m | \u001b[0m0.1568   \u001b[0m | \u001b[0m0.01858  \u001b[0m | \u001b[0m0.07002  \u001b[0m | \u001b[0m0.4863   \u001b[0m | \u001b[0m0.6063   \u001b[0m | \u001b[0m0.5689   \u001b[0m | \u001b[0m0.3174   \u001b[0m | \u001b[0m0.9886   \u001b[0m | \u001b[0m0.5797   \u001b[0m | \u001b[0m0.3801   \u001b[0m | \u001b[0m0.5509   \u001b[0m |\n",
      "| \u001b[95m6        \u001b[0m | \u001b[95m-0.8902  \u001b[0m | \u001b[95m0.7453   \u001b[0m | \u001b[95m0.6692   \u001b[0m | \u001b[95m0.2649   \u001b[0m | \u001b[95m0.06633  \u001b[0m | \u001b[95m0.3701   \u001b[0m | \u001b[95m0.6297   \u001b[0m | \u001b[95m0.2102   \u001b[0m | \u001b[95m0.7528   \u001b[0m | \u001b[95m0.06654  \u001b[0m | \u001b[95m0.2603   \u001b[0m | \u001b[95m0.8048   \u001b[0m | \u001b[95m0.1934   \u001b[0m | \u001b[95m0.6395   \u001b[0m | \u001b[95m0.5247   \u001b[0m | \u001b[95m0.9248   \u001b[0m | \u001b[95m0.2633   \u001b[0m | \u001b[95m0.06596  \u001b[0m | \u001b[95m0.7351   \u001b[0m | \u001b[95m0.7722   \u001b[0m | \u001b[95m0.9078   \u001b[0m | \u001b[95m0.932    \u001b[0m | \u001b[95m0.01395  \u001b[0m | \u001b[95m0.2344   \u001b[0m | \u001b[95m0.6168   \u001b[0m | \u001b[95m0.949    \u001b[0m | \u001b[95m0.9502   \u001b[0m | \u001b[95m0.5567   \u001b[0m | \u001b[95m0.9156   \u001b[0m | \u001b[95m0.6416   \u001b[0m | \u001b[95m0.39     \u001b[0m | \u001b[95m0.486    \u001b[0m | \u001b[95m0.6043   \u001b[0m | \u001b[95m0.5495   \u001b[0m | \u001b[95m0.9262   \u001b[0m | \u001b[95m0.9187   \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m-1.03    \u001b[0m | \u001b[0m0.3949   \u001b[0m | \u001b[0m0.9633   \u001b[0m | \u001b[0m0.174    \u001b[0m | \u001b[0m0.1263   \u001b[0m | \u001b[0m0.1351   \u001b[0m | \u001b[0m0.5057   \u001b[0m | \u001b[0m0.02152  \u001b[0m | \u001b[0m0.948    \u001b[0m | \u001b[0m0.8271   \u001b[0m | \u001b[0m0.01502  \u001b[0m | \u001b[0m0.1762   \u001b[0m | \u001b[0m0.3321   \u001b[0m | \u001b[0m0.131    \u001b[0m | \u001b[0m0.8095   \u001b[0m | \u001b[0m0.3447   \u001b[0m | \u001b[0m0.9401   \u001b[0m | \u001b[0m0.582    \u001b[0m | \u001b[0m0.8788   \u001b[0m | \u001b[0m0.8447   \u001b[0m | \u001b[0m0.9054   \u001b[0m | \u001b[0m0.4599   \u001b[0m | \u001b[0m0.5463   \u001b[0m | \u001b[0m0.7986   \u001b[0m | \u001b[0m0.2857   \u001b[0m | \u001b[0m0.4903   \u001b[0m | \u001b[0m0.5991   \u001b[0m | \u001b[0m0.01553  \u001b[0m | \u001b[0m0.5935   \u001b[0m | \u001b[0m0.4337   \u001b[0m | \u001b[0m0.8074   \u001b[0m | \u001b[0m0.3152   \u001b[0m | \u001b[0m0.8929   \u001b[0m | \u001b[0m0.5779   \u001b[0m | \u001b[0m0.184    \u001b[0m | \u001b[0m0.7879   \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m-1.222   \u001b[0m | \u001b[0m0.612    \u001b[0m | \u001b[0m0.05391  \u001b[0m | \u001b[0m0.4202   \u001b[0m | \u001b[0m0.6791   \u001b[0m | \u001b[0m0.9186   \u001b[0m | \u001b[0m0.000402 \u001b[0m | \u001b[0m0.9768   \u001b[0m | \u001b[0m0.3766   \u001b[0m | \u001b[0m0.9738   \u001b[0m | \u001b[0m0.6047   \u001b[0m | \u001b[0m0.8288   \u001b[0m | \u001b[0m0.5747   \u001b[0m | \u001b[0m0.6281   \u001b[0m | \u001b[0m0.2856   \u001b[0m | \u001b[0m0.5868   \u001b[0m | \u001b[0m0.75     \u001b[0m | \u001b[0m0.8583   \u001b[0m | \u001b[0m0.7551   \u001b[0m | \u001b[0m0.6981   \u001b[0m | \u001b[0m0.8645   \u001b[0m | \u001b[0m0.3227   \u001b[0m | \u001b[0m0.6708   \u001b[0m | \u001b[0m0.4509   \u001b[0m | \u001b[0m0.3821   \u001b[0m | \u001b[0m0.4108   \u001b[0m | \u001b[0m0.4015   \u001b[0m | \u001b[0m0.3174   \u001b[0m | \u001b[0m0.6219   \u001b[0m | \u001b[0m0.4302   \u001b[0m | \u001b[0m0.9738   \u001b[0m | \u001b[0m0.6778   \u001b[0m | \u001b[0m0.1986   \u001b[0m | \u001b[0m0.4267   \u001b[0m | \u001b[0m0.3433   \u001b[0m | \u001b[0m0.7976   \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m-0.9992  \u001b[0m | \u001b[0m0.88     \u001b[0m | \u001b[0m0.9038   \u001b[0m | \u001b[0m0.6627   \u001b[0m | \u001b[0m0.2702   \u001b[0m | \u001b[0m0.2524   \u001b[0m | \u001b[0m0.8549   \u001b[0m | \u001b[0m0.5277   \u001b[0m | \u001b[0m0.8022   \u001b[0m | \u001b[0m0.5725   \u001b[0m | \u001b[0m0.7331   \u001b[0m | \u001b[0m0.519    \u001b[0m | \u001b[0m0.7709   \u001b[0m | \u001b[0m0.5689   \u001b[0m | \u001b[0m0.4657   \u001b[0m | \u001b[0m0.3427   \u001b[0m | \u001b[0m0.06821  \u001b[0m | \u001b[0m0.3779   \u001b[0m | \u001b[0m0.07963  \u001b[0m | \u001b[0m0.9828   \u001b[0m | \u001b[0m0.1816   \u001b[0m | \u001b[0m0.8119   \u001b[0m | \u001b[0m0.875    \u001b[0m | \u001b[0m0.6884   \u001b[0m | \u001b[0m0.5695   \u001b[0m | \u001b[0m0.161    \u001b[0m | \u001b[0m0.4669   \u001b[0m | \u001b[0m0.3452   \u001b[0m | \u001b[0m0.225    \u001b[0m | \u001b[0m0.5925   \u001b[0m | \u001b[0m0.3123   \u001b[0m | \u001b[0m0.9163   \u001b[0m | \u001b[0m0.9096   \u001b[0m | \u001b[0m0.2571   \u001b[0m | \u001b[0m0.1109   \u001b[0m | \u001b[0m0.193    \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m-0.8987  \u001b[0m | \u001b[0m0.4996   \u001b[0m | \u001b[0m0.7286   \u001b[0m | \u001b[0m0.2082   \u001b[0m | \u001b[0m0.248    \u001b[0m | \u001b[0m0.8517   \u001b[0m | \u001b[0m0.4158   \u001b[0m | \u001b[0m0.6167   \u001b[0m | \u001b[0m0.2337   \u001b[0m | \u001b[0m0.102    \u001b[0m | \u001b[0m0.5159   \u001b[0m | \u001b[0m0.4771   \u001b[0m | \u001b[0m0.1527   \u001b[0m | \u001b[0m0.6218   \u001b[0m | \u001b[0m0.544    \u001b[0m | \u001b[0m0.6541   \u001b[0m | \u001b[0m0.1445   \u001b[0m | \u001b[0m0.7515   \u001b[0m | \u001b[0m0.222    \u001b[0m | \u001b[0m0.5194   \u001b[0m | \u001b[0m0.7853   \u001b[0m | \u001b[0m0.02233  \u001b[0m | \u001b[0m0.3244   \u001b[0m | \u001b[0m0.8729   \u001b[0m | \u001b[0m0.8447   \u001b[0m | \u001b[0m0.5384   \u001b[0m | \u001b[0m0.8666   \u001b[0m | \u001b[0m0.9498   \u001b[0m | \u001b[0m0.8264   \u001b[0m | \u001b[0m0.8541   \u001b[0m | \u001b[0m0.09874  \u001b[0m | \u001b[0m0.6513   \u001b[0m | \u001b[0m0.7035   \u001b[0m | \u001b[0m0.6102   \u001b[0m | \u001b[0m0.7996   \u001b[0m | \u001b[0m0.03457  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m11       \u001b[0m | \u001b[0m-0.9211  \u001b[0m | \u001b[0m0.7702   \u001b[0m | \u001b[0m0.7317   \u001b[0m | \u001b[0m0.2597   \u001b[0m | \u001b[0m0.2571   \u001b[0m | \u001b[0m0.6323   \u001b[0m | \u001b[0m0.3453   \u001b[0m | \u001b[0m0.7966   \u001b[0m | \u001b[0m0.4461   \u001b[0m | \u001b[0m0.7827   \u001b[0m | \u001b[0m0.9905   \u001b[0m | \u001b[0m0.3002   \u001b[0m | \u001b[0m0.143    \u001b[0m | \u001b[0m0.9013   \u001b[0m | \u001b[0m0.5416   \u001b[0m | \u001b[0m0.9747   \u001b[0m | \u001b[0m0.6366   \u001b[0m | \u001b[0m0.9939   \u001b[0m | \u001b[0m0.5461   \u001b[0m | \u001b[0m0.5264   \u001b[0m | \u001b[0m0.1354   \u001b[0m | \u001b[0m0.3557   \u001b[0m | \u001b[0m0.02622  \u001b[0m | \u001b[0m0.1604   \u001b[0m | \u001b[0m0.7456   \u001b[0m | \u001b[0m0.0304   \u001b[0m | \u001b[0m0.3665   \u001b[0m | \u001b[0m0.8623   \u001b[0m | \u001b[0m0.6927   \u001b[0m | \u001b[0m0.6909   \u001b[0m | \u001b[0m0.1886   \u001b[0m | \u001b[0m0.4419   \u001b[0m | \u001b[0m0.5816   \u001b[0m | \u001b[0m0.9898   \u001b[0m | \u001b[0m0.2039   \u001b[0m | \u001b[0m0.2477   \u001b[0m |\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m-0.9844  \u001b[0m | \u001b[0m0.2622   \u001b[0m | \u001b[0m0.7502   \u001b[0m | \u001b[0m0.457    \u001b[0m | \u001b[0m0.05693  \u001b[0m | \u001b[0m0.5085   \u001b[0m | \u001b[0m0.212    \u001b[0m | \u001b[0m0.7986   \u001b[0m | \u001b[0m0.2973   \u001b[0m | \u001b[0m0.02761  \u001b[0m | \u001b[0m0.5934   \u001b[0m | \u001b[0m0.8438   \u001b[0m | \u001b[0m0.381    \u001b[0m | \u001b[0m0.7499   \u001b[0m | \u001b[0m0.5111   \u001b[0m | \u001b[0m0.541    \u001b[0m | \u001b[0m0.9594   \u001b[0m | \u001b[0m0.804    \u001b[0m | \u001b[0m0.03232  \u001b[0m | \u001b[0m0.7094   \u001b[0m | \u001b[0m0.465    \u001b[0m | \u001b[0m0.9475   \u001b[0m | \u001b[0m0.2214   \u001b[0m | \u001b[0m0.2671   \u001b[0m | \u001b[0m0.08147  \u001b[0m | \u001b[0m0.4286   \u001b[0m | \u001b[0m0.109    \u001b[0m | \u001b[0m0.6338   \u001b[0m | \u001b[0m0.803    \u001b[0m | \u001b[0m0.6968   \u001b[0m | \u001b[0m0.7662   \u001b[0m | \u001b[0m0.3425   \u001b[0m | \u001b[0m0.8459   \u001b[0m | \u001b[0m0.4288   \u001b[0m | \u001b[0m0.824    \u001b[0m | \u001b[0m0.6265   \u001b[0m |\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m-0.912   \u001b[0m | \u001b[0m0.1434   \u001b[0m | \u001b[0m0.07839  \u001b[0m | \u001b[0m0.01833  \u001b[0m | \u001b[0m0.06672  \u001b[0m | \u001b[0m0.4586   \u001b[0m | \u001b[0m0.1133   \u001b[0m | \u001b[0m0.02778  \u001b[0m | \u001b[0m0.7549   \u001b[0m | \u001b[0m0.3949   \u001b[0m | \u001b[0m0.7469   \u001b[0m | \u001b[0m0.4524   \u001b[0m | \u001b[0m0.4501   \u001b[0m | \u001b[0m0.4781   \u001b[0m | \u001b[0m0.474    \u001b[0m | \u001b[0m0.8032   \u001b[0m | \u001b[0m0.4024   \u001b[0m | \u001b[0m0.9047   \u001b[0m | \u001b[0m0.03706  \u001b[0m | \u001b[0m0.7739   \u001b[0m | \u001b[0m0.1256   \u001b[0m | \u001b[0m0.6185   \u001b[0m | \u001b[0m0.01036  \u001b[0m | \u001b[0m0.5386   \u001b[0m | \u001b[0m0.003018 \u001b[0m | \u001b[0m0.9512   \u001b[0m | \u001b[0m0.9054   \u001b[0m | \u001b[0m0.796    \u001b[0m | \u001b[0m0.9153   \u001b[0m | \u001b[0m0.1456   \u001b[0m | \u001b[0m0.1577   \u001b[0m | \u001b[0m0.1876   \u001b[0m | \u001b[0m0.6225   \u001b[0m | \u001b[0m0.9058   \u001b[0m | \u001b[0m0.99     \u001b[0m | \u001b[0m0.7111   \u001b[0m |\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m-1.039   \u001b[0m | \u001b[0m0.7318   \u001b[0m | \u001b[0m0.9093   \u001b[0m | \u001b[0m0.4009   \u001b[0m | \u001b[0m0.2499   \u001b[0m | \u001b[0m0.1734   \u001b[0m | \u001b[0m0.1195   \u001b[0m | \u001b[0m0.8126   \u001b[0m | \u001b[0m0.1468   \u001b[0m | \u001b[0m0.2643   \u001b[0m | \u001b[0m0.8191   \u001b[0m | \u001b[0m0.3106   \u001b[0m | \u001b[0m0.9824   \u001b[0m | \u001b[0m0.2666   \u001b[0m | \u001b[0m0.5337   \u001b[0m | \u001b[0m0.3145   \u001b[0m | \u001b[0m0.9108   \u001b[0m | \u001b[0m0.3666   \u001b[0m | \u001b[0m0.4336   \u001b[0m | \u001b[0m0.5123   \u001b[0m | \u001b[0m0.9389   \u001b[0m | \u001b[0m0.03095  \u001b[0m | \u001b[0m0.7169   \u001b[0m | \u001b[0m0.891    \u001b[0m | \u001b[0m0.02729  \u001b[0m | \u001b[0m0.5221   \u001b[0m | \u001b[0m0.326    \u001b[0m | \u001b[0m0.8595   \u001b[0m | \u001b[0m0.5585   \u001b[0m | \u001b[0m0.6902   \u001b[0m | \u001b[0m0.4529   \u001b[0m | \u001b[0m0.6283   \u001b[0m | \u001b[0m0.2901   \u001b[0m | \u001b[0m0.009349 \u001b[0m | \u001b[0m0.5768   \u001b[0m | \u001b[0m0.3114   \u001b[0m |\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m-0.9254  \u001b[0m | \u001b[0m0.5173   \u001b[0m | \u001b[0m0.9164   \u001b[0m | \u001b[0m0.4265   \u001b[0m | \u001b[0m0.2474   \u001b[0m | \u001b[0m0.3713   \u001b[0m | \u001b[0m0.9319   \u001b[0m | \u001b[0m0.9369   \u001b[0m | \u001b[0m0.8443   \u001b[0m | \u001b[0m0.9202   \u001b[0m | \u001b[0m0.2279   \u001b[0m | \u001b[0m0.08748  \u001b[0m | \u001b[0m0.2273   \u001b[0m | \u001b[0m0.3144   \u001b[0m | \u001b[0m0.1748   \u001b[0m | \u001b[0m0.6071   \u001b[0m | \u001b[0m0.4136   \u001b[0m | \u001b[0m0.8164   \u001b[0m | \u001b[0m0.1851   \u001b[0m | \u001b[0m0.7019   \u001b[0m | \u001b[0m0.2404   \u001b[0m | \u001b[0m0.5742   \u001b[0m | \u001b[0m0.349    \u001b[0m | \u001b[0m0.05696  \u001b[0m | \u001b[0m0.2288   \u001b[0m | \u001b[0m0.6641   \u001b[0m | \u001b[0m0.4973   \u001b[0m | \u001b[0m0.519    \u001b[0m | \u001b[0m0.1747   \u001b[0m | \u001b[0m0.5707   \u001b[0m | \u001b[0m0.9968   \u001b[0m | \u001b[0m0.8168   \u001b[0m | \u001b[0m0.5944   \u001b[0m | \u001b[0m0.976    \u001b[0m | \u001b[0m0.9016   \u001b[0m | \u001b[0m0.5956   \u001b[0m |\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m-0.9272  \u001b[0m | \u001b[0m0.03243  \u001b[0m | \u001b[0m0.09358  \u001b[0m | \u001b[0m0.06537  \u001b[0m | \u001b[0m0.4517   \u001b[0m | \u001b[0m0.3754   \u001b[0m | \u001b[0m0.9754   \u001b[0m | \u001b[0m0.168    \u001b[0m | \u001b[0m0.9728   \u001b[0m | \u001b[0m0.7675   \u001b[0m | \u001b[0m0.8242   \u001b[0m | \u001b[0m0.6326   \u001b[0m | \u001b[0m0.6687   \u001b[0m | \u001b[0m0.4769   \u001b[0m | \u001b[0m0.01314  \u001b[0m | \u001b[0m0.353    \u001b[0m | \u001b[0m0.4921   \u001b[0m | \u001b[0m0.7301   \u001b[0m | \u001b[0m0.4686   \u001b[0m | \u001b[0m0.4574   \u001b[0m | \u001b[0m0.1377   \u001b[0m | \u001b[0m0.01089  \u001b[0m | \u001b[0m0.7583   \u001b[0m | \u001b[0m0.32     \u001b[0m | \u001b[0m0.9844   \u001b[0m | \u001b[0m0.2202   \u001b[0m | \u001b[0m0.3387   \u001b[0m | \u001b[0m0.5239   \u001b[0m | \u001b[0m0.7549   \u001b[0m | \u001b[0m0.4639   \u001b[0m | \u001b[0m0.1248   \u001b[0m | \u001b[0m0.3125   \u001b[0m | \u001b[0m0.5045   \u001b[0m | \u001b[0m0.6738   \u001b[0m | \u001b[0m0.7701   \u001b[0m | \u001b[0m0.1303   \u001b[0m |\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m-0.9366  \u001b[0m | \u001b[0m0.02292  \u001b[0m | \u001b[0m0.5191   \u001b[0m | \u001b[0m0.81     \u001b[0m | \u001b[0m0.0126   \u001b[0m | \u001b[0m0.6725   \u001b[0m | \u001b[0m0.6868   \u001b[0m | \u001b[0m0.4492   \u001b[0m | \u001b[0m0.9148   \u001b[0m | \u001b[0m0.6444   \u001b[0m | \u001b[0m0.00524  \u001b[0m | \u001b[0m0.4844   \u001b[0m | \u001b[0m0.8593   \u001b[0m | \u001b[0m0.8304   \u001b[0m | \u001b[0m0.6492   \u001b[0m | \u001b[0m0.6737   \u001b[0m | \u001b[0m0.5785   \u001b[0m | \u001b[0m0.2741   \u001b[0m | \u001b[0m0.5605   \u001b[0m | \u001b[0m0.6717   \u001b[0m | \u001b[0m0.3524   \u001b[0m | \u001b[0m0.8558   \u001b[0m | \u001b[0m0.195    \u001b[0m | \u001b[0m0.7473   \u001b[0m | \u001b[0m0.2896   \u001b[0m | \u001b[0m0.7738   \u001b[0m | \u001b[0m0.4277   \u001b[0m | \u001b[0m0.8077   \u001b[0m | \u001b[0m0.3535   \u001b[0m | \u001b[0m0.2137   \u001b[0m | \u001b[0m0.7673   \u001b[0m | \u001b[0m0.3086   \u001b[0m | \u001b[0m0.7332   \u001b[0m | \u001b[0m0.7445   \u001b[0m | \u001b[0m0.2214   \u001b[0m | \u001b[0m0.2141   \u001b[0m |\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m-0.9299  \u001b[0m | \u001b[0m0.1989   \u001b[0m | \u001b[0m0.1425   \u001b[0m | \u001b[0m0.3771   \u001b[0m | \u001b[0m0.02663  \u001b[0m | \u001b[0m0.1109   \u001b[0m | \u001b[0m0.6746   \u001b[0m | \u001b[0m0.7998   \u001b[0m | \u001b[0m0.08053  \u001b[0m | \u001b[0m0.2317   \u001b[0m | \u001b[0m0.2076   \u001b[0m | \u001b[0m0.9173   \u001b[0m | \u001b[0m0.7113   \u001b[0m | \u001b[0m0.5539   \u001b[0m | \u001b[0m0.3045   \u001b[0m | \u001b[0m0.8349   \u001b[0m | \u001b[0m0.4353   \u001b[0m | \u001b[0m0.9235   \u001b[0m | \u001b[0m0.7061   \u001b[0m | \u001b[0m0.478    \u001b[0m | \u001b[0m0.1262   \u001b[0m | \u001b[0m0.976    \u001b[0m | \u001b[0m0.1598   \u001b[0m | \u001b[0m0.2026   \u001b[0m | \u001b[0m0.4312   \u001b[0m | \u001b[0m0.4042   \u001b[0m | \u001b[0m0.1468   \u001b[0m | \u001b[0m0.7293   \u001b[0m | \u001b[0m0.1887   \u001b[0m | \u001b[0m0.6439   \u001b[0m | \u001b[0m0.7543   \u001b[0m | \u001b[0m0.2107   \u001b[0m | \u001b[0m0.601    \u001b[0m | \u001b[0m0.7489   \u001b[0m | \u001b[0m0.6382   \u001b[0m | \u001b[0m0.5971   \u001b[0m |\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m-0.9077  \u001b[0m | \u001b[0m0.2955   \u001b[0m | \u001b[0m0.7316   \u001b[0m | \u001b[0m0.9453   \u001b[0m | \u001b[0m0.4256   \u001b[0m | \u001b[0m0.7822   \u001b[0m | \u001b[0m0.05614  \u001b[0m | \u001b[0m0.8353   \u001b[0m | \u001b[0m0.1923   \u001b[0m | \u001b[0m0.3951   \u001b[0m | \u001b[0m0.3001   \u001b[0m | \u001b[0m0.0801   \u001b[0m | \u001b[0m0.9046   \u001b[0m | \u001b[0m0.3702   \u001b[0m | \u001b[0m0.5307   \u001b[0m | \u001b[0m0.4941   \u001b[0m | \u001b[0m0.1322   \u001b[0m | \u001b[0m0.2065   \u001b[0m | \u001b[0m0.07619  \u001b[0m | \u001b[0m0.5079   \u001b[0m | \u001b[0m0.2615   \u001b[0m | \u001b[0m0.3571   \u001b[0m | \u001b[0m0.1081   \u001b[0m | \u001b[0m0.7876   \u001b[0m | \u001b[0m0.1066   \u001b[0m | \u001b[0m0.9857   \u001b[0m | \u001b[0m0.1772   \u001b[0m | \u001b[0m0.5724   \u001b[0m | \u001b[0m0.04485  \u001b[0m | \u001b[0m0.7871   \u001b[0m | \u001b[0m0.1896   \u001b[0m | \u001b[0m0.5279   \u001b[0m | \u001b[0m0.7401   \u001b[0m | \u001b[0m0.1499   \u001b[0m | \u001b[0m0.5511   \u001b[0m | \u001b[0m0.2166   \u001b[0m |\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m-0.9564  \u001b[0m | \u001b[0m0.7592   \u001b[0m | \u001b[0m0.7229   \u001b[0m | \u001b[0m0.1765   \u001b[0m | \u001b[0m0.862    \u001b[0m | \u001b[0m0.01978  \u001b[0m | \u001b[0m0.8602   \u001b[0m | \u001b[0m0.5589   \u001b[0m | \u001b[0m0.4032   \u001b[0m | \u001b[0m0.7587   \u001b[0m | \u001b[0m0.7169   \u001b[0m | \u001b[0m0.9873   \u001b[0m | \u001b[0m0.2781   \u001b[0m | \u001b[0m0.003794 \u001b[0m | \u001b[0m0.9339   \u001b[0m | \u001b[0m0.8579   \u001b[0m | \u001b[0m0.7289   \u001b[0m | \u001b[0m0.5167   \u001b[0m | \u001b[0m0.707    \u001b[0m | \u001b[0m0.7805   \u001b[0m | \u001b[0m0.3749   \u001b[0m | \u001b[0m0.7703   \u001b[0m | \u001b[0m0.7506   \u001b[0m | \u001b[0m0.6132   \u001b[0m | \u001b[0m0.4019   \u001b[0m | \u001b[0m0.6973   \u001b[0m | \u001b[0m0.003113 \u001b[0m | \u001b[0m0.7749   \u001b[0m | \u001b[0m0.8964   \u001b[0m | \u001b[0m0.2393   \u001b[0m | \u001b[0m0.1208   \u001b[0m | \u001b[0m0.2203   \u001b[0m | \u001b[0m0.3021   \u001b[0m | \u001b[0m0.883    \u001b[0m | \u001b[0m0.5432   \u001b[0m | \u001b[0m0.2867   \u001b[0m |\n",
      "| \u001b[0m21       \u001b[0m | \u001b[0m-0.9442  \u001b[0m | \u001b[0m0.1384   \u001b[0m | \u001b[0m0.2901   \u001b[0m | \u001b[0m0.6139   \u001b[0m | \u001b[0m0.3241   \u001b[0m | \u001b[0m0.4574   \u001b[0m | \u001b[0m0.4441   \u001b[0m | \u001b[0m0.8281   \u001b[0m | \u001b[0m0.4263   \u001b[0m | \u001b[0m0.3457   \u001b[0m | \u001b[0m0.675    \u001b[0m | \u001b[0m0.2215   \u001b[0m | \u001b[0m0.4672   \u001b[0m | \u001b[0m0.3148   \u001b[0m | \u001b[0m0.6269   \u001b[0m | \u001b[0m0.8774   \u001b[0m | \u001b[0m0.4477   \u001b[0m | \u001b[0m0.7845   \u001b[0m | \u001b[0m0.457    \u001b[0m | \u001b[0m0.6562   \u001b[0m | \u001b[0m0.1318   \u001b[0m | \u001b[0m0.433    \u001b[0m | \u001b[0m0.9093   \u001b[0m | \u001b[0m0.6055   \u001b[0m | \u001b[0m0.7668   \u001b[0m | \u001b[0m0.5047   \u001b[0m | \u001b[0m0.4981   \u001b[0m | \u001b[0m0.8429   \u001b[0m | \u001b[0m0.06781  \u001b[0m | \u001b[0m0.5733   \u001b[0m | \u001b[0m0.9428   \u001b[0m | \u001b[0m0.5179   \u001b[0m | \u001b[0m0.1945   \u001b[0m | \u001b[0m0.8479   \u001b[0m | \u001b[0m0.2516   \u001b[0m | \u001b[0m0.7007   \u001b[0m |\n",
      "| \u001b[0m22       \u001b[0m | \u001b[0m-0.9452  \u001b[0m | \u001b[0m0.5403   \u001b[0m | \u001b[0m0.9488   \u001b[0m | \u001b[0m0.6243   \u001b[0m | \u001b[0m0.838    \u001b[0m | \u001b[0m0.007933 \u001b[0m | \u001b[0m0.9893   \u001b[0m | \u001b[0m0.07771  \u001b[0m | \u001b[0m0.3221   \u001b[0m | \u001b[0m0.9462   \u001b[0m | \u001b[0m0.008939 \u001b[0m | \u001b[0m0.8227   \u001b[0m | \u001b[0m0.8612   \u001b[0m | \u001b[0m0.4398   \u001b[0m | \u001b[0m0.2557   \u001b[0m | \u001b[0m0.8027   \u001b[0m | \u001b[0m0.4779   \u001b[0m | \u001b[0m0.1343   \u001b[0m | \u001b[0m0.9278   \u001b[0m | \u001b[0m0.896    \u001b[0m | \u001b[0m0.4915   \u001b[0m | \u001b[0m0.8567   \u001b[0m | \u001b[0m0.4186   \u001b[0m | \u001b[0m0.6835   \u001b[0m | \u001b[0m0.398    \u001b[0m | \u001b[0m0.5057   \u001b[0m | \u001b[0m0.1896   \u001b[0m | \u001b[0m0.965    \u001b[0m | \u001b[0m0.2942   \u001b[0m | \u001b[0m0.1035   \u001b[0m | \u001b[0m0.1443   \u001b[0m | \u001b[0m0.01409  \u001b[0m | \u001b[0m0.7159   \u001b[0m | \u001b[0m0.5645   \u001b[0m | \u001b[0m0.7946   \u001b[0m | \u001b[0m0.5071   \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m23       \u001b[0m | \u001b[0m-0.9872  \u001b[0m | \u001b[0m0.7918   \u001b[0m | \u001b[0m0.6958   \u001b[0m | \u001b[0m0.7778   \u001b[0m | \u001b[0m0.4065   \u001b[0m | \u001b[0m0.6478   \u001b[0m | \u001b[0m0.1798   \u001b[0m | \u001b[0m0.3218   \u001b[0m | \u001b[0m0.1726   \u001b[0m | \u001b[0m0.4086   \u001b[0m | \u001b[0m0.2414   \u001b[0m | \u001b[0m0.4069   \u001b[0m | \u001b[0m0.9752   \u001b[0m | \u001b[0m0.3203   \u001b[0m | \u001b[0m0.9825   \u001b[0m | \u001b[0m0.6363   \u001b[0m | \u001b[0m0.3751   \u001b[0m | \u001b[0m0.8575   \u001b[0m | \u001b[0m0.6196   \u001b[0m | \u001b[0m0.252    \u001b[0m | \u001b[0m0.7929   \u001b[0m | \u001b[0m0.4329   \u001b[0m | \u001b[0m0.3575   \u001b[0m | \u001b[0m0.3303   \u001b[0m | \u001b[0m0.6974   \u001b[0m | \u001b[0m0.2687   \u001b[0m | \u001b[0m0.8083   \u001b[0m | \u001b[0m0.2953   \u001b[0m | \u001b[0m0.5441   \u001b[0m | \u001b[0m0.4879   \u001b[0m | \u001b[0m0.8554   \u001b[0m | \u001b[0m0.8884   \u001b[0m | \u001b[0m0.1844   \u001b[0m | \u001b[0m0.5853   \u001b[0m | \u001b[0m0.8982   \u001b[0m | \u001b[0m0.4461   \u001b[0m |\n",
      "| \u001b[0m24       \u001b[0m | \u001b[0m-0.9871  \u001b[0m | \u001b[0m0.9219   \u001b[0m | \u001b[0m0.279    \u001b[0m | \u001b[0m0.6088   \u001b[0m | \u001b[0m0.6825   \u001b[0m | \u001b[0m0.2282   \u001b[0m | \u001b[0m0.01377  \u001b[0m | \u001b[0m0.4167   \u001b[0m | \u001b[0m0.9385   \u001b[0m | \u001b[0m0.343    \u001b[0m | \u001b[0m0.7797   \u001b[0m | \u001b[0m0.1747   \u001b[0m | \u001b[0m0.342    \u001b[0m | \u001b[0m0.1446   \u001b[0m | \u001b[0m0.7168   \u001b[0m | \u001b[0m0.6993   \u001b[0m | \u001b[0m0.6885   \u001b[0m | \u001b[0m0.2534   \u001b[0m | \u001b[0m0.6924   \u001b[0m | \u001b[0m0.2273   \u001b[0m | \u001b[0m0.4246   \u001b[0m | \u001b[0m0.3719   \u001b[0m | \u001b[0m0.3553   \u001b[0m | \u001b[0m0.05765  \u001b[0m | \u001b[0m0.6316   \u001b[0m | \u001b[0m0.7073   \u001b[0m | \u001b[0m0.6136   \u001b[0m | \u001b[0m0.6483   \u001b[0m | \u001b[0m0.1699   \u001b[0m | \u001b[0m0.1494   \u001b[0m | \u001b[0m0.5142   \u001b[0m | \u001b[0m0.8753   \u001b[0m | \u001b[0m0.184    \u001b[0m | \u001b[0m0.4628   \u001b[0m | \u001b[0m0.4289   \u001b[0m | \u001b[0m0.4973   \u001b[0m |\n",
      "| \u001b[0m25       \u001b[0m | \u001b[0m-1.083   \u001b[0m | \u001b[0m0.1615   \u001b[0m | \u001b[0m0.3424   \u001b[0m | \u001b[0m0.2619   \u001b[0m | \u001b[0m0.8445   \u001b[0m | \u001b[0m0.8003   \u001b[0m | \u001b[0m0.4266   \u001b[0m | \u001b[0m0.607    \u001b[0m | \u001b[0m0.1455   \u001b[0m | \u001b[0m0.5096   \u001b[0m | \u001b[0m0.2969   \u001b[0m | \u001b[0m0.8597   \u001b[0m | \u001b[0m0.6716   \u001b[0m | \u001b[0m0.6335   \u001b[0m | \u001b[0m0.1248   \u001b[0m | \u001b[0m0.4706   \u001b[0m | \u001b[0m0.9866   \u001b[0m | \u001b[0m0.9483   \u001b[0m | \u001b[0m0.6451   \u001b[0m | \u001b[0m0.1517   \u001b[0m | \u001b[0m0.6391   \u001b[0m | \u001b[0m0.5657   \u001b[0m | \u001b[0m0.4687   \u001b[0m | \u001b[0m0.428    \u001b[0m | \u001b[0m0.5993   \u001b[0m | \u001b[0m0.85     \u001b[0m | \u001b[0m0.7511   \u001b[0m | \u001b[0m0.5794   \u001b[0m | \u001b[0m0.9247   \u001b[0m | \u001b[0m0.06474  \u001b[0m | \u001b[0m0.9913   \u001b[0m | \u001b[0m0.05299  \u001b[0m | \u001b[0m0.1995   \u001b[0m | \u001b[0m0.4228   \u001b[0m | \u001b[0m0.1075   \u001b[0m | \u001b[0m0.6237   \u001b[0m |\n",
      "| \u001b[0m26       \u001b[0m | \u001b[0m-0.9742  \u001b[0m | \u001b[0m0.04799  \u001b[0m | \u001b[0m0.2846   \u001b[0m | \u001b[0m0.06104  \u001b[0m | \u001b[0m0.7035   \u001b[0m | \u001b[0m0.6685   \u001b[0m | \u001b[0m0.3786   \u001b[0m | \u001b[0m0.1882   \u001b[0m | \u001b[0m0.747    \u001b[0m | \u001b[0m0.3404   \u001b[0m | \u001b[0m0.7953   \u001b[0m | \u001b[0m0.4879   \u001b[0m | \u001b[0m0.5257   \u001b[0m | \u001b[0m0.02849  \u001b[0m | \u001b[0m0.6442   \u001b[0m | \u001b[0m0.3507   \u001b[0m | \u001b[0m0.2292   \u001b[0m | \u001b[0m0.4339   \u001b[0m | \u001b[0m0.3825   \u001b[0m | \u001b[0m0.4698   \u001b[0m | \u001b[0m0.9795   \u001b[0m | \u001b[0m0.3644   \u001b[0m | \u001b[0m0.7744   \u001b[0m | \u001b[0m0.5528   \u001b[0m | \u001b[0m0.8891   \u001b[0m | \u001b[0m0.355    \u001b[0m | \u001b[0m0.2455   \u001b[0m | \u001b[0m0.911    \u001b[0m | \u001b[0m0.04353  \u001b[0m | \u001b[0m0.9508   \u001b[0m | \u001b[0m0.5564   \u001b[0m | \u001b[0m0.3764   \u001b[0m | \u001b[0m0.9951   \u001b[0m | \u001b[0m0.05836  \u001b[0m | \u001b[0m0.5167   \u001b[0m | \u001b[0m0.0311   \u001b[0m |\n",
      "| \u001b[0m27       \u001b[0m | \u001b[0m-1.571   \u001b[0m | \u001b[0m0.5712   \u001b[0m | \u001b[0m0.1805   \u001b[0m | \u001b[0m0.631    \u001b[0m | \u001b[0m0.9809   \u001b[0m | \u001b[0m0.8749   \u001b[0m | \u001b[0m0.4518   \u001b[0m | \u001b[0m0.7085   \u001b[0m | \u001b[0m0.7775   \u001b[0m | \u001b[0m0.4948   \u001b[0m | \u001b[0m0.5285   \u001b[0m | \u001b[0m0.1508   \u001b[0m | \u001b[0m0.3694   \u001b[0m | \u001b[0m0.1422   \u001b[0m | \u001b[0m0.7269   \u001b[0m | \u001b[0m0.477    \u001b[0m | \u001b[0m0.4489   \u001b[0m | \u001b[0m0.886    \u001b[0m | \u001b[0m0.5276   \u001b[0m | \u001b[0m0.4091   \u001b[0m | \u001b[0m0.2689   \u001b[0m | \u001b[0m0.07201  \u001b[0m | \u001b[0m0.4181   \u001b[0m | \u001b[0m0.02575  \u001b[0m | \u001b[0m0.2912   \u001b[0m | \u001b[0m0.5035   \u001b[0m | \u001b[0m0.9659   \u001b[0m | \u001b[0m0.1094   \u001b[0m | \u001b[0m0.673    \u001b[0m | \u001b[0m0.4999   \u001b[0m | \u001b[0m0.7771   \u001b[0m | \u001b[0m0.1436   \u001b[0m | \u001b[0m0.0832   \u001b[0m | \u001b[0m0.3992   \u001b[0m | \u001b[0m0.797    \u001b[0m | \u001b[0m0.1917   \u001b[0m |\n",
      "| \u001b[0m28       \u001b[0m | \u001b[0m-0.9321  \u001b[0m | \u001b[0m0.7678   \u001b[0m | \u001b[0m0.2903   \u001b[0m | \u001b[0m0.2169   \u001b[0m | \u001b[0m0.01672  \u001b[0m | \u001b[0m0.3987   \u001b[0m | \u001b[0m0.3811   \u001b[0m | \u001b[0m0.6593   \u001b[0m | \u001b[0m0.07092  \u001b[0m | \u001b[0m0.1526   \u001b[0m | \u001b[0m0.01658  \u001b[0m | \u001b[0m0.1138   \u001b[0m | \u001b[0m0.6518   \u001b[0m | \u001b[0m0.4027   \u001b[0m | \u001b[0m0.321    \u001b[0m | \u001b[0m0.5579   \u001b[0m | \u001b[0m0.9935   \u001b[0m | \u001b[0m0.8345   \u001b[0m | \u001b[0m0.6996   \u001b[0m | \u001b[0m0.9183   \u001b[0m | \u001b[0m0.03973  \u001b[0m | \u001b[0m0.07033  \u001b[0m | \u001b[0m0.474    \u001b[0m | \u001b[0m0.3492   \u001b[0m | \u001b[0m0.9373   \u001b[0m | \u001b[0m0.4896   \u001b[0m | \u001b[0m0.5396   \u001b[0m | \u001b[0m0.8953   \u001b[0m | \u001b[0m0.4466   \u001b[0m | \u001b[0m0.877    \u001b[0m | \u001b[0m0.2536   \u001b[0m | \u001b[0m0.2738   \u001b[0m | \u001b[0m0.3284   \u001b[0m | \u001b[0m0.5476   \u001b[0m | \u001b[0m0.2201   \u001b[0m | \u001b[0m0.6714   \u001b[0m |\n",
      "| \u001b[0m29       \u001b[0m | \u001b[0m-1.102   \u001b[0m | \u001b[0m0.1428   \u001b[0m | \u001b[0m0.0941   \u001b[0m | \u001b[0m0.8702   \u001b[0m | \u001b[0m0.2369   \u001b[0m | \u001b[0m0.386    \u001b[0m | \u001b[0m0.5715   \u001b[0m | \u001b[0m0.5258   \u001b[0m | \u001b[0m0.07602  \u001b[0m | \u001b[0m0.8741   \u001b[0m | \u001b[0m0.9511   \u001b[0m | \u001b[0m0.8125   \u001b[0m | \u001b[0m0.2838   \u001b[0m | \u001b[0m0.5278   \u001b[0m | \u001b[0m0.3394   \u001b[0m | \u001b[0m0.5547   \u001b[0m | \u001b[0m0.9744   \u001b[0m | \u001b[0m0.3117   \u001b[0m | \u001b[0m0.6688   \u001b[0m | \u001b[0m0.326    \u001b[0m | \u001b[0m0.7745   \u001b[0m | \u001b[0m0.3258   \u001b[0m | \u001b[0m0.8898   \u001b[0m | \u001b[0m0.7517   \u001b[0m | \u001b[0m0.7626   \u001b[0m | \u001b[0m0.4695   \u001b[0m | \u001b[0m0.2108   \u001b[0m | \u001b[0m0.04148  \u001b[0m | \u001b[0m0.3218   \u001b[0m | \u001b[0m0.03711  \u001b[0m | \u001b[0m0.6939   \u001b[0m | \u001b[0m0.6704   \u001b[0m | \u001b[0m0.4305   \u001b[0m | \u001b[0m0.7678   \u001b[0m | \u001b[0m0.536    \u001b[0m | \u001b[0m0.03986  \u001b[0m |\n",
      "| \u001b[0m30       \u001b[0m | \u001b[0m-1.025   \u001b[0m | \u001b[0m0.1348   \u001b[0m | \u001b[0m0.1934   \u001b[0m | \u001b[0m0.3357   \u001b[0m | \u001b[0m0.05231  \u001b[0m | \u001b[0m0.6051   \u001b[0m | \u001b[0m0.5121   \u001b[0m | \u001b[0m0.6175   \u001b[0m | \u001b[0m0.4324   \u001b[0m | \u001b[0m0.8477   \u001b[0m | \u001b[0m0.4541   \u001b[0m | \u001b[0m0.0154   \u001b[0m | \u001b[0m0.8731   \u001b[0m | \u001b[0m0.6562   \u001b[0m | \u001b[0m0.823    \u001b[0m | \u001b[0m0.9518   \u001b[0m | \u001b[0m0.05091  \u001b[0m | \u001b[0m0.2351   \u001b[0m | \u001b[0m0.06334  \u001b[0m | \u001b[0m0.4217   \u001b[0m | \u001b[0m0.8638   \u001b[0m | \u001b[0m0.08162  \u001b[0m | \u001b[0m0.4731   \u001b[0m | \u001b[0m0.1255   \u001b[0m | \u001b[0m0.7729   \u001b[0m | \u001b[0m0.8414   \u001b[0m | \u001b[0m0.04329  \u001b[0m | \u001b[0m0.4864   \u001b[0m | \u001b[0m0.2394   \u001b[0m | \u001b[0m0.9525   \u001b[0m | \u001b[0m0.9439   \u001b[0m | \u001b[0m0.6139   \u001b[0m | \u001b[0m0.9735   \u001b[0m | \u001b[0m0.3449   \u001b[0m | \u001b[0m0.8979   \u001b[0m | \u001b[0m0.4346   \u001b[0m |\n",
      "| \u001b[0m31       \u001b[0m | \u001b[0m-0.924   \u001b[0m | \u001b[0m0.4508   \u001b[0m | \u001b[0m0.6974   \u001b[0m | \u001b[0m0.288    \u001b[0m | \u001b[0m0.01808  \u001b[0m | \u001b[0m0.4007   \u001b[0m | \u001b[0m0.5959   \u001b[0m | \u001b[0m0.4228   \u001b[0m | \u001b[0m0.4767   \u001b[0m | \u001b[0m0.2924   \u001b[0m | \u001b[0m0.4139   \u001b[0m | \u001b[0m0.5554   \u001b[0m | \u001b[0m0.3761   \u001b[0m | \u001b[0m0.6145   \u001b[0m | \u001b[0m0.4529   \u001b[0m | \u001b[0m0.8771   \u001b[0m | \u001b[0m0.2701   \u001b[0m | \u001b[0m0.5512   \u001b[0m | \u001b[0m0.4007   \u001b[0m | \u001b[0m0.6691   \u001b[0m | \u001b[0m0.3128   \u001b[0m | \u001b[0m0.6534   \u001b[0m | \u001b[0m0.1485   \u001b[0m | \u001b[0m0.5399   \u001b[0m | \u001b[0m0.6314   \u001b[0m | \u001b[0m0.7124   \u001b[0m | \u001b[0m0.5876   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.5318   \u001b[0m | \u001b[0m0.5942   \u001b[0m | \u001b[0m0.1564   \u001b[0m | \u001b[0m0.5279   \u001b[0m | \u001b[0m0.6897   \u001b[0m | \u001b[0m0.8598   \u001b[0m | \u001b[0m0.7058   \u001b[0m | \u001b[0m0.5616   \u001b[0m |\n",
      "| \u001b[0m32       \u001b[0m | \u001b[0m-0.9508  \u001b[0m | \u001b[0m0.3086   \u001b[0m | \u001b[0m0.8644   \u001b[0m | \u001b[0m0.5827   \u001b[0m | \u001b[0m0.05142  \u001b[0m | \u001b[0m0.6658   \u001b[0m | \u001b[0m0.3703   \u001b[0m | \u001b[0m0.8977   \u001b[0m | \u001b[0m0.02205  \u001b[0m | \u001b[0m0.2456   \u001b[0m | \u001b[0m0.3127   \u001b[0m | \u001b[0m0.1981   \u001b[0m | \u001b[0m0.5502   \u001b[0m | \u001b[0m0.5837   \u001b[0m | \u001b[0m0.4896   \u001b[0m | \u001b[0m0.7431   \u001b[0m | \u001b[0m0.2832   \u001b[0m | \u001b[0m0.7941   \u001b[0m | \u001b[0m0.216    \u001b[0m | \u001b[0m0.526    \u001b[0m | \u001b[0m0.02819  \u001b[0m | \u001b[0m0.3537   \u001b[0m | \u001b[0m0.2076   \u001b[0m | \u001b[0m0.7693   \u001b[0m | \u001b[0m0.739    \u001b[0m | \u001b[0m0.5362   \u001b[0m | \u001b[0m0.255    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.08227  \u001b[0m | \u001b[0m0.8947   \u001b[0m | \u001b[0m0.1576   \u001b[0m | \u001b[0m0.6268   \u001b[0m | \u001b[0m0.7376   \u001b[0m | \u001b[0m0.7735   \u001b[0m | \u001b[0m0.3284   \u001b[0m | \u001b[0m0.2151   \u001b[0m |\n",
      "| \u001b[0m33       \u001b[0m | \u001b[0m-0.9427  \u001b[0m | \u001b[0m0.4825   \u001b[0m | \u001b[0m0.6464   \u001b[0m | \u001b[0m0.6636   \u001b[0m | \u001b[0m0.1846   \u001b[0m | \u001b[0m0.7012   \u001b[0m | \u001b[0m0.2933   \u001b[0m | \u001b[0m0.1116   \u001b[0m | \u001b[0m0.6059   \u001b[0m | \u001b[0m0.1602   \u001b[0m | \u001b[0m0.1469   \u001b[0m | \u001b[0m0.757    \u001b[0m | \u001b[0m0.5726   \u001b[0m | \u001b[0m0.7192   \u001b[0m | \u001b[0m0.6756   \u001b[0m | \u001b[0m0.639    \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.01438  \u001b[0m | \u001b[0m0.1797   \u001b[0m | \u001b[0m0.5036   \u001b[0m | \u001b[0m0.7943   \u001b[0m | \u001b[0m0.8419   \u001b[0m | \u001b[0m0.02817  \u001b[0m | \u001b[0m0.8378   \u001b[0m | \u001b[0m0.2824   \u001b[0m | \u001b[0m0.9403   \u001b[0m | \u001b[0m0.7571   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.6176   \u001b[0m | \u001b[0m0.3814   \u001b[0m | \u001b[0m0.2168   \u001b[0m | \u001b[0m0.5254   \u001b[0m | \u001b[0m0.882    \u001b[0m | \u001b[0m0.476    \u001b[0m | \u001b[0m0.9881   \u001b[0m | \u001b[0m0.6435   \u001b[0m |\n",
      "| \u001b[0m34       \u001b[0m | \u001b[0m-0.9743  \u001b[0m | \u001b[0m0.2961   \u001b[0m | \u001b[0m0.6664   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0182   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.6275   \u001b[0m | \u001b[0m0.6738   \u001b[0m | \u001b[0m0.612    \u001b[0m | \u001b[0m0.7386   \u001b[0m | \u001b[0m0.5045   \u001b[0m | \u001b[0m0.3919   \u001b[0m | \u001b[0m0.526    \u001b[0m | \u001b[0m0.1379   \u001b[0m | \u001b[0m0.8534   \u001b[0m | \u001b[0m0.6158   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.4758   \u001b[0m | \u001b[0m0.6442   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.4905   \u001b[0m | \u001b[0m0.6028   \u001b[0m | \u001b[0m0.1146   \u001b[0m | \u001b[0m0.9629   \u001b[0m | \u001b[0m0.3201   \u001b[0m | \u001b[0m0.1681   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.2885   \u001b[0m | \u001b[0m0.5225   \u001b[0m | \u001b[0m0.2103   \u001b[0m | \u001b[0m0.4998   \u001b[0m | \u001b[0m0.5237   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.5219   \u001b[0m | \u001b[0m0.6704   \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m35       \u001b[0m | \u001b[0m-0.9196  \u001b[0m | \u001b[0m0.979    \u001b[0m | \u001b[0m0.9077   \u001b[0m | \u001b[0m0.06569  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.5585   \u001b[0m | \u001b[0m0.3646   \u001b[0m | \u001b[0m0.2063   \u001b[0m | \u001b[0m0.3388   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.5806   \u001b[0m | \u001b[0m0.7683   \u001b[0m | \u001b[0m0.02502  \u001b[0m | \u001b[0m0.827    \u001b[0m | \u001b[0m0.758    \u001b[0m | \u001b[0m0.9757   \u001b[0m | \u001b[0m0.2494   \u001b[0m | \u001b[0m0.4515   \u001b[0m | \u001b[0m0.5952   \u001b[0m | \u001b[0m0.567    \u001b[0m | \u001b[0m0.9815   \u001b[0m | \u001b[0m0.5585   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.4413   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.5327   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.8032   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.7428   \u001b[0m | \u001b[0m0.7233   \u001b[0m | \u001b[0m0.7509   \u001b[0m | \u001b[0m0.8238   \u001b[0m | \u001b[0m0.496    \u001b[0m |\n",
      "| \u001b[0m36       \u001b[0m | \u001b[0m-0.9179  \u001b[0m | \u001b[0m0.8505   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.6869   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.1124   \u001b[0m | \u001b[0m0.7169   \u001b[0m | \u001b[0m0.5335   \u001b[0m | \u001b[0m0.5176   \u001b[0m | \u001b[0m0.2239   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.5691   \u001b[0m | \u001b[0m0.4169   \u001b[0m | \u001b[0m0.4887   \u001b[0m | \u001b[0m0.6528   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.3202   \u001b[0m | \u001b[0m0.2486   \u001b[0m | \u001b[0m0.6906   \u001b[0m | \u001b[0m0.6076   \u001b[0m | \u001b[0m0.5229   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.07764  \u001b[0m | \u001b[0m0.1441   \u001b[0m | \u001b[0m0.5434   \u001b[0m | \u001b[0m0.8176   \u001b[0m | \u001b[0m0.6292   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.2006   \u001b[0m | \u001b[0m0.4876   \u001b[0m | \u001b[0m0.8813   \u001b[0m | \u001b[0m0.9304   \u001b[0m | \u001b[0m0.5246   \u001b[0m | \u001b[0m0.9681   \u001b[0m | \u001b[0m0.7911   \u001b[0m | \u001b[0m0.9705   \u001b[0m |\n",
      "| \u001b[0m37       \u001b[0m | \u001b[0m-0.9264  \u001b[0m | \u001b[0m0.8511   \u001b[0m | \u001b[0m0.3782   \u001b[0m | \u001b[0m0.05007  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.3901   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.8181   \u001b[0m | \u001b[0m0.2079   \u001b[0m | \u001b[0m0.6526   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.3783   \u001b[0m | \u001b[0m0.7417   \u001b[0m | \u001b[0m0.7484   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.4564   \u001b[0m | \u001b[0m0.2334   \u001b[0m | \u001b[0m0.7137   \u001b[0m | \u001b[0m0.6937   \u001b[0m | \u001b[0m0.2861   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.1955   \u001b[0m | \u001b[0m0.3144   \u001b[0m | \u001b[0m0.9632   \u001b[0m | \u001b[0m0.756    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.8617   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.2533   \u001b[0m | \u001b[0m0.5749   \u001b[0m | \u001b[0m0.6796   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.9341   \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "| \u001b[0m38       \u001b[0m | \u001b[0m-0.9705  \u001b[0m | \u001b[0m0.1205   \u001b[0m | \u001b[0m0.7298   \u001b[0m | \u001b[0m0.8485   \u001b[0m | \u001b[0m0.06534  \u001b[0m | \u001b[0m0.1857   \u001b[0m | \u001b[0m0.4238   \u001b[0m | \u001b[0m0.663    \u001b[0m | \u001b[0m0.5647   \u001b[0m | \u001b[0m0.5894   \u001b[0m | \u001b[0m0.2301   \u001b[0m | \u001b[0m0.2022   \u001b[0m | \u001b[0m0.7682   \u001b[0m | \u001b[0m0.2393   \u001b[0m | \u001b[0m0.3542   \u001b[0m | \u001b[0m0.818    \u001b[0m | \u001b[0m0.07562  \u001b[0m | \u001b[0m0.4218   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.6409   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.09091  \u001b[0m | \u001b[0m0.6063   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.2152   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.2392   \u001b[0m | \u001b[0m0.6178   \u001b[0m | \u001b[0m0.7189   \u001b[0m | \u001b[0m0.6638   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.7572   \u001b[0m | \u001b[0m0.9403   \u001b[0m |\n",
      "| \u001b[0m39       \u001b[0m | \u001b[0m-0.9119  \u001b[0m | \u001b[0m0.1547   \u001b[0m | \u001b[0m0.3546   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.6141   \u001b[0m | \u001b[0m0.5777   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.7816   \u001b[0m | \u001b[0m0.262    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.9948   \u001b[0m | \u001b[0m0.368    \u001b[0m | \u001b[0m0.94     \u001b[0m | \u001b[0m0.3109   \u001b[0m | \u001b[0m0.6264   \u001b[0m | \u001b[0m0.06544  \u001b[0m | \u001b[0m0.7554   \u001b[0m | \u001b[0m0.1209   \u001b[0m | \u001b[0m0.4757   \u001b[0m | \u001b[0m0.3235   \u001b[0m | \u001b[0m0.182    \u001b[0m | \u001b[0m0.2437   \u001b[0m | \u001b[0m0.8692   \u001b[0m | \u001b[0m0.9639   \u001b[0m | \u001b[0m0.3983   \u001b[0m | \u001b[0m0.7662   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.4957   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.4571   \u001b[0m | \u001b[0m0.9683   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.9888   \u001b[0m | \u001b[0m0.1864   \u001b[0m |\n",
      "| \u001b[0m40       \u001b[0m | \u001b[0m-0.8996  \u001b[0m | \u001b[0m0.4482   \u001b[0m | \u001b[0m0.9366   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.3298   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.04117  \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.3796   \u001b[0m | \u001b[0m0.3066   \u001b[0m | \u001b[0m0.8786   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.7681   \u001b[0m | \u001b[0m0.1429   \u001b[0m | \u001b[0m0.8349   \u001b[0m | \u001b[0m0.02769  \u001b[0m | \u001b[0m0.5982   \u001b[0m | \u001b[0m0.2125   \u001b[0m | \u001b[0m0.7131   \u001b[0m | \u001b[0m0.809    \u001b[0m | \u001b[0m0.8958   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.3254   \u001b[0m | \u001b[0m0.5235   \u001b[0m | \u001b[0m0.8783   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.5027   \u001b[0m | \u001b[0m0.7415   \u001b[0m | \u001b[0m0.967    \u001b[0m | \u001b[0m0.9014   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.5728   \u001b[0m |\n",
      "| \u001b[0m41       \u001b[0m | \u001b[0m-0.9611  \u001b[0m | \u001b[0m0.2285   \u001b[0m | \u001b[0m0.5776   \u001b[0m | \u001b[0m0.1748   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.2296   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.5757   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.07188  \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.6691   \u001b[0m | \u001b[0m0.69     \u001b[0m | \u001b[0m0.7704   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.5972   \u001b[0m | \u001b[0m0.7982   \u001b[0m | \u001b[0m0.5324   \u001b[0m | \u001b[0m0.7364   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.3479   \u001b[0m | \u001b[0m0.742    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.5643   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.6715   \u001b[0m | \u001b[0m0.666    \u001b[0m | \u001b[0m0.8273   \u001b[0m | \u001b[0m0.446    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.7355   \u001b[0m |\n",
      "| \u001b[0m42       \u001b[0m | \u001b[0m-0.9193  \u001b[0m | \u001b[0m0.3884   \u001b[0m | \u001b[0m0.5586   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.5048   \u001b[0m | \u001b[0m0.7062   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.9852   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.9967   \u001b[0m | \u001b[0m0.8376   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.6455   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.2305   \u001b[0m | \u001b[0m0.3025   \u001b[0m | \u001b[0m0.07057  \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.8953   \u001b[0m | \u001b[0m0.6997   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.4291   \u001b[0m | \u001b[0m0.4397   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.6589   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.1278   \u001b[0m | \u001b[0m0.9683   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.9158   \u001b[0m |\n",
      "| \u001b[0m43       \u001b[0m | \u001b[0m-0.9102  \u001b[0m | \u001b[0m0.5696   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.6524   \u001b[0m | \u001b[0m0.2533   \u001b[0m | \u001b[0m0.1333   \u001b[0m | \u001b[0m0.5823   \u001b[0m | \u001b[0m0.4721   \u001b[0m | \u001b[0m0.7976   \u001b[0m | \u001b[0m0.192    \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.07866  \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.1554   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.8265   \u001b[0m | \u001b[0m0.4915   \u001b[0m | \u001b[0m0.3551   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.7787   \u001b[0m | \u001b[0m0.424    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.5405   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.1299   \u001b[0m |\n",
      "| \u001b[0m44       \u001b[0m | \u001b[0m-0.9548  \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.09914  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.554    \u001b[0m | \u001b[0m0.9487   \u001b[0m | \u001b[0m0.7296   \u001b[0m | \u001b[0m0.8826   \u001b[0m | \u001b[0m0.6054   \u001b[0m | \u001b[0m0.2002   \u001b[0m | \u001b[0m0.3676   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.01695  \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.5228   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.5314   \u001b[0m | \u001b[0m0.8904   \u001b[0m | \u001b[0m0.5467   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.02362  \u001b[0m | \u001b[0m0.3426   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.8617   \u001b[0m | \u001b[0m0.6856   \u001b[0m | \u001b[0m0.1136   \u001b[0m | \u001b[0m0.9092   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.7256   \u001b[0m |\n",
      "| \u001b[0m45       \u001b[0m | \u001b[0m-0.9007  \u001b[0m | \u001b[0m0.2766   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.4903   \u001b[0m | \u001b[0m0.6836   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.41     \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.3566   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.158    \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.5797   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.5868   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.8656   \u001b[0m | \u001b[0m0.6151   \u001b[0m | \u001b[0m0.005729 \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.5656   \u001b[0m | \u001b[0m0.9771   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.9444   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.812    \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.984    \u001b[0m | \u001b[0m0.5857   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.215    \u001b[0m |\n",
      "| \u001b[0m46       \u001b[0m | \u001b[0m-0.9569  \u001b[0m | \u001b[0m0.7059   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.187    \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.6922   \u001b[0m | \u001b[0m0.6438   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.1737   \u001b[0m | \u001b[0m0.08998  \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.4467   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.4191   \u001b[0m | \u001b[0m0.6899   \u001b[0m | \u001b[0m0.3993   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.507    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.6252   \u001b[0m | \u001b[0m0.229    \u001b[0m | \u001b[0m0.3868   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.5061   \u001b[0m | \u001b[0m0.954    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.7645   \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[95m47       \u001b[0m | \u001b[95m-0.8866  \u001b[0m | \u001b[95m0.5628   \u001b[0m | \u001b[95m0.4644   \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.2325   \u001b[0m | \u001b[95m0.832    \u001b[0m | \u001b[95m0.007757 \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.1299   \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.2828   \u001b[0m | \u001b[95m0.6472   \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.6631   \u001b[0m | \u001b[95m0.2927   \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.6298   \u001b[0m | \u001b[95m0.2384   \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.5991   \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.3743   \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.2183   \u001b[0m |\n",
      "| \u001b[0m48       \u001b[0m | \u001b[0m-0.895   \u001b[0m | \u001b[0m0.1974   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.1994   \u001b[0m | \u001b[0m0.5828   \u001b[0m | \u001b[0m0.07128  \u001b[0m | \u001b[0m0.3313   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.4729   \u001b[0m | \u001b[0m0.8472   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.9511   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.9581   \u001b[0m | \u001b[0m0.1626   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.9044   \u001b[0m | \u001b[0m0.5931   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.7079   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.5544   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.3001   \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[0m49       \u001b[0m | \u001b[0m-0.9353  \u001b[0m | \u001b[0m0.7275   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.8684   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.6512   \u001b[0m | \u001b[0m0.1694   \u001b[0m | \u001b[0m0.9421   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.8994   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.6285   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.4844   \u001b[0m | \u001b[0m0.631    \u001b[0m | \u001b[0m0.1308   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.6399   \u001b[0m | \u001b[0m0.657    \u001b[0m | \u001b[0m0.1772   \u001b[0m | \u001b[0m0.6066   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.6971   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[95m50       \u001b[0m | \u001b[95m-0.8686  \u001b[0m | \u001b[95m0.3856   \u001b[0m | \u001b[95m0.3056   \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.4361   \u001b[0m | \u001b[95m0.4145   \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.7129   \u001b[0m | \u001b[95m0.7693   \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.7099   \u001b[0m | \u001b[95m0.5428   \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.4224   \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.08847  \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.937    \u001b[0m | \u001b[95m0.7886   \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.5851   \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.1316   \u001b[0m | \u001b[95m0.3728   \u001b[0m |\n",
      "| \u001b[0m51       \u001b[0m | \u001b[0m-0.8908  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.5529   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.4132   \u001b[0m | \u001b[0m0.5438   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.6624   \u001b[0m | \u001b[0m0.6773   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.9614   \u001b[0m | \u001b[0m0.2513   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.4104   \u001b[0m | \u001b[0m0.6426   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.8783   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.2704   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0624   \u001b[0m | \u001b[0m0.5761   \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[0m52       \u001b[0m | \u001b[0m-0.8718  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.5469   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.4126   \u001b[0m | \u001b[0m0.4621   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.9676   \u001b[0m | \u001b[0m0.9776   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.2661   \u001b[0m | \u001b[0m0.9354   \u001b[0m | \u001b[0m0.9935   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.6069   \u001b[0m | \u001b[0m0.5336   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.1131   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.8996   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.7525   \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[0m53       \u001b[0m | \u001b[0m-0.8883  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.5987   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.4902   \u001b[0m | \u001b[0m0.9171   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.9484   \u001b[0m | \u001b[0m0.3959   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.9419   \u001b[0m | \u001b[0m0.8472   \u001b[0m | \u001b[0m0.1417   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.5254   \u001b[0m | \u001b[0m0.1407   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.5778   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.9946   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.8235   \u001b[0m | \u001b[0m0.6601   \u001b[0m | \u001b[0m0.7129   \u001b[0m |\n",
      "| \u001b[0m54       \u001b[0m | \u001b[0m-0.8912  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.05775  \u001b[0m | \u001b[0m0.7091   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.6693   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.6973   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.4232   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.8168   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.5075   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.7422   \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[0m55       \u001b[0m | \u001b[0m-0.9165  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.7752   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.3536   \u001b[0m | \u001b[0m0.6651   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.8845   \u001b[0m | \u001b[0m0.9784   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.9575   \u001b[0m | \u001b[0m0.3539   \u001b[0m | \u001b[0m0.7947   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.288    \u001b[0m | \u001b[0m0.7274   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.00738  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.6299   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.8834   \u001b[0m | \u001b[0m0.3875   \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[0m56       \u001b[0m | \u001b[0m-0.8906  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.277    \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.2786   \u001b[0m | \u001b[0m0.2645   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.1701   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.6368   \u001b[0m | \u001b[0m0.9404   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.9163   \u001b[0m | \u001b[0m0.6449   \u001b[0m | \u001b[0m0.5211   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.496    \u001b[0m | \u001b[0m0.8271   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.6792   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.1145   \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[0m57       \u001b[0m | \u001b[0m-0.9416  \u001b[0m | \u001b[0m0.3072   \u001b[0m | \u001b[0m0.0235   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.09812  \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.8294   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.9554   \u001b[0m | \u001b[0m0.7349   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.5858   \u001b[0m | \u001b[0m0.3372   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.9093   \u001b[0m | \u001b[0m0.2795   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.9517   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.4789   \u001b[0m | \u001b[0m0.0      \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m58       \u001b[0m | \u001b[0m-0.8991  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.3776   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.9794   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.8996   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.8496   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.03365  \u001b[0m | \u001b[0m0.3205   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.5341   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.7811   \u001b[0m | \u001b[0m0.9063   \u001b[0m | \u001b[0m0.4393   \u001b[0m |\n",
      "| \u001b[0m59       \u001b[0m | \u001b[0m-0.9042  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.926    \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.7368   \u001b[0m | \u001b[0m0.2463   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.8135   \u001b[0m | \u001b[0m0.8108   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.6502   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.7004   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.3653   \u001b[0m | \u001b[0m0.6162   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.9429   \u001b[0m | \u001b[0m0.5403   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.2344   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.004167 \u001b[0m | \u001b[0m0.3626   \u001b[0m |\n",
      "| \u001b[0m60       \u001b[0m | \u001b[0m-0.9787  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.9989   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.6175   \u001b[0m | \u001b[0m0.8583   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.7364   \u001b[0m | \u001b[0m0.9265   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.7511   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.7589   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.06765  \u001b[0m | \u001b[0m0.5689   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.5185   \u001b[0m | \u001b[0m0.8057   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.5532   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.951    \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[0m61       \u001b[0m | \u001b[0m-0.884   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.5471   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.3717   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.4024   \u001b[0m | \u001b[0m0.9267   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.8135   \u001b[0m | \u001b[0m0.614    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.8305   \u001b[0m | \u001b[0m0.1338   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.9057   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.7032   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.6558   \u001b[0m | \u001b[0m0.1292   \u001b[0m | \u001b[0m0.8827   \u001b[0m |\n",
      "| \u001b[0m62       \u001b[0m | \u001b[0m-0.9256  \u001b[0m | \u001b[0m0.4806   \u001b[0m | \u001b[0m0.4513   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.7014   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.8464   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.905    \u001b[0m | \u001b[0m0.6509   \u001b[0m | \u001b[0m0.5161   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.8125   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.3854   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.7343   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.7878   \u001b[0m | \u001b[0m0.3174   \u001b[0m | \u001b[0m0.1046   \u001b[0m |\n",
      "| \u001b[0m63       \u001b[0m | \u001b[0m-0.9077  \u001b[0m | \u001b[0m0.3346   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.8957   \u001b[0m | \u001b[0m0.3041   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.9048   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.9547   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.006832 \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.7998   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.3063   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.3748   \u001b[0m | \u001b[0m0.6286   \u001b[0m |\n",
      "| \u001b[95m64       \u001b[0m | \u001b[95m-0.8408  \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.8475   \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.2897   \u001b[0m | \u001b[95m0.1706   \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.2561   \u001b[0m | \u001b[95m0.7973   \u001b[0m | \u001b[95m0.9761   \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.6587   \u001b[0m | \u001b[95m0.01421  \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.505    \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.9601   \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.08328  \u001b[0m | \u001b[95m0.0      \u001b[0m |\n",
      "| \u001b[95m65       \u001b[0m | \u001b[95m-0.8405  \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.5626   \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.06252  \u001b[0m | \u001b[95m0.4409   \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.09512  \u001b[0m | \u001b[95m0.472    \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.8271   \u001b[0m | \u001b[95m0.9798   \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.4328   \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.4322   \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.6858   \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.669    \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m |\n",
      "| \u001b[0m66       \u001b[0m | \u001b[0m-0.8787  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.7473   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.1837   \u001b[0m | \u001b[0m0.1414   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.1752   \u001b[0m | \u001b[0m0.3214   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.9286   \u001b[0m | \u001b[0m0.7263   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.6142   \u001b[0m | \u001b[0m0.3918   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.7582   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.4259   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.1276   \u001b[0m |\n",
      "| \u001b[0m67       \u001b[0m | \u001b[0m-0.8711  \u001b[0m | \u001b[0m0.9255   \u001b[0m | \u001b[0m0.9879   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.3393   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.6442   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.2799   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.7825   \u001b[0m | \u001b[0m0.2001   \u001b[0m | \u001b[0m0.1134   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.3793   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.2548   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[0m68       \u001b[0m | \u001b[0m-0.8926  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.5263   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.1359   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.7241   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.127    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.128    \u001b[0m | \u001b[0m0.2262   \u001b[0m | \u001b[0m0.4268   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.2408   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.6055   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m69       \u001b[0m | \u001b[0m-0.8863  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.352    \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.3405   \u001b[0m | \u001b[0m0.316    \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.578    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.4061   \u001b[0m | \u001b[0m0.8825   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.9705   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.4181   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.1025   \u001b[0m |\n",
      "| \u001b[0m70       \u001b[0m | \u001b[0m-0.8675  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.2818   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.5723   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.9654   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.3502   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.6754   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.04611  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.3438   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.4056   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[0m71       \u001b[0m | \u001b[0m-0.8657  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.4101   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.03338  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.5668   \u001b[0m | \u001b[0m0.13     \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.4635   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.7603   \u001b[0m | \u001b[0m0.03219  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.5526   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.6067   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.5526   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[0m72       \u001b[0m | \u001b[0m-0.9567  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.7274   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.9906   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.2509   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.1974   \u001b[0m | \u001b[0m0.4809   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.7124   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.7991   \u001b[0m | \u001b[0m0.4074   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.5349   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.1234   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.7061   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.9422   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[0m73       \u001b[0m | \u001b[0m-0.9122  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.274    \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.4105   \u001b[0m | \u001b[0m0.8054   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.04055  \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.494    \u001b[0m | \u001b[0m0.1847   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.5598   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.3698   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.9443   \u001b[0m |\n",
      "| \u001b[0m74       \u001b[0m | \u001b[0m-0.8919  \u001b[0m | \u001b[0m0.4646   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.6747   \u001b[0m | \u001b[0m0.2744   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.1886   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.01938  \u001b[0m | \u001b[0m0.8757   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.2824   \u001b[0m | \u001b[0m0.7595   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[95m75       \u001b[0m | \u001b[95m-0.829   \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.7926   \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.4352   \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.4933   \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.4994   \u001b[0m | \u001b[95m0.0793   \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.6869   \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.4165   \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m |\n",
      "| \u001b[0m76       \u001b[0m | \u001b[0m-0.8362  \u001b[0m | \u001b[0m0.8431   \u001b[0m | \u001b[0m0.2993   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.87     \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0907   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.3189   \u001b[0m | \u001b[0m0.2016   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.4572   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[0m77       \u001b[0m | \u001b[0m-0.8414  \u001b[0m | \u001b[0m0.3597   \u001b[0m | \u001b[0m0.6386   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.473    \u001b[0m | \u001b[0m0.7321   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.5321   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.3921   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.4826   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[0m78       \u001b[0m | \u001b[0m-0.8773  \u001b[0m | \u001b[0m0.2489   \u001b[0m | \u001b[0m0.7311   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.6934   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.7221   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.5958   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.3585   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.7001   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.06146  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "| \u001b[0m79       \u001b[0m | \u001b[0m-0.8446  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.9352   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.8513   \u001b[0m | \u001b[0m0.3684   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.3669   \u001b[0m | \u001b[0m0.07278  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.8976   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.06126  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.571    \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m80       \u001b[0m | \u001b[0m-0.8645  \u001b[0m | \u001b[0m0.186    \u001b[0m | \u001b[0m0.5251   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.3574   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.8785   \u001b[0m | \u001b[0m0.3421   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.1545   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.3051   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
      "=============================================================================================================================================================================================================================================================================================================================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "def objective_function(onpromotion, total_other_promo_store, total_other_city_promo, holiday,\n",
    "                       holiday_description, event, time_since_quake, time_since_quake_sq, state, city, \n",
    "                       dcoilwtico, day, month, workday, payday, onpromotion_lag_1, type, dayofyear, year,\n",
    "                       onpromotion_lag_2, onpromotion_lag_3, onpromotion_lag_4, onpromotion_lag_5,\n",
    "                       onpromotion_lag_6, onpromotion_lag_7, dcoilwtico_lag_1, dcoilwtico_lag_2, \n",
    "                       dcoilwtico_lag_3, dcoilwtico_lag_4, dcoilwtico_lag_5, dcoilwtico_lag_6, \n",
    "                       dcoilwtico_lag_7, sales_one_year_lag, Change_in_oil_prices, promo_last_7_days, X_C=X_C, y=y):\n",
    "    \n",
    "    # Convert non-integer arguments to integers\n",
    "    # Convert non-integer arguments to integers\n",
    "    variable_list = [int(round(Change_in_oil_prices)), int(round(city)),int(round(day)), int(round(dayofyear)), int(round(dcoilwtico)),\n",
    "                        int(round(dcoilwtico_lag_1)), int(round(dcoilwtico_lag_2)), int(round(dcoilwtico_lag_3)), int(round(dcoilwtico_lag_4)),\n",
    "                        int(round(dcoilwtico_lag_5)), int(round(dcoilwtico_lag_6)), int(round(dcoilwtico_lag_7)), int(round(event)),\n",
    "                        int(round(holiday)), int(round(holiday_description)), int(round(month)), int(round(onpromotion)),int(round(onpromotion_lag_1)),\n",
    "                        int(round(onpromotion_lag_2)), int(round(onpromotion_lag_3)), int(round(onpromotion_lag_4)), int(round(onpromotion_lag_5)),\n",
    "                        int(round(onpromotion_lag_6)), int(round(onpromotion_lag_7)), int(round(payday)), int(round(promo_last_7_days)),\n",
    "                        int(round(sales_one_year_lag)), int(round(state)), int(round(time_since_quake)), int(round(time_since_quake_sq)),\n",
    "                        int(round(total_other_city_promo)), int(round(total_other_promo_store)), int(round(type)), int(round(workday)), int(round(year))]\n",
    "    X_C = X_C.copy()\n",
    "    column_to_remove = []\n",
    "    for i in range(3, X_C.shape[1]):\n",
    "        if variable_list[i-3]==0:\n",
    "            column_to_remove.append(X_C.columns[i])\n",
    "    \n",
    "    X_C.drop(column_to_remove, axis=1, inplace=True)\n",
    "            \n",
    "    xgb_params = {\n",
    "        'tree_method': 'gpu_hist',  # Specify GPU usage\n",
    "        'predictor': 'gpu_predictor',\n",
    "        'enable_categorical': True,}\n",
    "\n",
    "    model_2 = XGBRegressor(**xgb_params)\n",
    "\n",
    "    model_1 = LinearRegression(fit_intercept=False, algorithm=\"svd\", copy_X=True)\n",
    "    # Use time series split for cross validation. \n",
    "    cv_split = TimeSeriesSplit(n_splits = 4)\n",
    "    \n",
    "    # Create lists to append MSLE scores.\n",
    "    valid_msle = []\n",
    "    \n",
    "    # Dates to index through. \n",
    "    dates = X_C.index.drop_duplicates()\n",
    "    \n",
    "    \n",
    "    list1 = [\"time_since_quake\", \"time_since_quake_sq\"]\n",
    "    list2 = X_C.columns\n",
    "\n",
    "    # Convert lists to sets\n",
    "    set1 = set(list1)\n",
    "    set2 = set(list2)\n",
    "\n",
    "    # Find the values in set1 that are not in set2\n",
    "    uncommon_values = set1 - set2\n",
    "\n",
    "    # Remove the uncommon values from list1\n",
    "    list1 = [value for value in list1 if value not in uncommon_values]\n",
    "    \n",
    "    numeric_transformer = [\"float\", StandardScaler()]\n",
    "    data_preprocessor = Prepare_data(list1, [numeric_transformer])\n",
    "    \n",
    "    # Perform Cross-Validation to determine how model will do on unseen data.\n",
    "    for train_index, valid_index in cv_split.split(dates):\n",
    "\n",
    "        model = Hybrid_Pipeline(data_preprocessor, model_1, model_2, Boosted=False, to_tensor=False)\n",
    "\n",
    "        # Index dates.\n",
    "        date_train, date_valid = dates[train_index], dates[valid_index]\n",
    "\n",
    "        # Selecting data for y_train and y_valid.\n",
    "        y_train = y.loc[date_train]\n",
    "        y_valid = y.loc[date_valid]\n",
    "\n",
    "        # Selecting data for X_train and X_valid.\n",
    "        X_train = X_C.loc[date_train]\n",
    "        X_valid = X_C.loc[date_valid]\n",
    "\n",
    "        X_train = X_train.reset_index().sort_values([\"store_nbr\", \"family\", \"date\"])\n",
    "        X_valid = X_valid.reset_index().sort_values([\"store_nbr\", \"family\", \"date\"])\n",
    "        X_train = X_train.set_index([\"date\"])\n",
    "        X_valid = X_valid.set_index([\"date\"])\n",
    "\n",
    "        y_train = y_train.reset_index().sort_values([\"store_nbr\", \"family\", \"date\"])\n",
    "        y_valid = y_valid.reset_index().sort_values([\"store_nbr\", \"family\", \"date\"])\n",
    "        y_train = y_train.set_index([\"date\"])\n",
    "        y_valid = y_valid.set_index([\"date\"])\n",
    "\n",
    "\n",
    "        # Fitting model.\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Create predictions for Trainning and Validation.\n",
    "        pred = model.predict(X_valid)\n",
    "\n",
    "        # MSE for trainning and validation. \n",
    "        valid_msle.append(float(mean_squared_log_error(y_valid[\"sales\"], pred[\"sales\"])))\n",
    "\n",
    "\n",
    "    return -float(np.sqrt(np.mean(valid_msle)))\n",
    "\n",
    "# Define the parameter space for Bayesian optimization (each feature is a parameter)\n",
    "params = {X_C.columns[i]: (0, 1) for i in range(3, X_C.shape[1])}\n",
    "\n",
    "# Initialize the Bayesian optimizer\n",
    "optimizer = BayesianOptimization(\n",
    "    f=objective_function,\n",
    "    pbounds=params,\n",
    "    random_state=1,  # For reproducibility\n",
    ")\n",
    "\n",
    "# Perform the optimization\n",
    "optimizer.maximize(init_points=30, n_iter=50)\n",
    "\n",
    "variables = list(optimizer.max[\"params\"].values())\n",
    "variables = [True, True, True] + [x>0.5 for x in variables]\n",
    "X_C = X_C[X_C.columns[variables]]\n",
    "\n",
    "list1 = [\"time_since_quake\", \"time_since_quake_sq\"]\n",
    "list2 = X_C.columns\n",
    "\n",
    "# Convert lists to sets\n",
    "set1 = set(list1)\n",
    "set2 = set(list2)\n",
    "\n",
    "# Find the values in set1 that are not in set2\n",
    "uncommon_values = set1 - set2\n",
    "\n",
    "# Remove the uncommon values from list1\n",
    "list1 = [value for value in list1 if value not in uncommon_values]\n",
    "\n",
    "numeric_transformer = [\"float\", StandardScaler()]\n",
    "data_preprocessor = Prepare_data(list1, [numeric_transformer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c511603c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_optimization(n_estimators, gamma, subsample, max_depth, learning_rate):\n",
    "    \n",
    "    \n",
    "    model_1 = LinearRegression(fit_intercept=False, algorithm=\"svd\", copy_X=True)\n",
    "    \n",
    "    \n",
    "    n_estimators = int(n_estimators)\n",
    "    max_depth = int(max_depth)\n",
    "    \n",
    "    params = {\n",
    "    'tree_method': 'gpu_hist',  # Specify GPU usage\n",
    "    'predictor': 'gpu_predictor',\n",
    "    'enable_categorical': True,\n",
    "    'max_depth': max_depth,\n",
    "    'learning_rate': learning_rate,\n",
    "    'n_estimators': n_estimators,\n",
    "    'gamma': gamma,\n",
    "    'subsample': subsample}\n",
    "\n",
    "    model_2 = XGBRegressor(**params)\n",
    "    # Use time series split for cross validation. \n",
    "    cv_split = TimeSeriesSplit(n_splits = 4)\n",
    "    \n",
    "    # Create lists to append MSLE scores.\n",
    "    valid_msle = []\n",
    "\n",
    "    # Dates to index through. \n",
    "    dates = X_C.index.drop_duplicates()\n",
    "\n",
    "    \n",
    "    # Perform Cross-Validation to determine how model will do on unseen data.\n",
    "    for train_index, valid_index in cv_split.split(dates):\n",
    "\n",
    "        model = Hybrid_Pipeline(data_preprocessor, model_1, model_2, Boosted=False, to_tensor=False)\n",
    "\n",
    "        # Index dates.\n",
    "        date_train, date_valid = dates[train_index], dates[valid_index]\n",
    "\n",
    "        # Selecting data for y_train and y_valid.\n",
    "        y_train = y.loc[date_train]\n",
    "        y_valid = y.loc[date_valid]\n",
    "\n",
    "        # Selecting data for X_train and X_valid.\n",
    "        X_train = X_C.loc[date_train]\n",
    "        X_valid = X_C.loc[date_valid]\n",
    "\n",
    "        X_train = X_train.reset_index().sort_values([\"store_nbr\", \"family\", \"date\"])\n",
    "        X_valid = X_valid.reset_index().sort_values([\"store_nbr\", \"family\", \"date\"])\n",
    "        X_train = X_train.set_index([\"date\"])\n",
    "        X_valid = X_valid.set_index([\"date\"])\n",
    "\n",
    "        y_train = y_train.reset_index().sort_values([\"store_nbr\", \"family\", \"date\"])\n",
    "        y_valid = y_valid.reset_index().sort_values([\"store_nbr\", \"family\", \"date\"])\n",
    "        y_train = y_train.set_index([\"date\"])\n",
    "        y_valid = y_valid.set_index([\"date\"])\n",
    "\n",
    "\n",
    "        # Fitting model.\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Create predictions for Trainning and Validation.\n",
    "        pred = model.predict(X_valid)\n",
    "\n",
    "        # MSE for trainning and validation. \n",
    "        valid_msle.append(float(mean_squared_log_error(y_valid[\"sales\"], pred[\"sales\"])))\n",
    "\n",
    "\n",
    "    return -float(np.sqrt(np.mean(valid_msle)))\n",
    "\n",
    "parambounds = {\n",
    "    'learning_rate': (0.00001, 1),\n",
    "    'n_estimators': (0, 500),\n",
    "    'max_depth': (3,12),\n",
    "    'subsample': (0.0001, 1.0),  \n",
    "    'gamma': (3, 8),\n",
    "    \n",
    "}\n",
    "\n",
    "optimizer = BayesianOptimization(\n",
    "    f=hyperparameter_optimization,\n",
    "    pbounds=parambounds,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "optimizer.maximize(init_points=30, n_iter=100,)\n",
    "print(optimizer.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "11d5a122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "Training RMSLE: 0.647, Validation RMSLE: 0.614\n",
      "Fold 2:\n",
      "Training RMSLE: 0.619, Validation RMSLE: 0.771\n",
      "Fold 3:\n",
      "Training RMSLE: 0.628, Validation RMSLE: 0.679\n",
      "Fold 4:\n",
      "Training RMSLE: 0.640, Validation RMSLE: 0.596\n",
      "Average Across Folds\n",
      "Training RMSLE:0.633, Validation RMSLE: 0.669\n"
     ]
    }
   ],
   "source": [
    "params = optimizer.max[\"params\"]\n",
    "\n",
    "xgb_params = {\n",
    "    'tree_method': 'gpu_hist',  # Specify GPU usage\n",
    "    'predictor': 'gpu_predictor',\n",
    "    'enable_categorical': True,\n",
    "    'max_depth': int(params[\"max_depth\"]),\n",
    "    'learning_rate': params[\"learning_rate\"],\n",
    "    'n_estimators': int(params[\"n_estimators\"]),\n",
    "    'gamma': params[\"gamma\"],\n",
    "    'subsample': params[\"subsample\"]\n",
    "}\n",
    "\n",
    "xgb = XGBRegressor(**xgb_params)\n",
    "\n",
    "\n",
    "model_1 = LinearRegression(fit_intercept=False, algorithm=\"svd\", copy_X=True)\n",
    "\n",
    "# Use time series split for cross validation. \n",
    "cv_split = TimeSeriesSplit(n_splits = 4)\n",
    "\n",
    "# Create lists to append MSE scores. \n",
    "train_msle = []\n",
    "valid_msle = []\n",
    "\n",
    "# Dates to index through. \n",
    "dates = X_C.index.drop_duplicates()\n",
    "a = 0\n",
    "# Perform Cross-Validation to determine how model will do on unseen data.\n",
    "for train_index, valid_index in cv_split.split(dates):\n",
    "    a = a+1\n",
    "    print(f\"Fold {a}:\") \n",
    "    model = Hybrid_Pipeline(data_preprocessor, lr, xgb, Boosted=False, to_tensor=False)\n",
    "    \n",
    "    # Index dates.\n",
    "    date_train, date_valid = dates[train_index], dates[valid_index]\n",
    "\n",
    "    # Selecting data for y_train and y_valid.\n",
    "    y_train = y.loc[date_train]\n",
    "    y_valid = y.loc[date_valid]\n",
    "    \n",
    "    # Selecting data for X_train and X_valid.\n",
    "    X_train = X_C.loc[date_train]\n",
    "    X_valid = X_C.loc[date_valid]\n",
    "    \n",
    "    X_train = X_train.reset_index().sort_values([\"store_nbr\", \"family\", \"date\"])\n",
    "    X_valid = X_valid.reset_index().sort_values([\"store_nbr\", \"family\", \"date\"])\n",
    "    X_train = X_train.set_index([\"date\"])\n",
    "    X_valid = X_valid.set_index([\"date\"])\n",
    "\n",
    "    y_train = y_train.reset_index().sort_values([\"store_nbr\", \"family\", \"date\"])\n",
    "    y_valid = y_valid.reset_index().sort_values([\"store_nbr\", \"family\", \"date\"])\n",
    "    y_train = y_train.set_index([\"date\"])\n",
    "    y_valid = y_valid.set_index([\"date\"])\n",
    "\n",
    "\n",
    "    # Fitting model.\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Create predictions for Trainning and Validation.\n",
    "    fit = model.predict(X_train)\n",
    "    pred = model.predict(X_valid)\n",
    "    \n",
    "    # MSE for trainning and validation. \n",
    "    train_msle.append(float(mean_squared_log_error(y_train[\"sales\"], fit[\"sales\"])))\n",
    "    valid_msle.append(float(mean_squared_log_error(y_valid[\"sales\"], pred[\"sales\"])))\n",
    "    \n",
    "    print(f\"Training RMSLE: {cp.sqrt(mean_squared_log_error(y_train.sales, fit.sales)):.3f}, Validation RMSLE: {cp.sqrt(mean_squared_log_error(y_valid.sales, pred.sales)):.3f}\")\n",
    "\n",
    "# Returns the square root of the average of the MSE.\n",
    "print(\"Average Across Folds\")\n",
    "print(f\"Training RMSLE:{np.sqrt(np.mean(train_msle)):.3f}, Validation RMSLE: {np.sqrt(np.mean(valid_msle)):.3f}\")\n",
    "\n",
    "e_2 = 1/np.sqrt(np.mean(valid_msle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "96937b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Model\n",
    "model = Hybrid_Pipeline(data_preprocessor, lr, xgb, Boosted=True, to_tensor=False)\n",
    "model.fit(X_C, y)\n",
    "\n",
    "X_test_C = X_test_C[X_test_C.columns[variables]]\n",
    "pred_2 = model.predict(X_test_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314a8cd0",
   "metadata": {},
   "source": [
    "## Linear Regression, Random Forest Regressor, Boosted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ee5f3e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_C = X.copy()\n",
    "\n",
    "X_C[\"family\"] = X_C[\"family\"].cat.codes\n",
    "X_C[\"store_nbr\"] = X_C[\"store_nbr\"].cat.codes\n",
    "#X_C[\"holiday\"] = X_C[\"holiday\"].cat.codes\n",
    "X_C[\"event\"] = X[\"event\"].cat.codes\n",
    "X_C[\"city\"] = X_C[\"city\"].cat.codes\n",
    "X_C[\"state\"] = X_C[\"state\"].cat.codes\n",
    "X_C[\"type\"] = X_C[\"type\"].cat.codes\n",
    "\n",
    "X_C = X_C[[\"id\", \"store_nbr\", \"family\"] + sorted(set(X_C.columns)-set([\"id\", \"store_nbr\", \"family\"]))]\n",
    "\n",
    "X_C = X_C.reset_index().sort_values([\"store_nbr\", \"family\", \"date\"]).set_index([\"date\"])\n",
    "y = y.reset_index().sort_values([\"store_nbr\", \"family\", \"date\"]).set_index([\"date\"])\n",
    "\n",
    "X_test_C = X_test.copy()\n",
    "X_test_C = X_test_C[[\"id\", \"store_nbr\", \"family\"] + sorted(set(X_test_C.columns)-set([\"id\", \"store_nbr\", \"family\"]))]\n",
    "X_test_C = X_test_C.reset_index().sort_values([\"store_nbr\", \"family\", \"date\"])\n",
    "X_test_C = X_test_C.set_index([\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1e4d042d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | Change... |   city    |    day    | dayofyear | dcoilw... | dcoilw... | dcoilw... | dcoilw... | dcoilw... | dcoilw... | dcoilw... | dcoilw... |   event   |  holiday  | holida... |   month   | onprom... | onprom... | onprom... | onprom... | onprom... | onprom... | onprom... | onprom... |  payday   | promo_... | sales_... |   state   | time_s... | time_s... | total_... | total_... |   type    |  workday  |   year    |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "<class 'numpy.object_'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[96], line 108\u001b[0m\n\u001b[1;32m    101\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m BayesianOptimization(\n\u001b[1;32m    102\u001b[0m     f\u001b[38;5;241m=\u001b[39mobjective_function,\n\u001b[1;32m    103\u001b[0m     pbounds\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    104\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,  \u001b[38;5;66;03m# For reproducibility\u001b[39;00m\n\u001b[1;32m    105\u001b[0m )\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# Perform the optimization\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(optimizer\u001b[38;5;241m.\u001b[39mmax[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[1;32m    111\u001b[0m variables \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m] \u001b[38;5;241m+\u001b[39m [x\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m variables]\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-23.12/lib/python3.10/site-packages/bayes_opt/bayesian_optimization.py:310\u001b[0m, in \u001b[0;36mBayesianOptimization.maximize\u001b[0;34m(self, init_points, n_iter, acquisition_function, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[1;32m    308\u001b[0m     x_probe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuggest(util)\n\u001b[1;32m    309\u001b[0m     iteration \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_probe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlazy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bounds_transformer \u001b[38;5;129;01mand\u001b[39;00m iteration \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;66;03m# The bounds transformer should only modify the bounds after\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;66;03m# the init_points points (only for the true iterations)\u001b[39;00m\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_bounds(\n\u001b[1;32m    316\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bounds_transformer\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space))\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-23.12/lib/python3.10/site-packages/bayes_opt/bayesian_optimization.py:208\u001b[0m, in \u001b[0;36mBayesianOptimization.probe\u001b[0;34m(self, params, lazy)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_queue\u001b[38;5;241m.\u001b[39madd(params)\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 208\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_space\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch(Events\u001b[38;5;241m.\u001b[39mOPTIMIZATION_STEP)\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-23.12/lib/python3.10/site-packages/bayes_opt/target_space.py:236\u001b[0m, in \u001b[0;36mTargetSpace.probe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    234\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_as_array(params)\n\u001b[1;32m    235\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_keys, x))\n\u001b[0;32m--> 236\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constraint \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister(x, target)\n",
      "Cell \u001b[0;32mIn[96], line 86\u001b[0m, in \u001b[0;36mobjective_function\u001b[0;34m(onpromotion, total_other_promo_store, total_other_city_promo, holiday, holiday_description, event, time_since_quake, time_since_quake_sq, state, city, dcoilwtico, day, month, workday, payday, onpromotion_lag_1, type, dayofyear, year, onpromotion_lag_2, onpromotion_lag_3, onpromotion_lag_4, onpromotion_lag_5, onpromotion_lag_6, onpromotion_lag_7, dcoilwtico_lag_1, dcoilwtico_lag_2, dcoilwtico_lag_3, dcoilwtico_lag_4, dcoilwtico_lag_5, dcoilwtico_lag_6, dcoilwtico_lag_7, sales_one_year_lag, Change_in_oil_prices, promo_last_7_days, X_C, y)\u001b[0m\n\u001b[1;32m     82\u001b[0m y_valid \u001b[38;5;241m=\u001b[39m y_valid\u001b[38;5;241m.\u001b[39mset_index([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# Fitting model.\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Create predictions for Trainning and Validation.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_valid)\n",
      "File \u001b[0;32m/mnt/c/Users/Jon Scheaffer/GitHub/Machine-Learning-for-Store-Sales-Forecasting-Kaggle-Competition/jons_time_series_functions.py:467\u001b[0m, in \u001b[0;36mHybrid_Pipeline.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    465\u001b[0m X_1, X_2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess\u001b[38;5;241m.\u001b[39mfit_transform(X_C)\n\u001b[1;32m    466\u001b[0m \u001b[38;5;66;03m# Fit hybrid models\u001b[39;00m\n\u001b[0;32m--> 467\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/c/Users/Jon Scheaffer/GitHub/Machine-Learning-for-Store-Sales-Forecasting-Kaggle-Competition/jons_time_series_functions.py:339\u001b[0m, in \u001b[0;36mHybrid_Time_Series_ML.fit\u001b[0;34m(self, X_1, X_2, y)\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_2\u001b[38;5;241m.\u001b[39mfit(X_2, y_t)\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 339\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_resid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msales\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    344\u001b[0m     y_fit \u001b[38;5;241m=\u001b[39m y_fit\u001b[38;5;241m.\u001b[39mstack([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore_nbr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfamily\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mreset_index()\u001b[38;5;241m.\u001b[39msort_values([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore_nbr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfamily\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-23.12/lib/python3.10/site-packages/nvtx/nvtx.py:115\u001b[0m, in \u001b[0;36mannotate.__call__.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     libnvtx_push_range(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattributes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdomain\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[0;32m--> 115\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m     libnvtx_pop_range(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdomain\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-23.12/lib/python3.10/site-packages/cuml/internals/api_decorators.py:188\u001b[0m, in \u001b[0;36m_make_decorator_function.<locals>.decorator_function.<locals>.decorator_closure.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m     set_api_output_dtype(output_dtype)\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m process_return:\n\u001b[0;32m--> 188\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32mrandomforestregressor.pyx:416\u001b[0m, in \u001b[0;36mcuml.ensemble.randomforestregressor.RandomForestRegressor.fit\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-23.12/lib/python3.10/site-packages/cuml/internals/api_decorators.py:188\u001b[0m, in \u001b[0;36m_make_decorator_function.<locals>.decorator_function.<locals>.decorator_closure.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m     set_api_output_dtype(output_dtype)\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m process_return:\n\u001b[0;32m--> 188\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32mrandomforest_common.pyx:267\u001b[0m, in \u001b[0;36mcuml.ensemble.randomforest_common.BaseRandomForestModel._dataset_setup_for_fit\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-23.12/lib/python3.10/site-packages/nvtx/nvtx.py:115\u001b[0m, in \u001b[0;36mannotate.__call__.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     libnvtx_push_range(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattributes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdomain\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[0;32m--> 115\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m     libnvtx_pop_range(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdomain\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-23.12/lib/python3.10/site-packages/cuml/internals/input_utils.py:380\u001b[0m, in \u001b[0;36minput_to_cuml_array\u001b[0;34m(X, order, deepcopy, check_dtype, convert_to_dtype, check_mem_type, convert_to_mem_type, safe_dtype_conversion, check_cols, check_rows, fail_on_order, force_contiguous)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;129m@nvtx_annotate\u001b[39m(\n\u001b[1;32m    293\u001b[0m     message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcommon.input_utils.input_to_cuml_array\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    294\u001b[0m     category\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutils\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    309\u001b[0m     force_contiguous\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    310\u001b[0m ):\n\u001b[1;32m    311\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;124;03m    Convert input X to CumlArray.\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    378\u001b[0m \n\u001b[1;32m    379\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 380\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43mCumlArray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_input\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeepcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeepcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_to_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_to_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_mem_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_mem_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_to_mem_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_to_mem_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m        \u001b[49m\u001b[43msafe_dtype_conversion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe_dtype_conversion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_rows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfail_on_order\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfail_on_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_contiguous\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_contiguous\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    395\u001b[0m         shape \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39m__cuda_array_interface__[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-23.12/lib/python3.10/site-packages/cuml/internals/memory_utils.py:87\u001b[0m, in \u001b[0;36mwith_cupy_rmm.<locals>.cupy_rmm_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m GPU_ENABLED:\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m cupy_using_allocator(rmm_cupy_allocator):\n\u001b[0;32m---> 87\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-23.12/lib/python3.10/site-packages/nvtx/nvtx.py:115\u001b[0m, in \u001b[0;36mannotate.__call__.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     libnvtx_push_range(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattributes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdomain\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[0;32m--> 115\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m     libnvtx_pop_range(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdomain\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-23.12/lib/python3.10/site-packages/cuml/internals/array.py:1104\u001b[0m, in \u001b[0;36mCumlArray.from_input\u001b[0;34m(cls, X, order, deepcopy, check_dtype, convert_to_dtype, check_mem_type, convert_to_mem_type, safe_dtype_conversion, check_cols, check_rows, fail_on_order, force_contiguous)\u001b[0m\n\u001b[1;32m   1098\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1099\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: cuDF Series has missing/null values, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1100\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhich are not supported by cuML.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1101\u001b[0m         )\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, CudfDataFrame):\n\u001b[0;32m-> 1104\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_cupy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1105\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, (PandasDataFrame, PandasSeries)):\n\u001b[1;32m   1106\u001b[0m     X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto_numpy(copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-23.12/lib/python3.10/site-packages/nvtx/nvtx.py:115\u001b[0m, in \u001b[0;36mannotate.__call__.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     libnvtx_push_range(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattributes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdomain\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[0;32m--> 115\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m     libnvtx_pop_range(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdomain\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-23.12/lib/python3.10/site-packages/cudf/core/frame.py:497\u001b[0m, in \u001b[0;36mFrame.to_cupy\u001b[0;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;129m@_cudf_nvtx_annotate\u001b[39m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_cupy\u001b[39m(\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    476\u001b[0m     na_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    477\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m cupy\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m    478\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convert the Frame to a CuPy array.\u001b[39;00m\n\u001b[1;32m    479\u001b[0m \n\u001b[1;32m    480\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;124;03m    cupy.ndarray\u001b[39;00m\n\u001b[1;32m    496\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 497\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_to_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcupy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-23.12/lib/python3.10/site-packages/nvtx/nvtx.py:115\u001b[0m, in \u001b[0;36mannotate.__call__.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     libnvtx_push_range(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattributes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdomain\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[0;32m--> 115\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m     libnvtx_pop_range(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdomain\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-23.12/lib/python3.10/site-packages/cudf/core/frame.py:462\u001b[0m, in \u001b[0;36mFrame._to_array\u001b[0;34m(self, get_column_values, make_empty_matrix, dtype, na_value)\u001b[0m\n\u001b[1;32m    455\u001b[0m matrix \u001b[38;5;241m=\u001b[39m make_empty_matrix(\n\u001b[1;32m    456\u001b[0m     shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m), ncol), dtype\u001b[38;5;241m=\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    457\u001b[0m )\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;66;03m# TODO: col.values may fail if there is nullable data or an\u001b[39;00m\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;66;03m# unsupported dtype. We may want to catch and provide a more\u001b[39;00m\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;66;03m# suitable error.\u001b[39;00m\n\u001b[0;32m--> 462\u001b[0m     matrix[:, i] \u001b[38;5;241m=\u001b[39m get_column_values_na(col)\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m matrix\n",
      "File \u001b[0;32mcupy/_core/core.pyx:1588\u001b[0m, in \u001b[0;36mcupy._core.core._ndarray_base.__setitem__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mcupy/_core/_routines_indexing.pyx:50\u001b[0m, in \u001b[0;36mcupy._core._routines_indexing._ndarray_setitem\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mcupy/_core/_routines_indexing.pyx:1026\u001b[0m, in \u001b[0;36mcupy._core._routines_indexing._scatter_op\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mcupy/_core/_kernel.pyx:1375\u001b[0m, in \u001b[0;36mcupy._core._kernel.ufunc.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mcupy/_core/_kernel.pyx:1402\u001b[0m, in \u001b[0;36mcupy._core._kernel.ufunc._get_ufunc_kernel\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mcupy/_core/_kernel.pyx:1082\u001b[0m, in \u001b[0;36mcupy._core._kernel._get_ufunc_kernel\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mcupy/_core/_kernel.pyx:90\u001b[0m, in \u001b[0;36mcupy._core._kernel._get_simple_elementwise_kernel\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mcupy/_core/_kernel.pyx:71\u001b[0m, in \u001b[0;36mcupy._core._kernel._get_simple_elementwise_kernel_code\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mcupy/_core/_kernel.pyx:343\u001b[0m, in \u001b[0;36mcupy._core._kernel._get_kernel_params\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mcupy/_core/_kernel.pyx:319\u001b[0m, in \u001b[0;36mcupy._core._kernel._ArgInfo.get_param_c_type\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mcupy/_core/_kernel.pyx:306\u001b[0m, in \u001b[0;36mcupy._core._kernel._ArgInfo.get_c_type\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mcupy/_core/_scalar.pyx:68\u001b[0m, in \u001b[0;36mcupy._core._scalar.get_typename\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mcupy/_core/_scalar.pyx:73\u001b[0m, in \u001b[0;36mcupy._core._scalar.get_typename\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: <class 'numpy.object_'>"
     ]
    }
   ],
   "source": [
    "def objective_function(onpromotion, total_other_promo_store, total_other_city_promo, holiday,\n",
    "                       holiday_description, event, time_since_quake, time_since_quake_sq, state, city, \n",
    "                       dcoilwtico, day, month, workday, payday, onpromotion_lag_1, type, dayofyear, year,\n",
    "                       onpromotion_lag_2, onpromotion_lag_3, onpromotion_lag_4, onpromotion_lag_5,\n",
    "                       onpromotion_lag_6, onpromotion_lag_7, dcoilwtico_lag_1, dcoilwtico_lag_2, \n",
    "                       dcoilwtico_lag_3, dcoilwtico_lag_4, dcoilwtico_lag_5, dcoilwtico_lag_6, \n",
    "                       dcoilwtico_lag_7, sales_one_year_lag, Change_in_oil_prices, promo_last_7_days, X_C=X_C, y=y):\n",
    "    \n",
    "    # Convert non-integer arguments to integers\n",
    "    variable_list = [int(round(Change_in_oil_prices)), int(round(city)),int(round(day)), int(round(dayofyear)), int(round(dcoilwtico)),\n",
    "                        int(round(dcoilwtico_lag_1)), int(round(dcoilwtico_lag_2)), int(round(dcoilwtico_lag_3)), int(round(dcoilwtico_lag_4)),\n",
    "                        int(round(dcoilwtico_lag_5)), int(round(dcoilwtico_lag_6)), int(round(dcoilwtico_lag_7)), int(round(event)),\n",
    "                        int(round(holiday)), int(round(holiday_description)), int(round(month)), int(round(onpromotion)),int(round(onpromotion_lag_1)),\n",
    "                        int(round(onpromotion_lag_2)), int(round(onpromotion_lag_3)), int(round(onpromotion_lag_4)), int(round(onpromotion_lag_5)),\n",
    "                        int(round(onpromotion_lag_6)), int(round(onpromotion_lag_7)), int(round(payday)), int(round(promo_last_7_days)),\n",
    "                        int(round(sales_one_year_lag)), int(round(state)), int(round(time_since_quake)), int(round(time_since_quake_sq)),\n",
    "                        int(round(total_other_city_promo)), int(round(total_other_promo_store)), int(round(type)), int(round(workday)), int(round(year))]\n",
    "    \n",
    "    X_C = X_C.copy()\n",
    "    column_to_remove = []\n",
    "    for i in range(3, X_C.shape[1]):\n",
    "        if variable_list[i-3]==0:\n",
    "            column_to_remove.append(X_C.columns[i])\n",
    "    \n",
    "    X_C.drop(column_to_remove, axis=1, inplace=True)\n",
    "\n",
    "    model_2 = RandomForestRegressor()\n",
    "\n",
    "    model_1 = LinearRegression(fit_intercept=False, algorithm=\"svd\", copy_X=True)\n",
    "    # Use time series split for cross validation. \n",
    "    cv_split = TimeSeriesSplit(n_splits = 4)\n",
    "    \n",
    "    # Create lists to append MSLE scores.\n",
    "    valid_msle = []\n",
    "    \n",
    "    # Dates to index through. \n",
    "    dates = X_C.index.drop_duplicates()\n",
    "    \n",
    "    \n",
    "    list1 = [\"time_since_quake\", \"time_since_quake_sq\"]\n",
    "    list2 = X_C.columns\n",
    "\n",
    "    # Convert lists to sets\n",
    "    set1 = set(list1)\n",
    "    set2 = set(list2)\n",
    "\n",
    "    # Find the values in set1 that are not in set2\n",
    "    uncommon_values = set1 - set2\n",
    "\n",
    "    # Remove the uncommon values from list1\n",
    "    list1 = [value for value in list1 if value not in uncommon_values]\n",
    "    \n",
    "    numeric_transformer = [\"float\", StandardScaler()]\n",
    "    data_preprocessor = Prepare_data(list1, [numeric_transformer])\n",
    "    \n",
    "    # Perform Cross-Validation to determine how model will do on unseen data.\n",
    "    for train_index, valid_index in cv_split.split(dates):\n",
    "\n",
    "        model = Hybrid_Pipeline(data_preprocessor, model_1, model_2, Boosted=True, to_tensor=False)\n",
    "\n",
    "        # Index dates.\n",
    "        date_train, date_valid = dates[train_index], dates[valid_index]\n",
    "\n",
    "        # Selecting data for y_train and y_valid.\n",
    "        y_train = y.loc[date_train]\n",
    "        y_valid = y.loc[date_valid]\n",
    "\n",
    "        # Selecting data for X_train and X_valid.\n",
    "        X_train = X_C.loc[date_train]\n",
    "        X_valid = X_C.loc[date_valid]\n",
    "\n",
    "        X_train = X_train.reset_index().sort_values([\"store_nbr\", \"family\", \"date\"])\n",
    "        X_valid = X_valid.reset_index().sort_values([\"store_nbr\", \"family\", \"date\"])\n",
    "        X_train = X_train.set_index([\"date\"])\n",
    "        X_valid = X_valid.set_index([\"date\"])\n",
    "\n",
    "        y_train = y_train.reset_index().sort_values([\"store_nbr\", \"family\", \"date\"])\n",
    "        y_valid = y_valid.reset_index().sort_values([\"store_nbr\", \"family\", \"date\"])\n",
    "        y_train = y_train.set_index([\"date\"])\n",
    "        y_valid = y_valid.set_index([\"date\"])\n",
    "\n",
    "\n",
    "        # Fitting model.\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Create predictions for Trainning and Validation.\n",
    "        pred = model.predict(X_valid)\n",
    "\n",
    "        # MSE for trainning and validation. \n",
    "        valid_msle.append(float(mean_squared_log_error(y_valid[\"sales\"], pred[\"sales\"])))\n",
    "\n",
    "\n",
    "    return -float(np.sqrt(np.mean(valid_msle)))\n",
    "\n",
    "# Define the parameter space for Bayesian optimization (each feature is a parameter)\n",
    "params = {X_C.columns[i]: (0, 1) for i in range(3, X_C.shape[1])}\n",
    "\n",
    "# Initialize the Bayesian optimizer\n",
    "optimizer = BayesianOptimization(\n",
    "    f=objective_function,\n",
    "    pbounds=params,\n",
    "    random_state=1,  # For reproducibility\n",
    ")\n",
    "\n",
    "# Perform the optimization\n",
    "optimizer.maximize(init_points=30, n_iter=100)\n",
    "\n",
    "variables = list(optimizer.max[\"params\"].values())\n",
    "variables = [True, True, True] + [x>0.5 for x in variables]\n",
    "X_C = X_C[X_C.columns[variables]]\n",
    "\n",
    "list1 = [\"time_since_quake\", \"time_since_quake_sq\"]\n",
    "list2 = X_C.columns\n",
    "\n",
    "# Convert lists to sets\n",
    "set1 = set(list1)\n",
    "set2 = set(list2)\n",
    "\n",
    "# Find the values in set1 that are not in set2\n",
    "uncommon_values = set1 - set2\n",
    "\n",
    "# Remove the uncommon values from list1\n",
    "list1 = [value for value in list1 if value not in uncommon_values]\n",
    "\n",
    "numeric_transformer = [\"float\", StandardScaler()]\n",
    "data_preprocessor = Prepare_data(list1, [numeric_transformer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fa0bd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623323f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Model\n",
    "model = Hybrid_Pipeline(data_preprocessor, lr, xgb, Boosted=True, to_tensor=False)\n",
    "model.fit(X_C, y)\n",
    "\n",
    "X_test_C = X_test_C[X_test_C.columns[variables]]\n",
    "pred_3 = model.predict(X_test_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7d5d80",
   "metadata": {},
   "source": [
    "## Linear Regression, Random Forest Regressor, Stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8ee15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function(onpromotion, total_other_promo_store, total_other_city_promo, holiday,\n",
    "                       holiday_description, event, time_since_quake, time_since_quake_sq, state, city, \n",
    "                       dcoilwtico, day, month, workday, payday, onpromotion_lag_1, type, dayofyear, year,\n",
    "                       onpromotion_lag_2, onpromotion_lag_3, onpromotion_lag_4, onpromotion_lag_5,\n",
    "                       onpromotion_lag_6, onpromotion_lag_7, dcoilwtico_lag_1, dcoilwtico_lag_2, \n",
    "                       dcoilwtico_lag_3, dcoilwtico_lag_4, dcoilwtico_lag_5, dcoilwtico_lag_6, \n",
    "                       dcoilwtico_lag_7, sales_one_year_lag, Change_in_oil_prices, promo_last_7_days, X_C=X_C, y=y):\n",
    "    \n",
    "    # Convert non-integer arguments to integers\n",
    "    variable_list = [int(round(Change_in_oil_prices)), int(round(city)),int(round(day)), int(round(dayofyear)), int(round(dcoilwtico)),\n",
    "                        int(round(dcoilwtico_lag_1)), int(round(dcoilwtico_lag_2)), int(round(dcoilwtico_lag_3)), int(round(dcoilwtico_lag_4)),\n",
    "                        int(round(dcoilwtico_lag_5)), int(round(dcoilwtico_lag_6)), int(round(dcoilwtico_lag_7)), int(round(event)),\n",
    "                        int(round(holiday)), int(round(holiday_description)), int(round(month)), int(round(onpromotion)),int(round(onpromotion_lag_1)),\n",
    "                        int(round(onpromotion_lag_2)), int(round(onpromotion_lag_3)), int(round(onpromotion_lag_4)), int(round(onpromotion_lag_5)),\n",
    "                        int(round(onpromotion_lag_6)), int(round(onpromotion_lag_7)), int(round(payday)), int(round(promo_last_7_days)),\n",
    "                        int(round(sales_one_year_lag)), int(round(state)), int(round(time_since_quake)), int(round(time_since_quake_sq)),\n",
    "                        int(round(total_other_city_promo)), int(round(total_other_promo_store)), int(round(type)), int(round(workday)), int(round(year))]\n",
    "    \n",
    "    X_C = X_C.copy()\n",
    "    column_to_remove = []\n",
    "    for i in range(3, X_C.shape[1]):\n",
    "        if variable_list[i-3]==0:\n",
    "            column_to_remove.append(X_C.columns[i])\n",
    "    \n",
    "    X_C.drop(column_to_remove, axis=1, inplace=True)\n",
    "\n",
    "    model_2 = RandomForestRegressor()\n",
    "\n",
    "    model_1 = LinearRegression(fit_intercept=False, algorithm=\"svd\", copy_X=True)\n",
    "    # Use time series split for cross validation. \n",
    "    cv_split = TimeSeriesSplit(n_splits = 4)\n",
    "    \n",
    "    # Create lists to append MSLE scores.\n",
    "    valid_msle = []\n",
    "    \n",
    "    # Dates to index through. \n",
    "    dates = X_C.index.drop_duplicates()\n",
    "    \n",
    "    \n",
    "    list1 = [\"time_since_quake\", \"time_since_quake_sq\"]\n",
    "    list2 = X_C.columns\n",
    "\n",
    "    # Convert lists to sets\n",
    "    set1 = set(list1)\n",
    "    set2 = set(list2)\n",
    "\n",
    "    # Find the values in set1 that are not in set2\n",
    "    uncommon_values = set1 - set2\n",
    "\n",
    "    # Remove the uncommon values from list1\n",
    "    list1 = [value for value in list1 if value not in uncommon_values]\n",
    "    \n",
    "    numeric_transformer = [\"float\", StandardScaler()]\n",
    "    data_preprocessor = Prepare_data(list1, [numeric_transformer])\n",
    "    \n",
    "    # Perform Cross-Validation to determine how model will do on unseen data.\n",
    "    for train_index, valid_index in cv_split.split(dates):\n",
    "\n",
    "        model = Hybrid_Pipeline(data_preprocessor, model_1, model_2, Boosted=False, to_tensor=False)\n",
    "\n",
    "        # Index dates.\n",
    "        date_train, date_valid = dates[train_index], dates[valid_index]\n",
    "\n",
    "        # Selecting data for y_train and y_valid.\n",
    "        y_train = y.loc[date_train]\n",
    "        y_valid = y.loc[date_valid]\n",
    "\n",
    "        # Selecting data for X_train and X_valid.\n",
    "        X_train = X_C.loc[date_train]\n",
    "        X_valid = X_C.loc[date_valid]\n",
    "\n",
    "        X_train = X_train.reset_index().sort_values([\"store_nbr\", \"family\", \"date\"])\n",
    "        X_valid = X_valid.reset_index().sort_values([\"store_nbr\", \"family\", \"date\"])\n",
    "        X_train = X_train.set_index([\"date\"])\n",
    "        X_valid = X_valid.set_index([\"date\"])\n",
    "\n",
    "        y_train = y_train.reset_index().sort_values([\"store_nbr\", \"family\", \"date\"])\n",
    "        y_valid = y_valid.reset_index().sort_values([\"store_nbr\", \"family\", \"date\"])\n",
    "        y_train = y_train.set_index([\"date\"])\n",
    "        y_valid = y_valid.set_index([\"date\"])\n",
    "\n",
    "\n",
    "        # Fitting model.\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Create predictions for Trainning and Validation.\n",
    "        pred = model.predict(X_valid)\n",
    "\n",
    "        # MSE for trainning and validation. \n",
    "        valid_msle.append(float(mean_squared_log_error(y_valid[\"sales\"], pred[\"sales\"])))\n",
    "\n",
    "\n",
    "    return -float(np.sqrt(np.mean(valid_msle)))\n",
    "\n",
    "# Define the parameter space for Bayesian optimization (each feature is a parameter)\n",
    "params = {X_C.columns[i]: (0, 1) for i in range(3, X_C.shape[1])}\n",
    "\n",
    "# Initialize the Bayesian optimizer\n",
    "optimizer = BayesianOptimization(\n",
    "    f=objective_function,\n",
    "    pbounds=params,\n",
    "    random_state=1,  # For reproducibility\n",
    ")\n",
    "\n",
    "# Perform the optimization\n",
    "optimizer.maximize(init_points=30, n_iter=100)\n",
    "\n",
    "variables = list(optimizer.max[\"params\"].values())\n",
    "variables = [True, True, True] + [x>0.5 for x in variables]\n",
    "X_C = X_C[X_C.columns[variables]]\n",
    "\n",
    "list1 = [\"time_since_quake\", \"time_since_quake_sq\"]\n",
    "list2 = X_C.columns\n",
    "\n",
    "# Convert lists to sets\n",
    "set1 = set(list1)\n",
    "set2 = set(list2)\n",
    "\n",
    "# Find the values in set1 that are not in set2\n",
    "uncommon_values = set1 - set2\n",
    "\n",
    "# Remove the uncommon values from list1\n",
    "list1 = [value for value in list1 if value not in uncommon_values]\n",
    "\n",
    "numeric_transformer = [\"float\", StandardScaler()]\n",
    "data_preprocessor = Prepare_data(list1, [numeric_transformer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e5e31c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b7199a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Model\n",
    "model = Hybrid_Pipeline(data_preprocessor, lr, xgb, Boosted=True, to_tensor=False)\n",
    "model.fit(X_C, y)\n",
    "\n",
    "X_test_C = X_test_C[X_test_C.columns[variables]]\n",
    "pred_4 = model.predict(X_test_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73be0b25",
   "metadata": {},
   "source": [
    "## Linear Regression, K-NN Regressor, Stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225cfb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function(onpromotion, total_other_promo_store, total_other_city_promo, holiday,\n",
    "                       holiday_description, event, time_since_quake, time_since_quake_sq, state, city, \n",
    "                       dcoilwtico, day, month, workday, payday, onpromotion_lag_1, type, dayofyear, year,\n",
    "                       onpromotion_lag_2, onpromotion_lag_3, onpromotion_lag_4, onpromotion_lag_5,\n",
    "                       onpromotion_lag_6, onpromotion_lag_7, dcoilwtico_lag_1, dcoilwtico_lag_2, \n",
    "                       dcoilwtico_lag_3, dcoilwtico_lag_4, dcoilwtico_lag_5, dcoilwtico_lag_6, \n",
    "                       dcoilwtico_lag_7, sales_one_year_lag, Change_in_oil_prices, promo_last_7_days, X_C=X_C, y=y):\n",
    "    \n",
    "    # Convert non-integer arguments to integers\n",
    "    variable_list = [int(round(Change_in_oil_prices)), int(round(city)),int(round(day)), int(round(dayofyear)), int(round(dcoilwtico)),\n",
    "                        int(round(dcoilwtico_lag_1)), int(round(dcoilwtico_lag_2)), int(round(dcoilwtico_lag_3)), int(round(dcoilwtico_lag_4)),\n",
    "                        int(round(dcoilwtico_lag_5)), int(round(dcoilwtico_lag_6)), int(round(dcoilwtico_lag_7)), int(round(event)),\n",
    "                        int(round(holiday)), int(round(holiday_description)), int(round(month)), int(round(onpromotion)),int(round(onpromotion_lag_1)),\n",
    "                        int(round(onpromotion_lag_2)), int(round(onpromotion_lag_3)), int(round(onpromotion_lag_4)), int(round(onpromotion_lag_5)),\n",
    "                        int(round(onpromotion_lag_6)), int(round(onpromotion_lag_7)), int(round(payday)), int(round(promo_last_7_days)),\n",
    "                        int(round(sales_one_year_lag)), int(round(state)), int(round(time_since_quake)), int(round(time_since_quake_sq)),\n",
    "                        int(round(total_other_city_promo)), int(round(total_other_promo_store)), int(round(type)), int(round(workday)), int(round(year))]\n",
    "    \n",
    "    X_C = X_C.copy()\n",
    "    column_to_remove = []\n",
    "    for i in range(3, X_C.shape[1]):\n",
    "        if variable_list[i-3]==0:\n",
    "            column_to_remove.append(X_C.columns[i])\n",
    "    \n",
    "    X_C.drop(column_to_remove, axis=1, inplace=True)\n",
    "\n",
    "    model_2 = KNeighborsRegressor()\n",
    "\n",
    "    model_1 = LinearRegression(fit_intercept=False, algorithm=\"svd\", copy_X=True)\n",
    "    # Use time series split for cross validation. \n",
    "    cv_split = TimeSeriesSplit(n_splits = 4)\n",
    "    \n",
    "    # Create lists to append MSLE scores.\n",
    "    valid_msle = []\n",
    "    \n",
    "    # Dates to index through. \n",
    "    dates = X_C.index.drop_duplicates()\n",
    "    \n",
    "    \n",
    "    list1 = [\"time_since_quake\", \"time_since_quake_sq\"]\n",
    "    list2 = X_C.columns\n",
    "\n",
    "    # Convert lists to sets\n",
    "    set1 = set(list1)\n",
    "    set2 = set(list2)\n",
    "\n",
    "    # Find the values in set1 that are not in set2\n",
    "    uncommon_values = set1 - set2\n",
    "\n",
    "    # Remove the uncommon values from list1\n",
    "    list1 = [value for value in list1 if value not in uncommon_values]\n",
    "    \n",
    "    numeric_transformer = [\"float\", StandardScaler()]\n",
    "    data_preprocessor = Prepare_data(list1, [numeric_transformer])\n",
    "    \n",
    "    # Perform Cross-Validation to determine how model will do on unseen data.\n",
    "    for train_index, valid_index in cv_split.split(dates):\n",
    "\n",
    "        model = Hybrid_Pipeline(data_preprocessor, model_1, model_2, Boosted=False, to_tensor=False)\n",
    "\n",
    "        # Index dates.\n",
    "        date_train, date_valid = dates[train_index], dates[valid_index]\n",
    "\n",
    "        # Selecting data for y_train and y_valid.\n",
    "        y_train = y.loc[date_train]\n",
    "        y_valid = y.loc[date_valid]\n",
    "\n",
    "        # Selecting data for X_train and X_valid.\n",
    "        X_train = X_C.loc[date_train]\n",
    "        X_valid = X_C.loc[date_valid]\n",
    "\n",
    "        X_train = X_train.reset_index().sort_values([\"store_nbr\", \"family\", \"date\"])\n",
    "        X_valid = X_valid.reset_index().sort_values([\"store_nbr\", \"family\", \"date\"])\n",
    "        X_train = X_train.set_index([\"date\"])\n",
    "        X_valid = X_valid.set_index([\"date\"])\n",
    "\n",
    "        y_train = y_train.reset_index().sort_values([\"store_nbr\", \"family\", \"date\"])\n",
    "        y_valid = y_valid.reset_index().sort_values([\"store_nbr\", \"family\", \"date\"])\n",
    "        y_train = y_train.set_index([\"date\"])\n",
    "        y_valid = y_valid.set_index([\"date\"])\n",
    "\n",
    "\n",
    "        # Fitting model.\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Create predictions for Trainning and Validation.\n",
    "        pred = model.predict(X_valid)\n",
    "\n",
    "        # MSE for trainning and validation. \n",
    "        valid_msle.append(float(mean_squared_log_error(y_valid[\"sales\"], pred[\"sales\"])))\n",
    "\n",
    "\n",
    "    return -float(np.sqrt(np.mean(valid_msle)))\n",
    "\n",
    "# Define the parameter space for Bayesian optimization (each feature is a parameter)\n",
    "params = {X_C.columns[i]: (0, 1) for i in range(3, X_C.shape[1])}\n",
    "\n",
    "# Initialize the Bayesian optimizer\n",
    "optimizer = BayesianOptimization(\n",
    "    f=objective_function,\n",
    "    pbounds=params,\n",
    "    random_state=1,  # For reproducibility\n",
    ")\n",
    "\n",
    "# Perform the optimization\n",
    "optimizer.maximize(init_points=30, n_iter=100)\n",
    "\n",
    "variables = list(optimizer.max[\"params\"].values())\n",
    "variables = [True, True, True] + [x>0.5 for x in variables]\n",
    "X_C = X_C[X_C.columns[variables]]\n",
    "\n",
    "list1 = [\"time_since_quake\", \"time_since_quake_sq\"]\n",
    "list2 = X_C.columns\n",
    "\n",
    "# Convert lists to sets\n",
    "set1 = set(list1)\n",
    "set2 = set(list2)\n",
    "\n",
    "# Find the values in set1 that are not in set2\n",
    "uncommon_values = set1 - set2\n",
    "\n",
    "# Remove the uncommon values from list1\n",
    "list1 = [value for value in list1 if value not in uncommon_values]\n",
    "\n",
    "numeric_transformer = [\"float\", StandardScaler()]\n",
    "data_preprocessor = Prepare_data(list1, [numeric_transformer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f2ec06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c760f21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Model\n",
    "model = Hybrid_Pipeline(data_preprocessor, lr, xgb, Boosted=True, to_tensor=False)\n",
    "model.fit(X_C, y)\n",
    "\n",
    "X_test_C = X_test_C[X_test_C.columns[variables]]\n",
    "pred_5 = model.predict(X_test_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d132bc",
   "metadata": {},
   "source": [
    "## Linear Regression, K-NN Regressor, Stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8357d25e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88724cfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d26506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Model\n",
    "model = Hybrid_Pipeline(data_preprocessor, lr, xgb, Boosted=True, to_tensor=False)\n",
    "model.fit(X_C, y)\n",
    "\n",
    "X_test_C = X_test_C[X_test_C.columns[variables]]\n",
    "pred_6 = model.predict(X_test_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147f88b2",
   "metadata": {},
   "source": [
    "## Linear Regression, LSTM Regressor, Boosted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8792b61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Model\n",
    "model = Hybrid_Pipeline(data_preprocessor, lr, xgb, Boosted=True, to_tensor=False)\n",
    "model.fit(X_C, y)\n",
    "\n",
    "X_test_C = X_test_C[X_test_C.columns[variables]]\n",
    "pred_7 = model.predict(X_test_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a9dfb7",
   "metadata": {},
   "source": [
    "## Linear Regression, LSTM Regressor, Boosted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f318129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Model\n",
    "model = Hybrid_Pipeline(data_preprocessor, lr, xgb, Boosted=True, to_tensor=False)\n",
    "model.fit(X_C, y)\n",
    "\n",
    "X_test_C = X_test_C[X_test_C.columns[variables]]\n",
    "pred_8 = model.predict(X_test_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd116d2-42fc-489e-8167-20406eb2c7d1",
   "metadata": {},
   "source": [
    "## Final Predictions and Submission "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "161b6096-78e0-4052-b58a-398d9c2b54e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2790612</th>\n",
       "      <td>5.620099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2792394</th>\n",
       "      <td>6.278926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2794176</th>\n",
       "      <td>5.620099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2795958</th>\n",
       "      <td>5.010477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2797740</th>\n",
       "      <td>5.010477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            sales\n",
       "id               \n",
       "2790612  5.620099\n",
       "2792394  6.278926\n",
       "2794176  5.620099\n",
       "2795958  5.010477\n",
       "2797740  5.010477"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate Predictions\n",
    "e_sum = e_1+e_2+e_3+e_4+e_5+e_6+e_7+e_8\n",
    "\n",
    "ensembled_pred = pred_1*e_1/e_sum + pred_2*e_2/e_sum + pred_3*e_3/e_sum + pred_4*e_4/e_sum + pred_5*e_5/e_sum + pred_6*e_6/e_sum + pred_7*e_7/e_sum + pred_8*e_8/e_sum\n",
    "pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6ca14a1b-1fff-4e6e-adec-26c42425112d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembled_pred.to_csv('submission.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8a61c910-4a78-462f-ad44-f0c8d196abc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.6.7 / client 1.6.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 538k/538k [00:02<00:00, 204kB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Successfully submitted to Store Sales - Time Series Forecasting"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api.competition_submit('submission.csv','1st API Submission','store-sales-time-series-forecasting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362e8537",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (rapidsai)",
   "language": "python",
   "name": "rapidsai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
